{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(1, \"/labs/gevaertlab/users/yyhhli/code/vae/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data.dataloader import DataLoader\n",
    "from applications.application_cross_validation import ApplicationCV\n",
    "from datasets.utils import sitk2tensor\n",
    "from datasets import PATCH_DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 16:55:41 | patch_stanfordradiogenomics:StanfordRadiogenomicsPatchAugDataset] patient split: train:100, test:43\n",
      "[05-19 16:55:41 | patch_stanfordradiogenomics:StanfordRadiogenomicsPatchDataset] patient split: train:100, test:43\n"
     ]
    }
   ],
   "source": [
    "\n",
    "stfrg_train_patch = PATCH_DATASETS[\"StanfordRadiogenomicsPatchAugDataset\"](root_dir=None,\n",
    "                                                                            transform=sitk2tensor,\n",
    "                                                                            split='train')\n",
    "stfrg_train_patch_dataloader = DataLoader(dataset=stfrg_train_patch,\n",
    "                                            batch_size=1,\n",
    "                                            shuffle=False,\n",
    "                                            drop_last=False,\n",
    "                                            num_workers=4,\n",
    "                                            pin_memory=True)\n",
    "stfrg_test_patch = PATCH_DATASETS[\"StanfordRadiogenomicsPatchDataset\"](root_dir=None,\n",
    "                                                                        transform=sitk2tensor,\n",
    "                                                                        split='test')\n",
    "stfrg_test_patch_dataloader = DataLoader(dataset=stfrg_test_patch,\n",
    "                                            batch_size=1,\n",
    "                                            shuffle=False,\n",
    "                                            drop_last=False,\n",
    "                                            num_workers=4,\n",
    "                                            pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Predicting StfAJCC with model version 70 =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 16:55:42 | instantiator:  <module>] Created a temporary directory at /tmp/tmpbm09qgp1\n",
      "[05-19 16:55:42 | instantiator:    _write] Writing /tmp/tmpbm09qgp1/_remote_module_non_sriptable.py\n",
      "[05-19 16:55:45 | patch_ds:LIDCPatchAugDataset] patient split: train:699, val:88, test:88\n",
      "[05-19 16:55:45 | patch_ds:LNDbPatch32AugDataset] patient split: train:168, val:22, test:22\n",
      "[05-19 16:55:45 | patch_stanfordradiogenomics:StanfordRadiogenomicsPatchAugDataset] patient split: train:100, test:43\n",
      "[05-19 16:55:45 | export:  Exporter] initializing embeddings\n",
      "[05-19 16:55:49 | patch_ds:LIDCPatchAugDataset] patient split: train:699, val:88, test:88\n",
      "[05-19 16:55:49 | patch_ds:LNDbPatch32AugDataset] patient split: train:168, val:22, test:22\n",
      "[05-19 16:55:49 | patch_stanfordradiogenomics:StanfordRadiogenomicsPatchAugDataset] patient split: train:100, test:43\n",
      "[05-19 16:55:51 | application_cross_validation:ApplicationCV] -----CV prediction for task StfAJCC-----\n",
      "[05-19 16:55:51 | application:ApplicationCV] Loading best hparams ...\n",
      "[05-19 16:55:51 | cv_models:cv_predict_task] models used ['logistic_regression', 'k_nearest_neighbors', 'svc', 'random_forest', 'mlp', 'xgboost']\n",
      "[05-19 16:55:51 | cv_models:cv_predict_task] Before transform: X shape = train:(100, 4096), val:(43, 4096); Y shape = train:(100,), val:(43,)\n",
      "[05-19 16:55:51 | models:data_summary] X shape = train:(99, 4096), val:(40, 4096); Y shape = train:(99,), val:(40,)\n",
      "Y classes = \n",
      " train: \n",
      "  value count\n",
      "0     I    64\n",
      "1   II+    35; \n",
      " val: \n",
      "  value count\n",
      "0     I    23\n",
      "1   II+    17\n",
      "[05-19 16:55:51 | cv_models:cv_predict_eval_with_model] ======logistic_regression======\n",
      "[05-19 16:55:51 | models:predict_with_model] ======logistic_regression======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | 6.0 secs.\n",
      "initializing | 9.0 secs.\n",
      "train Counter({'I': 69, 'II+': 42}) test Counter({'I': 18, 'II+': 10})\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.2s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   1.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.9s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.9s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[05-19 16:55:57 | models:grid_cv_model] best parameters: {'predictor__C': 0.1}\n",
      "[05-19 16:55:57 | models:predict_with_model] result for CV:{'split0_test_score': array([0.62162162, 0.56756757]), 'split1_test_score': array([0.62162162, 0.81081081]), 'split2_test_score': array([0.62162162, 0.67567568]), 'mean_test_score': array([0.62162162, 0.68468468]), 'std_test_score': array([0.        , 0.09950776]), 'rank_test_score': array([2, 1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[05-19 16:55:57 | models:predict_with_model] result for validation set:{'Accuracy': 0.6428571428571429, 'F1': 0.6324143692564744, 'Precision': 0.6285714285714287, 'Recall': 0.6428571428571429, 'AUROC': 0.6111111111111112}\n",
      "[05-19 16:55:58 | models:predict_with_model] ======logistic_regression======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "train Counter({'I': 69, 'II+': 42}) test Counter({'I': 18, 'II+': 10})\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   1.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.9s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   1.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[05-19 16:56:03 | models:grid_cv_model] best parameters: {'predictor__C': 0.1}\n",
      "[05-19 16:56:03 | models:predict_with_model] result for CV:{'split0_test_score': array([0.32432432, 0.67567568]), 'split1_test_score': array([0.56756757, 0.59459459]), 'split2_test_score': array([0.62162162, 0.7027027 ]), 'mean_test_score': array([0.5045045 , 0.65765766]), 'std_test_score': array([0.1293036 , 0.04593711]), 'rank_test_score': array([2, 1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[05-19 16:56:03 | models:predict_with_model] result for validation set:{'Accuracy': 0.6428571428571429, 'F1': 0.6485867074102368, 'Precision': 0.6607142857142857, 'Recall': 0.6428571428571429, 'AUROC': 0.6611111111111111}\n",
      "[05-19 16:56:03 | models:predict_with_model] ======logistic_regression======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "train Counter({'I': 70, 'II+': 41}) test Counter({'I': 17, 'II+': 11})\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   1.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   1.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.9s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[05-19 16:56:09 | models:grid_cv_model] best parameters: {'predictor__C': 0.1}\n",
      "[05-19 16:56:09 | models:predict_with_model] result for CV:{'split0_test_score': array([0.7027027 , 0.62162162]), 'split1_test_score': array([0.56756757, 0.7027027 ]), 'split2_test_score': array([0.62162162, 0.75675676]), 'mean_test_score': array([0.63063063, 0.69369369]), 'std_test_score': array([0.05553526, 0.05553526]), 'rank_test_score': array([2, 1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[05-19 16:56:09 | models:predict_with_model] result for validation set:{'Accuracy': 0.6428571428571429, 'F1': 0.6428571428571429, 'Precision': 0.6428571428571429, 'Recall': 0.6428571428571429, 'AUROC': 0.7379679144385025}\n",
      "[05-19 16:56:09 | models:predict_with_model] ======logistic_regression======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "train Counter({'I': 70, 'II+': 41}) test Counter({'I': 17, 'II+': 11})\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[05-19 16:56:13 | models:grid_cv_model] best parameters: {'predictor__C': 0.1}\n",
      "[05-19 16:56:13 | models:predict_with_model] result for CV:{'split0_test_score': array([0.62162162, 0.67567568]), 'split1_test_score': array([0.67567568, 0.72972973]), 'split2_test_score': array([0.59459459, 0.67567568]), 'mean_test_score': array([0.63063063, 0.69369369]), 'std_test_score': array([0.03370863, 0.02548133]), 'rank_test_score': array([2, 1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[05-19 16:56:13 | models:predict_with_model] result for validation set:{'Accuracy': 0.5357142857142857, 'F1': 0.46701509872241587, 'Precision': 0.45238095238095244, 'Recall': 0.5357142857142857, 'AUROC': 0.49732620320855614}\n",
      "[05-19 16:56:13 | models:predict_with_model] ======logistic_regression======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "train Counter({'I': 70, 'II+': 42}) test Counter({'I': 17, 'II+': 10})\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[05-19 16:56:15 | models:grid_cv_model] best parameters: {'predictor__C': 0.01}\n",
      "[05-19 16:56:15 | models:predict_with_model] result for CV:{'split0_test_score': array([0.73684211, 0.71052632]), 'split1_test_score': array([0.54054054, 0.43243243]), 'split2_test_score': array([0.59459459, 0.64864865]), 'mean_test_score': array([0.62399241, 0.59720247]), 'std_test_score': array([0.08279191, 0.11921712]), 'rank_test_score': array([1, 2], dtype=int32)}\n",
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 16:56:15 | models:predict_with_model] result for validation set:{'Accuracy': 0.6296296296296297, 'F1': 0.48653198653198654, 'Precision': 0.39643347050754457, 'Recall': 0.6296296296296297, 'AUROC': 0.5}\n",
      "[05-19 16:56:15 | cv_models:cv_predict_eval_with_model] ======k_nearest_neighbors======\n",
      "[05-19 16:56:15 | models:predict_with_model] ======k_nearest_neighbors======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "train Counter({'I': 69, 'II+': 42}) test Counter({'I': 18, 'II+': 10})\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 16:56:17 | models:grid_cv_model] best parameters: {'predictor__n_neighbors': 3, 'predictor__p': 5}\n",
      "[05-19 16:56:17 | models:predict_with_model] result for CV:{'split0_test_score': array([0.62162162, 0.62162162, 0.59459459, 0.64864865, 0.64864865,\n",
      "       0.59459459, 0.62162162, 0.62162162, 0.62162162, 0.56756757,\n",
      "       0.62162162, 0.64864865]), 'split1_test_score': array([0.67567568, 0.64864865, 0.72972973, 0.67567568, 0.67567568,\n",
      "       0.64864865, 0.7027027 , 0.62162162, 0.64864865, 0.7027027 ,\n",
      "       0.7027027 , 0.59459459]), 'split2_test_score': array([0.67567568, 0.75675676, 0.81081081, 0.72972973, 0.67567568,\n",
      "       0.72972973, 0.59459459, 0.72972973, 0.78378378, 0.64864865,\n",
      "       0.7027027 , 0.7027027 ]), 'mean_test_score': array([0.65765766, 0.67567568, 0.71171171, 0.68468468, 0.66666667,\n",
      "       0.65765766, 0.63963964, 0.65765766, 0.68468468, 0.63963964,\n",
      "       0.67567568, 0.64864865]), 'std_test_score': array([0.02548133, 0.05838505, 0.08918464, 0.03370863, 0.01274066,\n",
      "       0.05553526, 0.04593711, 0.05096265, 0.07093701, 0.05553526,\n",
      "       0.03822199, 0.04413495]), 'rank_test_score': array([ 7,  4,  1,  2,  6,  7, 11,  9,  2, 11,  4, 10], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 16:56:18 | models:predict_with_model] result for validation set:{'Accuracy': 0.6785714285714286, 'F1': 0.6744564112985165, 'Precision': 0.6720969089390142, 'Recall': 0.6785714285714286, 'AUROC': 0.663888888888889}\n",
      "[05-19 16:56:18 | models:predict_with_model] ======k_nearest_neighbors======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Counter({'I': 69, 'II+': 42}) test Counter({'I': 18, 'II+': 10})\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 16:56:20 | models:grid_cv_model] best parameters: {'predictor__n_neighbors': 10, 'predictor__p': 5}\n",
      "[05-19 16:56:20 | models:predict_with_model] result for CV:{'split0_test_score': array([0.54054054, 0.51351351, 0.51351351, 0.59459459, 0.59459459,\n",
      "       0.67567568, 0.62162162, 0.59459459, 0.67567568, 0.62162162,\n",
      "       0.64864865, 0.75675676]), 'split1_test_score': array([0.59459459, 0.64864865, 0.67567568, 0.59459459, 0.56756757,\n",
      "       0.59459459, 0.59459459, 0.56756757, 0.56756757, 0.59459459,\n",
      "       0.62162162, 0.56756757]), 'split2_test_score': array([0.64864865, 0.64864865, 0.59459459, 0.7027027 , 0.67567568,\n",
      "       0.7027027 , 0.72972973, 0.62162162, 0.7027027 , 0.59459459,\n",
      "       0.56756757, 0.64864865]), 'mean_test_score': array([0.59459459, 0.6036036 , 0.59459459, 0.63063063, 0.61261261,\n",
      "       0.65765766, 0.64864865, 0.59459459, 0.64864865, 0.6036036 ,\n",
      "       0.61261261, 0.65765766]), 'std_test_score': array([0.04413495, 0.06370331, 0.06620243, 0.05096265, 0.04593711,\n",
      "       0.04593711, 0.05838505, 0.02206748, 0.05838505, 0.01274066,\n",
      "       0.03370863, 0.07749843]), 'rank_test_score': array([10,  8, 10,  5,  6,  2,  3, 10,  3,  8,  7,  1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 16:56:20 | models:predict_with_model] result for validation set:{'Accuracy': 0.6071428571428571, 'F1': 0.5875888817065287, 'Precision': 0.5816326530612245, 'Recall': 0.6071428571428571, 'AUROC': 0.5722222222222222}\n",
      "[05-19 16:56:20 | models:predict_with_model] ======k_nearest_neighbors======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Counter({'I': 70, 'II+': 41}) test Counter({'I': 17, 'II+': 11})\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 16:56:22 | models:grid_cv_model] best parameters: {'predictor__n_neighbors': 7, 'predictor__p': 2}\n",
      "[05-19 16:56:22 | models:predict_with_model] result for CV:{'split0_test_score': array([0.75675676, 0.75675676, 0.56756757, 0.7027027 , 0.78378378,\n",
      "       0.59459459, 0.72972973, 0.7027027 , 0.64864865, 0.7027027 ,\n",
      "       0.67567568, 0.7027027 ]), 'split1_test_score': array([0.56756757, 0.54054054, 0.54054054, 0.59459459, 0.54054054,\n",
      "       0.56756757, 0.64864865, 0.64864865, 0.62162162, 0.64864865,\n",
      "       0.62162162, 0.64864865]), 'split2_test_score': array([0.64864865, 0.67567568, 0.72972973, 0.67567568, 0.67567568,\n",
      "       0.72972973, 0.67567568, 0.78378378, 0.75675676, 0.64864865,\n",
      "       0.7027027 , 0.75675676]), 'mean_test_score': array([0.65765766, 0.65765766, 0.61261261, 0.65765766, 0.66666667,\n",
      "       0.63063063, 0.68468468, 0.71171171, 0.67567568, 0.66666667,\n",
      "       0.66666667, 0.7027027 ]), 'std_test_score': array([0.07749843, 0.08918464, 0.08354611, 0.04593711, 0.09950776,\n",
      "       0.07093701, 0.03370863, 0.05553526, 0.05838505, 0.02548133,\n",
      "       0.03370863, 0.04413495]), 'rank_test_score': array([ 8,  8, 12,  8,  5, 11,  3,  1,  4,  5,  5,  2], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 16:56:23 | models:predict_with_model] result for validation set:{'Accuracy': 0.6785714285714286, 'F1': 0.6755102040816325, 'Precision': 0.6742063492063491, 'Recall': 0.6785714285714286, 'AUROC': 0.7085561497326204}\n",
      "[05-19 16:56:23 | models:predict_with_model] ======k_nearest_neighbors======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Counter({'I': 70, 'II+': 41}) test Counter({'I': 17, 'II+': 11})\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 16:56:25 | models:grid_cv_model] best parameters: {'predictor__n_neighbors': 7, 'predictor__p': 5}\n",
      "[05-19 16:56:25 | models:predict_with_model] result for CV:{'split0_test_score': array([0.67567568, 0.64864865, 0.59459459, 0.72972973, 0.72972973,\n",
      "       0.64864865, 0.72972973, 0.75675676, 0.64864865, 0.72972973,\n",
      "       0.7027027 , 0.72972973]), 'split1_test_score': array([0.7027027 , 0.64864865, 0.43243243, 0.72972973, 0.64864865,\n",
      "       0.64864865, 0.72972973, 0.78378378, 0.7027027 , 0.67567568,\n",
      "       0.67567568, 0.67567568]), 'split2_test_score': array([0.59459459, 0.62162162, 0.7027027 , 0.62162162, 0.62162162,\n",
      "       0.75675676, 0.54054054, 0.59459459, 0.81081081, 0.56756757,\n",
      "       0.64864865, 0.67567568]), 'mean_test_score': array([0.65765766, 0.63963964, 0.57657658, 0.69369369, 0.66666667,\n",
      "       0.68468468, 0.66666667, 0.71171171, 0.72072072, 0.65765766,\n",
      "       0.67567568, 0.69369369]), 'std_test_score': array([0.04593711, 0.01274066, 0.11107052, 0.05096265, 0.04593711,\n",
      "       0.05096265, 0.08918464, 0.08354611, 0.06741725, 0.06741725,\n",
      "       0.02206748, 0.02548133]), 'rank_test_score': array([ 9, 11, 12,  3,  7,  5,  7,  2,  1, 10,  6,  4], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 16:56:25 | models:predict_with_model] result for validation set:{'Accuracy': 0.4642857142857143, 'F1': 0.4678147939017504, 'Precision': 0.4724702380952381, 'Recall': 0.4642857142857143, 'AUROC': 0.45989304812834225}\n",
      "[05-19 16:56:25 | models:predict_with_model] ======k_nearest_neighbors======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Counter({'I': 70, 'II+': 42}) test Counter({'I': 17, 'II+': 10})\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 16:56:27 | models:grid_cv_model] best parameters: {'predictor__n_neighbors': 5, 'predictor__p': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 16:56:27 | models:predict_with_model] result for CV:{'split0_test_score': array([0.71052632, 0.63157895, 0.52631579, 0.81578947, 0.68421053,\n",
      "       0.60526316, 0.78947368, 0.76315789, 0.65789474, 0.84210526,\n",
      "       0.78947368, 0.81578947]), 'split1_test_score': array([0.64864865, 0.64864865, 0.56756757, 0.64864865, 0.62162162,\n",
      "       0.56756757, 0.62162162, 0.62162162, 0.54054054, 0.59459459,\n",
      "       0.56756757, 0.48648649]), 'split2_test_score': array([0.72972973, 0.7027027 , 0.62162162, 0.72972973, 0.78378378,\n",
      "       0.7027027 , 0.7027027 , 0.72972973, 0.67567568, 0.59459459,\n",
      "       0.62162162, 0.64864865]), 'mean_test_score': array([0.69630156, 0.66097677, 0.57183499, 0.73138928, 0.69653864,\n",
      "       0.62517781, 0.70459934, 0.70483642, 0.62470365, 0.67709815,\n",
      "       0.65955429, 0.6503082 ]), 'std_test_score': array([0.03459569, 0.03031649, 0.03902528, 0.06824505, 0.06677389,\n",
      "       0.05693752, 0.06853844, 0.06040357, 0.05995338, 0.11667765,\n",
      "       0.09448015, 0.1344425 ]), 'rank_test_score': array([ 5,  7, 12,  1,  4, 10,  3,  2, 11,  6,  8,  9], dtype=int32)}\n",
      "[05-19 16:56:27 | models:predict_with_model] result for validation set:{'Accuracy': 0.6296296296296297, 'F1': 0.5414462081128749, 'Precision': 0.5881481481481482, 'Recall': 0.6296296296296297, 'AUROC': 0.6499999999999999}\n",
      "[05-19 16:56:27 | cv_models:cv_predict_eval_with_model] ======svc======\n",
      "[05-19 16:56:27 | models:predict_with_model] ======svc======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "train Counter({'I': 69, 'II+': 42}) test Counter({'I': 18, 'II+': 10})\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 16:56:29 | models:grid_cv_model] best parameters: {'predictor__C': 1, 'predictor__degree': 1}\n",
      "[05-19 16:56:29 | models:predict_with_model] result for CV:{'split0_test_score': array([0.62162162, 0.62162162, 0.62162162, 0.62162162, 0.62162162,\n",
      "       0.62162162, 0.62162162, 0.62162162, 0.62162162]), 'split1_test_score': array([0.62162162, 0.62162162, 0.62162162, 0.62162162, 0.62162162,\n",
      "       0.62162162, 0.67567568, 0.67567568, 0.67567568]), 'split2_test_score': array([0.62162162, 0.62162162, 0.62162162, 0.62162162, 0.62162162,\n",
      "       0.62162162, 0.72972973, 0.72972973, 0.72972973]), 'mean_test_score': array([0.62162162, 0.62162162, 0.62162162, 0.62162162, 0.62162162,\n",
      "       0.62162162, 0.67567568, 0.67567568, 0.67567568]), 'std_test_score': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.04413495, 0.04413495, 0.04413495]), 'rank_test_score': array([4, 4, 4, 4, 4, 4, 1, 1, 1], dtype=int32)}\n",
      "[05-19 16:56:29 | models:predict_with_model] result for validation set:{'Accuracy': 0.6428571428571429, 'F1': 0.6324143692564744, 'Precision': 0.6285714285714287, 'Recall': 0.6428571428571429, 'AUROC': 0.6388888888888888}\n",
      "[05-19 16:56:29 | models:predict_with_model] ======svc======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "train Counter({'I': 69, 'II+': 42}) test Counter({'I': 18, 'II+': 10})\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 16:56:30 | models:grid_cv_model] best parameters: {'predictor__C': 0.01, 'predictor__degree': 1}\n",
      "[05-19 16:56:30 | models:predict_with_model] result for CV:{'split0_test_score': array([0.67567568, 0.67567568, 0.67567568, 0.67567568, 0.67567568,\n",
      "       0.67567568, 0.59459459, 0.59459459, 0.59459459]), 'split1_test_score': array([0.56756757, 0.56756757, 0.56756757, 0.56756757, 0.56756757,\n",
      "       0.56756757, 0.56756757, 0.56756757, 0.56756757]), 'split2_test_score': array([0.62162162, 0.62162162, 0.62162162, 0.62162162, 0.62162162,\n",
      "       0.62162162, 0.64864865, 0.64864865, 0.64864865]), 'mean_test_score': array([0.62162162, 0.62162162, 0.62162162, 0.62162162, 0.62162162,\n",
      "       0.62162162, 0.6036036 , 0.6036036 , 0.6036036 ]), 'std_test_score': array([0.04413495, 0.04413495, 0.04413495, 0.04413495, 0.04413495,\n",
      "       0.04413495, 0.03370863, 0.03370863, 0.03370863]), 'rank_test_score': array([1, 1, 1, 1, 1, 1, 7, 7, 7], dtype=int32)}\n",
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 16:56:31 | models:predict_with_model] result for validation set:{'Accuracy': 0.6428571428571429, 'F1': 0.5031055900621119, 'Precision': 0.41326530612244905, 'Recall': 0.6428571428571429, 'AUROC': 0.7277777777777777}\n",
      "[05-19 16:56:31 | models:predict_with_model] ======svc======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "train Counter({'I': 70, 'II+': 41}) test Counter({'I': 17, 'II+': 11})\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 16:56:32 | models:grid_cv_model] best parameters: {'predictor__C': 1, 'predictor__degree': 1}\n",
      "[05-19 16:56:32 | models:predict_with_model] result for CV:{'split0_test_score': array([0.7027027 , 0.7027027 , 0.7027027 , 0.7027027 , 0.7027027 ,\n",
      "       0.7027027 , 0.67567568, 0.67567568, 0.67567568]), 'split1_test_score': array([0.56756757, 0.56756757, 0.56756757, 0.56756757, 0.56756757,\n",
      "       0.56756757, 0.62162162, 0.62162162, 0.62162162]), 'split2_test_score': array([0.62162162, 0.62162162, 0.62162162, 0.62162162, 0.62162162,\n",
      "       0.62162162, 0.62162162, 0.62162162, 0.62162162]), 'mean_test_score': array([0.63063063, 0.63063063, 0.63063063, 0.63063063, 0.63063063,\n",
      "       0.63063063, 0.63963964, 0.63963964, 0.63963964]), 'std_test_score': array([0.05553526, 0.05553526, 0.05553526, 0.05553526, 0.05553526,\n",
      "       0.05553526, 0.02548133, 0.02548133, 0.02548133]), 'rank_test_score': array([4, 4, 4, 4, 4, 4, 1, 1, 1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 16:56:32 | models:predict_with_model] result for validation set:{'Accuracy': 0.6428571428571429, 'F1': 0.6219715956558061, 'Precision': 0.629251700680272, 'Recall': 0.6428571428571429, 'AUROC': 0.7540106951871658}\n",
      "[05-19 16:56:32 | models:predict_with_model] ======svc======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Counter({'I': 70, 'II+': 41}) test Counter({'I': 17, 'II+': 11})\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 16:56:34 | models:grid_cv_model] best parameters: {'predictor__C': 1, 'predictor__degree': 1}\n",
      "[05-19 16:56:34 | models:predict_with_model] result for CV:{'split0_test_score': array([0.62162162, 0.62162162, 0.62162162, 0.62162162, 0.62162162,\n",
      "       0.62162162, 0.67567568, 0.67567568, 0.67567568]), 'split1_test_score': array([0.67567568, 0.67567568, 0.67567568, 0.67567568, 0.67567568,\n",
      "       0.67567568, 0.72972973, 0.72972973, 0.72972973]), 'split2_test_score': array([0.59459459, 0.59459459, 0.59459459, 0.59459459, 0.59459459,\n",
      "       0.59459459, 0.59459459, 0.59459459, 0.59459459]), 'mean_test_score': array([0.63063063, 0.63063063, 0.63063063, 0.63063063, 0.63063063,\n",
      "       0.63063063, 0.66666667, 0.66666667, 0.66666667]), 'std_test_score': array([0.03370863, 0.03370863, 0.03370863, 0.03370863, 0.03370863,\n",
      "       0.03370863, 0.05553526, 0.05553526, 0.05553526]), 'rank_test_score': array([4, 4, 4, 4, 4, 4, 1, 1, 1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 16:56:34 | models:predict_with_model] result for validation set:{'Accuracy': 0.6071428571428571, 'F1': 0.5122668029644775, 'Precision': 0.570054945054945, 'Recall': 0.6071428571428571, 'AUROC': 0.7219251336898396}\n",
      "[05-19 16:56:34 | models:predict_with_model] ======svc======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "train Counter({'I': 70, 'II+': 42}) test Counter({'I': 17, 'II+': 10})\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 16:56:35 | models:grid_cv_model] best parameters: {'predictor__C': 0.01, 'predictor__degree': 1}\n",
      "[05-19 16:56:35 | models:predict_with_model] result for CV:{'split0_test_score': array([0.73684211, 0.73684211, 0.73684211, 0.73684211, 0.73684211,\n",
      "       0.73684211, 0.71052632, 0.71052632, 0.71052632]), 'split1_test_score': array([0.54054054, 0.54054054, 0.54054054, 0.54054054, 0.54054054,\n",
      "       0.54054054, 0.56756757, 0.56756757, 0.56756757]), 'split2_test_score': array([0.59459459, 0.59459459, 0.59459459, 0.59459459, 0.59459459,\n",
      "       0.59459459, 0.56756757, 0.56756757, 0.56756757]), 'mean_test_score': array([0.62399241, 0.62399241, 0.62399241, 0.62399241, 0.62399241,\n",
      "       0.62399241, 0.61522048, 0.61522048, 0.61522048]), 'std_test_score': array([0.08279191, 0.08279191, 0.08279191, 0.08279191, 0.08279191,\n",
      "       0.08279191, 0.0673914 , 0.0673914 , 0.0673914 ]), 'rank_test_score': array([1, 1, 1, 1, 1, 1, 7, 7, 7], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 16:56:35 | models:predict_with_model] result for validation set:{'Accuracy': 0.6296296296296297, 'F1': 0.48653198653198654, 'Precision': 0.39643347050754457, 'Recall': 0.6296296296296297, 'AUROC': 0.5882352941176471}\n",
      "[05-19 16:56:35 | cv_models:cv_predict_eval_with_model] ======random_forest======\n",
      "[05-19 16:56:35 | models:predict_with_model] ======random_forest======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "train Counter({'I': 69, 'II+': 42}) test Counter({'I': 18, 'II+': 10})\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 16:57:08 | models:grid_cv_model] best parameters: {'predictor__max_depth': 10, 'predictor__max_features': 'auto', 'predictor__min_samples_leaf': 1, 'predictor__n_estimators': 200}\n",
      "[05-19 16:57:08 | models:predict_with_model] result for CV:{'split0_test_score': array([0.59459459, 0.62162162, 0.62162162, 0.59459459, 0.59459459,\n",
      "       0.59459459, 0.62162162, 0.62162162, 0.59459459, 0.62162162,\n",
      "       0.62162162, 0.59459459, 0.59459459, 0.59459459, 0.62162162,\n",
      "       0.62162162]), 'split1_test_score': array([0.75675676, 0.75675676, 0.75675676, 0.72972973, 0.7027027 ,\n",
      "       0.7027027 , 0.72972973, 0.72972973, 0.75675676, 0.75675676,\n",
      "       0.75675676, 0.72972973, 0.7027027 , 0.7027027 , 0.72972973,\n",
      "       0.72972973]), 'split2_test_score': array([0.67567568, 0.7027027 , 0.67567568, 0.7027027 , 0.72972973,\n",
      "       0.72972973, 0.7027027 , 0.7027027 , 0.67567568, 0.7027027 ,\n",
      "       0.67567568, 0.7027027 , 0.72972973, 0.72972973, 0.7027027 ,\n",
      "       0.7027027 ]), 'mean_test_score': array([0.67567568, 0.69369369, 0.68468468, 0.67567568, 0.67567568,\n",
      "       0.67567568, 0.68468468, 0.68468468, 0.67567568, 0.69369369,\n",
      "       0.68468468, 0.67567568, 0.67567568, 0.67567568, 0.68468468,\n",
      "       0.68468468]), 'std_test_score': array([0.06620243, 0.05553526, 0.05553526, 0.05838505, 0.05838505,\n",
      "       0.05838505, 0.04593711, 0.04593711, 0.06620243, 0.05553526,\n",
      "       0.05553526, 0.05838505, 0.05838505, 0.05838505, 0.04593711,\n",
      "       0.04593711]), 'rank_test_score': array([9, 1, 3, 9, 9, 9, 5, 5, 9, 1, 3, 9, 9, 9, 5, 5], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 16:57:08 | models:predict_with_model] result for validation set:{'Accuracy': 0.6785714285714286, 'F1': 0.6625727213962508, 'Precision': 0.6632653061224489, 'Recall': 0.6785714285714286, 'AUROC': 0.5888888888888889}\n",
      "[05-19 16:57:08 | models:predict_with_model] ======random_forest======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "train Counter({'I': 69, 'II+': 42}) test Counter({'I': 18, 'II+': 10})\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 16:57:41 | models:grid_cv_model] best parameters: {'predictor__max_depth': 10, 'predictor__max_features': 'auto', 'predictor__min_samples_leaf': 1, 'predictor__n_estimators': 100}\n",
      "[05-19 16:57:41 | models:predict_with_model] result for CV:{'split0_test_score': array([0.64864865, 0.59459459, 0.59459459, 0.59459459, 0.62162162,\n",
      "       0.59459459, 0.59459459, 0.59459459, 0.64864865, 0.59459459,\n",
      "       0.59459459, 0.59459459, 0.62162162, 0.59459459, 0.59459459,\n",
      "       0.59459459]), 'split1_test_score': array([0.59459459, 0.56756757, 0.56756757, 0.56756757, 0.62162162,\n",
      "       0.59459459, 0.56756757, 0.56756757, 0.59459459, 0.56756757,\n",
      "       0.56756757, 0.56756757, 0.62162162, 0.59459459, 0.56756757,\n",
      "       0.56756757]), 'split2_test_score': array([0.67567568, 0.64864865, 0.62162162, 0.64864865, 0.62162162,\n",
      "       0.64864865, 0.67567568, 0.67567568, 0.67567568, 0.64864865,\n",
      "       0.62162162, 0.64864865, 0.62162162, 0.64864865, 0.67567568,\n",
      "       0.67567568]), 'mean_test_score': array([0.63963964, 0.6036036 , 0.59459459, 0.6036036 , 0.62162162,\n",
      "       0.61261261, 0.61261261, 0.61261261, 0.63963964, 0.6036036 ,\n",
      "       0.59459459, 0.6036036 , 0.62162162, 0.61261261, 0.61261261,\n",
      "       0.61261261]), 'std_test_score': array([0.03370863, 0.03370863, 0.02206748, 0.03370863, 0.        ,\n",
      "       0.02548133, 0.04593711, 0.04593711, 0.03370863, 0.03370863,\n",
      "       0.02206748, 0.03370863, 0.        , 0.02548133, 0.04593711,\n",
      "       0.04593711]), 'rank_test_score': array([ 1, 11, 15, 11,  3,  5,  5,  5,  1, 11, 15, 11,  3,  5,  5,  5],\n",
      "      dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 16:57:41 | models:predict_with_model] result for validation set:{'Accuracy': 0.8214285714285714, 'F1': 0.802555168408827, 'Precision': 0.8602484472049691, 'Recall': 0.8214285714285714, 'AUROC': 0.7083333333333334}\n",
      "[05-19 16:57:41 | models:predict_with_model] ======random_forest======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "train Counter({'I': 70, 'II+': 41}) test Counter({'I': 17, 'II+': 11})\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 16:58:13 | models:grid_cv_model] best parameters: {'predictor__max_depth': 10, 'predictor__max_features': 'auto', 'predictor__min_samples_leaf': 1, 'predictor__n_estimators': 100}\n",
      "[05-19 16:58:13 | models:predict_with_model] result for CV:{'split0_test_score': array([0.64864865, 0.64864865, 0.62162162, 0.62162162, 0.62162162,\n",
      "       0.64864865, 0.62162162, 0.62162162, 0.64864865, 0.64864865,\n",
      "       0.62162162, 0.62162162, 0.62162162, 0.64864865, 0.62162162,\n",
      "       0.62162162]), 'split1_test_score': array([0.67567568, 0.7027027 , 0.7027027 , 0.7027027 , 0.64864865,\n",
      "       0.67567568, 0.7027027 , 0.7027027 , 0.67567568, 0.7027027 ,\n",
      "       0.7027027 , 0.7027027 , 0.64864865, 0.67567568, 0.7027027 ,\n",
      "       0.7027027 ]), 'split2_test_score': array([0.75675676, 0.7027027 , 0.7027027 , 0.72972973, 0.72972973,\n",
      "       0.72972973, 0.72972973, 0.72972973, 0.75675676, 0.7027027 ,\n",
      "       0.7027027 , 0.72972973, 0.72972973, 0.72972973, 0.72972973,\n",
      "       0.72972973]), 'mean_test_score': array([0.69369369, 0.68468468, 0.67567568, 0.68468468, 0.66666667,\n",
      "       0.68468468, 0.68468468, 0.68468468, 0.69369369, 0.68468468,\n",
      "       0.67567568, 0.68468468, 0.66666667, 0.68468468, 0.68468468,\n",
      "       0.68468468]), 'std_test_score': array([0.04593711, 0.02548133, 0.03822199, 0.04593711, 0.04593711,\n",
      "       0.03370863, 0.04593711, 0.04593711, 0.04593711, 0.02548133,\n",
      "       0.03822199, 0.04593711, 0.04593711, 0.03370863, 0.04593711,\n",
      "       0.04593711]), 'rank_test_score': array([ 1,  3, 13,  3, 15,  3,  3,  3,  1,  3, 13,  3, 15,  3,  3,  3],\n",
      "      dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 16:58:13 | models:predict_with_model] result for validation set:{'Accuracy': 0.6785714285714286, 'F1': 0.6662263767526925, 'Precision': 0.6705357142857142, 'Recall': 0.6785714285714286, 'AUROC': 0.7058823529411764}\n",
      "[05-19 16:58:13 | models:predict_with_model] ======random_forest======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Counter({'I': 70, 'II+': 41}) test Counter({'I': 17, 'II+': 11})\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.2s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 16:58:46 | models:grid_cv_model] best parameters: {'predictor__max_depth': 10, 'predictor__max_features': 'auto', 'predictor__min_samples_leaf': 1, 'predictor__n_estimators': 1000}\n",
      "[05-19 16:58:46 | models:predict_with_model] result for CV:{'split0_test_score': array([0.67567568, 0.67567568, 0.7027027 , 0.7027027 , 0.7027027 ,\n",
      "       0.7027027 , 0.7027027 , 0.7027027 , 0.67567568, 0.67567568,\n",
      "       0.7027027 , 0.7027027 , 0.7027027 , 0.7027027 , 0.7027027 ,\n",
      "       0.7027027 ]), 'split1_test_score': array([0.75675676, 0.75675676, 0.75675676, 0.75675676, 0.75675676,\n",
      "       0.75675676, 0.75675676, 0.75675676, 0.75675676, 0.75675676,\n",
      "       0.75675676, 0.75675676, 0.75675676, 0.75675676, 0.75675676,\n",
      "       0.75675676]), 'split2_test_score': array([0.64864865, 0.64864865, 0.64864865, 0.7027027 , 0.62162162,\n",
      "       0.67567568, 0.62162162, 0.67567568, 0.64864865, 0.64864865,\n",
      "       0.64864865, 0.7027027 , 0.62162162, 0.67567568, 0.62162162,\n",
      "       0.67567568]), 'mean_test_score': array([0.69369369, 0.69369369, 0.7027027 , 0.72072072, 0.69369369,\n",
      "       0.71171171, 0.69369369, 0.71171171, 0.69369369, 0.69369369,\n",
      "       0.7027027 , 0.72072072, 0.69369369, 0.71171171, 0.69369369,\n",
      "       0.71171171]), 'std_test_score': array([0.04593711, 0.04593711, 0.04413495, 0.02548133, 0.05553526,\n",
      "       0.03370863, 0.05553526, 0.03370863, 0.04593711, 0.04593711,\n",
      "       0.04413495, 0.02548133, 0.05553526, 0.03370863, 0.05553526,\n",
      "       0.03370863]), 'rank_test_score': array([9, 9, 7, 1, 9, 3, 9, 3, 9, 9, 7, 1, 9, 3, 9, 3], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 16:58:48 | models:predict_with_model] result for validation set:{'Accuracy': 0.7142857142857143, 'F1': 0.6975772765246449, 'Precision': 0.7142857142857143, 'Recall': 0.7142857142857143, 'AUROC': 0.7272727272727273}\n",
      "[05-19 16:58:48 | models:predict_with_model] ======random_forest======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Counter({'I': 70, 'II+': 42}) test Counter({'I': 17, 'II+': 10})\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 16:59:21 | models:grid_cv_model] best parameters: {'predictor__max_depth': 10, 'predictor__max_features': 'auto', 'predictor__min_samples_leaf': 4, 'predictor__n_estimators': 500}\n",
      "[05-19 16:59:21 | models:predict_with_model] result for CV:{'split0_test_score': array([0.78947368, 0.71052632, 0.73684211, 0.76315789, 0.76315789,\n",
      "       0.76315789, 0.81578947, 0.73684211, 0.78947368, 0.71052632,\n",
      "       0.73684211, 0.76315789, 0.76315789, 0.76315789, 0.81578947,\n",
      "       0.73684211]), 'split1_test_score': array([0.59459459, 0.56756757, 0.56756757, 0.56756757, 0.56756757,\n",
      "       0.56756757, 0.56756757, 0.56756757, 0.59459459, 0.56756757,\n",
      "       0.56756757, 0.56756757, 0.56756757, 0.56756757, 0.56756757,\n",
      "       0.56756757]), 'split2_test_score': array([0.62162162, 0.62162162, 0.67567568, 0.67567568, 0.59459459,\n",
      "       0.67567568, 0.7027027 , 0.7027027 , 0.62162162, 0.62162162,\n",
      "       0.67567568, 0.67567568, 0.59459459, 0.67567568, 0.7027027 ,\n",
      "       0.7027027 ]), 'mean_test_score': array([0.6685633 , 0.6332385 , 0.66002845, 0.66880038, 0.64177335,\n",
      "       0.66880038, 0.69535325, 0.66903746, 0.6685633 , 0.6332385 ,\n",
      "       0.66002845, 0.66880038, 0.64177335, 0.66880038, 0.69535325,\n",
      "       0.66903746]), 'std_test_score': array([0.08620559, 0.0589379 , 0.06998616, 0.07999728, 0.08653812,\n",
      "       0.07999728, 0.10146934, 0.07309117, 0.08620559, 0.0589379 ,\n",
      "       0.06998616, 0.07999728, 0.08653812, 0.07999728, 0.10146934,\n",
      "       0.07309117]), 'rank_test_score': array([ 9, 15, 11,  5, 13,  5,  1,  3,  9, 15, 11,  5, 13,  5,  1,  3],\n",
      "      dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 16:59:22 | models:predict_with_model] result for validation set:{'Accuracy': 0.6666666666666666, 'F1': 0.5651867512332629, 'Precision': 0.7820512820512819, 'Recall': 0.6666666666666666, 'AUROC': 0.5882352941176471}\n",
      "[05-19 16:59:22 | cv_models:cv_predict_eval_with_model] ======mlp======\n",
      "[05-19 16:59:22 | models:predict_with_model] ======mlp======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "train Counter({'I': 69, 'II+': 42}) test Counter({'I': 18, 'II+': 10})\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.9s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.7s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.7s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.8s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.9s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 16:59:34 | models:grid_cv_model] best parameters: {'predictor__hidden_layer_sizes': (100, 10)}\n",
      "[05-19 16:59:34 | models:predict_with_model] result for CV:{'split0_test_score': array([0.59459459, 0.56756757, 0.59459459, 0.56756757]), 'split1_test_score': array([0.7027027 , 0.7027027 , 0.54054054, 0.56756757]), 'split2_test_score': array([0.72972973, 0.64864865, 0.7027027 , 0.7027027 ]), 'mean_test_score': array([0.67567568, 0.63963964, 0.61261261, 0.61261261]), 'std_test_score': array([0.05838505, 0.05553526, 0.06741725, 0.06370331]), 'rank_test_score': array([1, 2, 3, 3], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 16:59:34 | models:predict_with_model] result for validation set:{'Accuracy': 0.6785714285714286, 'F1': 0.6847926267281107, 'Precision': 0.7344322344322344, 'Recall': 0.6785714285714286, 'AUROC': 0.6833333333333333}\n",
      "[05-19 16:59:34 | models:predict_with_model] ======mlp======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "train Counter({'I': 69, 'II+': 42}) test Counter({'I': 18, 'II+': 10})\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.9s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.8s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.9s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.7s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   4.2s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   4.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 16:59:51 | models:grid_cv_model] best parameters: {'predictor__hidden_layer_sizes': (400, 40)}\n",
      "[05-19 16:59:51 | models:predict_with_model] result for CV:{'split0_test_score': array([0.64864865, 0.48648649, 0.7027027 , 0.56756757]), 'split1_test_score': array([0.56756757, 0.64864865, 0.67567568, 0.72972973]), 'split2_test_score': array([0.54054054, 0.51351351, 0.54054054, 0.67567568]), 'mean_test_score': array([0.58558559, 0.54954955, 0.63963964, 0.65765766]), 'std_test_score': array([0.04593711, 0.07093701, 0.07093701, 0.06741725]), 'rank_test_score': array([3, 4, 2, 1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   2.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 16:59:53 | models:predict_with_model] result for validation set:{'Accuracy': 0.6785714285714286, 'F1': 0.6849237718802935, 'Precision': 0.7065934065934066, 'Recall': 0.6785714285714286, 'AUROC': 0.7555555555555555}\n",
      "[05-19 16:59:53 | models:predict_with_model] ======mlp======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   2.5s\n",
      "train Counter({'I': 70, 'II+': 41}) test Counter({'I': 17, 'II+': 11})\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.2s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.9s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.9s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   2.2s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   2.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   2.8s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   2.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   2.1s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   2.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:00:07 | models:grid_cv_model] best parameters: {'predictor__hidden_layer_sizes': (100, 10)}\n",
      "[05-19 17:00:07 | models:predict_with_model] result for CV:{'split0_test_score': array([0.72972973, 0.62162162, 0.59459459, 0.62162162]), 'split1_test_score': array([0.7027027 , 0.62162162, 0.7027027 , 0.67567568]), 'split2_test_score': array([0.67567568, 0.72972973, 0.75675676, 0.67567568]), 'mean_test_score': array([0.7027027 , 0.65765766, 0.68468468, 0.65765766]), 'std_test_score': array([0.02206748, 0.05096265, 0.06741725, 0.02548133]), 'rank_test_score': array([1, 4, 2, 3], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:00:08 | models:predict_with_model] result for validation set:{'Accuracy': 0.6071428571428571, 'F1': 0.5490127758420442, 'Precision': 0.5758928571428571, 'Recall': 0.6071428571428571, 'AUROC': 0.6524064171122994}\n",
      "[05-19 17:00:08 | models:predict_with_model] ======mlp======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "train Counter({'I': 70, 'II+': 41}) test Counter({'I': 17, 'II+': 11})\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.9s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   1.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.6s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.6s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.6s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:00:20 | models:grid_cv_model] best parameters: {'predictor__hidden_layer_sizes': (100, 20)}\n",
      "[05-19 17:00:20 | models:predict_with_model] result for CV:{'split0_test_score': array([0.67567568, 0.7027027 , 0.7027027 , 0.62162162]), 'split1_test_score': array([0.64864865, 0.64864865, 0.62162162, 0.54054054]), 'split2_test_score': array([0.64864865, 0.7027027 , 0.67567568, 0.64864865]), 'mean_test_score': array([0.65765766, 0.68468468, 0.66666667, 0.6036036 ]), 'std_test_score': array([0.01274066, 0.02548133, 0.03370863, 0.04593711]), 'rank_test_score': array([3, 1, 2, 4], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:00:20 | models:predict_with_model] result for validation set:{'Accuracy': 0.5357142857142857, 'F1': 0.46701509872241587, 'Precision': 0.45238095238095244, 'Recall': 0.5357142857142857, 'AUROC': 0.45454545454545453}\n",
      "[05-19 17:00:21 | models:predict_with_model] ======mlp======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "train Counter({'I': 70, 'II+': 42}) test Counter({'I': 17, 'II+': 10})\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.9s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.7s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   2.5s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   2.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   2.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   2.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:00:36 | models:grid_cv_model] best parameters: {'predictor__hidden_layer_sizes': (400, 40)}\n",
      "[05-19 17:00:36 | models:predict_with_model] result for CV:{'split0_test_score': array([0.63157895, 0.65789474, 0.68421053, 0.71052632]), 'split1_test_score': array([0.54054054, 0.51351351, 0.54054054, 0.51351351]), 'split2_test_score': array([0.67567568, 0.62162162, 0.56756757, 0.64864865]), 'mean_test_score': array([0.61593172, 0.59767662, 0.59743954, 0.62422949]), 'std_test_score': array([0.05626724, 0.06132703, 0.06234056, 0.08226272]), 'rank_test_score': array([2, 3, 4, 1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   2.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:00:38 | models:predict_with_model] result for validation set:{'Accuracy': 0.7037037037037037, 'F1': 0.682261208576998, 'Precision': 0.6966490299823633, 'Recall': 0.7037037037037037, 'AUROC': 0.6529411764705882}\n",
      "[05-19 17:00:38 | cv_models:cv_predict_eval_with_model] ======xgboost======\n",
      "[05-19 17:00:38 | models:predict_with_model] ======xgboost======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   2.7s\n",
      "train Counter({'I': 69, 'II+': 42}) test Counter({'I': 18, 'II+': 10})\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:00:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:00:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:00:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:00:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:00:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:00:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:00:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:00:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:00:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:00:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:00:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:00:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:00:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[05-19 17:00:44 | models:grid_cv_model] best parameters: {'predictor__learning_rate': 0.01, 'predictor__n_estimators': 100, 'predictor__reg_alpha': 1}\n",
      "[05-19 17:00:44 | models:predict_with_model] result for CV:{'split0_test_score': array([0.56756757, 0.62162162, 0.59459459, 0.62162162]), 'split1_test_score': array([0.72972973, 0.62162162, 0.72972973, 0.62162162]), 'split2_test_score': array([0.75675676, 0.62162162, 0.7027027 , 0.62162162]), 'mean_test_score': array([0.68468468, 0.62162162, 0.67567568, 0.62162162]), 'std_test_score': array([0.08354611, 0.        , 0.05838505, 0.        ]), 'rank_test_score': array([1, 3, 2, 3], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:00:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[05-19 17:00:45 | models:predict_with_model] result for validation set:{'Accuracy': 0.7142857142857143, 'F1': 0.7142857142857143, 'Precision': 0.7142857142857143, 'Recall': 0.7142857142857143, 'AUROC': 0.6666666666666667}\n",
      "[05-19 17:00:45 | models:predict_with_model] ======xgboost======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "train Counter({'I': 69, 'II+': 42}) test Counter({'I': 18, 'II+': 10})\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:00:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:00:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:00:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:00:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:00:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:00:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:00:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:00:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:00:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:00:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:00:49] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:00:49] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:00:49] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[05-19 17:00:50 | models:grid_cv_model] best parameters: {'predictor__learning_rate': 0.01, 'predictor__n_estimators': 100, 'predictor__reg_alpha': 1}\n",
      "[05-19 17:00:50 | models:predict_with_model] result for CV:{'split0_test_score': array([0.7027027 , 0.67567568, 0.75675676, 0.67567568]), 'split1_test_score': array([0.67567568, 0.56756757, 0.56756757, 0.56756757]), 'split2_test_score': array([0.67567568, 0.62162162, 0.64864865, 0.62162162]), 'mean_test_score': array([0.68468468, 0.62162162, 0.65765766, 0.62162162]), 'std_test_score': array([0.01274066, 0.04413495, 0.07749843, 0.04413495]), 'rank_test_score': array([1, 3, 2, 3], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:00:50] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[05-19 17:00:51 | models:predict_with_model] result for validation set:{'Accuracy': 0.5357142857142857, 'F1': 0.5401360544217688, 'Precision': 0.5458365164247517, 'Recall': 0.5357142857142857, 'AUROC': 0.6166666666666667}\n",
      "[05-19 17:00:51 | models:predict_with_model] ======xgboost======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "train Counter({'I': 70, 'II+': 41}) test Counter({'I': 17, 'II+': 11})\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:00:51] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:00:51] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:00:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:00:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:00:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:00:53] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:00:53] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:00:54] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:00:54] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:00:54] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:00:55] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:00:55] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:00:55] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[05-19 17:00:56 | models:grid_cv_model] best parameters: {'predictor__learning_rate': 0.01, 'predictor__n_estimators': 100, 'predictor__reg_alpha': 1}\n",
      "[05-19 17:00:56 | models:predict_with_model] result for CV:{'split0_test_score': array([0.7027027 , 0.7027027 , 0.64864865, 0.7027027 ]), 'split1_test_score': array([0.67567568, 0.56756757, 0.64864865, 0.56756757]), 'split2_test_score': array([0.62162162, 0.62162162, 0.67567568, 0.62162162]), 'mean_test_score': array([0.66666667, 0.63063063, 0.65765766, 0.63063063]), 'std_test_score': array([0.03370863, 0.05553526, 0.01274066, 0.05553526]), 'rank_test_score': array([1, 3, 2, 3], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:00:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[05-19 17:00:57 | models:predict_with_model] result for validation set:{'Accuracy': 0.5357142857142857, 'F1': 0.49719887955182074, 'Precision': 0.4897186147186147, 'Recall': 0.5357142857142857, 'AUROC': 0.679144385026738}\n",
      "[05-19 17:00:57 | models:predict_with_model] ======xgboost======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "train Counter({'I': 70, 'II+': 41}) test Counter({'I': 17, 'II+': 11})\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:00:57] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:00:57] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:00:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:00:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:00:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:00:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:01:00] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:01:00] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:01:00] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:01:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:01:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:01:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:01:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[05-19 17:01:02 | models:grid_cv_model] best parameters: {'predictor__learning_rate': 0.1, 'predictor__n_estimators': 100, 'predictor__reg_alpha': 1}\n",
      "[05-19 17:01:02 | models:predict_with_model] result for CV:{'split0_test_score': array([0.67567568, 0.62162162, 0.72972973, 0.62162162]), 'split1_test_score': array([0.7027027 , 0.67567568, 0.75675676, 0.67567568]), 'split2_test_score': array([0.62162162, 0.59459459, 0.56756757, 0.59459459]), 'mean_test_score': array([0.66666667, 0.63063063, 0.68468468, 0.63063063]), 'std_test_score': array([0.03370863, 0.03370863, 0.08354611, 0.03370863]), 'rank_test_score': array([2, 3, 1, 3], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:01:02] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[05-19 17:01:02 | models:predict_with_model] result for validation set:{'Accuracy': 0.5714285714285714, 'F1': 0.4897959183673469, 'Precision': 0.4952380952380952, 'Recall': 0.5714285714285714, 'AUROC': 0.5668449197860963}\n",
      "[05-19 17:01:02 | models:predict_with_model] ======xgboost======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "train Counter({'I': 70, 'II+': 42}) test Counter({'I': 17, 'II+': 10})\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:01:02] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:01:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:01:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:01:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:01:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:01:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:01:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:01:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:01:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:01:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:01:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:01:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:01:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[05-19 17:01:08 | models:grid_cv_model] best parameters: {'predictor__learning_rate': 0.01, 'predictor__n_estimators': 100, 'predictor__reg_alpha': 10}\n",
      "[05-19 17:01:08 | models:predict_with_model] result for CV:{'split0_test_score': array([0.63157895, 0.73684211, 0.60526316, 0.73684211]), 'split1_test_score': array([0.56756757, 0.54054054, 0.59459459, 0.54054054]), 'split2_test_score': array([0.59459459, 0.59459459, 0.56756757, 0.59459459]), 'mean_test_score': array([0.5979137 , 0.62399241, 0.58914177, 0.62399241]), 'std_test_score': array([0.02623772, 0.08279191, 0.01586483, 0.08279191]), 'rank_test_score': array([3, 1, 4, 1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:01:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[05-19 17:01:09 | models:predict_with_model] result for validation set:{'Accuracy': 0.7407407407407407, 'F1': 0.6930720589257175, 'Precision': 0.8163580246913581, 'Recall': 0.7407407407407407, 'AUROC': 0.5470588235294117}\n",
      "[05-19 17:01:09 | application_cross_validation:ApplicationCV] Saved results to /labs/gevaertlab/users/yyhhli/code/vae/applications/results/VAE3D32AUG_70/StfAJCC.cv_result_dict.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "{'__dict': {}, 'logistic_regression': {'Accuracy': [0.6428571428571429, 0.6428571428571429, 0.6428571428571429, 0.5357142857142857, 0.6296296296296297], 'F1': [0.6324143692564744, 0.6485867074102368, 0.6428571428571429, 0.46701509872241587, 0.48653198653198654], 'Precision': [0.6285714285714287, 0.6607142857142857, 0.6428571428571429, 0.45238095238095244, 0.39643347050754457], 'Recall': [0.6428571428571429, 0.6428571428571429, 0.6428571428571429, 0.5357142857142857, 0.6296296296296297], 'AUROC': [0.6111111111111112, 0.6611111111111111, 0.7379679144385025, 0.49732620320855614, 0.5]}, 'k_nearest_neighbors': {'Accuracy': [0.6785714285714286, 0.6071428571428571, 0.6785714285714286, 0.4642857142857143, 0.6296296296296297], 'F1': [0.6744564112985165, 0.5875888817065287, 0.6755102040816325, 0.4678147939017504, 0.5414462081128749], 'Precision': [0.6720969089390142, 0.5816326530612245, 0.6742063492063491, 0.4724702380952381, 0.5881481481481482], 'Recall': [0.6785714285714286, 0.6071428571428571, 0.6785714285714286, 0.4642857142857143, 0.6296296296296297], 'AUROC': [0.663888888888889, 0.5722222222222222, 0.7085561497326204, 0.45989304812834225, 0.6499999999999999]}, 'svc': {'Accuracy': [0.6428571428571429, 0.6428571428571429, 0.6428571428571429, 0.6071428571428571, 0.6296296296296297], 'F1': [0.6324143692564744, 0.5031055900621119, 0.6219715956558061, 0.5122668029644775, 0.48653198653198654], 'Precision': [0.6285714285714287, 0.41326530612244905, 0.629251700680272, 0.570054945054945, 0.39643347050754457], 'Recall': [0.6428571428571429, 0.6428571428571429, 0.6428571428571429, 0.6071428571428571, 0.6296296296296297], 'AUROC': [0.6388888888888888, 0.7277777777777777, 0.7540106951871658, 0.7219251336898396, 0.5882352941176471]}, 'random_forest': {'Accuracy': [0.6785714285714286, 0.8214285714285714, 0.6785714285714286, 0.7142857142857143, 0.6666666666666666], 'F1': [0.6625727213962508, 0.802555168408827, 0.6662263767526925, 0.6975772765246449, 0.5651867512332629], 'Precision': [0.6632653061224489, 0.8602484472049691, 0.6705357142857142, 0.7142857142857143, 0.7820512820512819], 'Recall': [0.6785714285714286, 0.8214285714285714, 0.6785714285714286, 0.7142857142857143, 0.6666666666666666], 'AUROC': [0.5888888888888889, 0.7083333333333334, 0.7058823529411764, 0.7272727272727273, 0.5882352941176471]}, 'mlp': {'Accuracy': [0.6785714285714286, 0.6785714285714286, 0.6071428571428571, 0.5357142857142857, 0.7037037037037037], 'F1': [0.6847926267281107, 0.6849237718802935, 0.5490127758420442, 0.46701509872241587, 0.682261208576998], 'Precision': [0.7344322344322344, 0.7065934065934066, 0.5758928571428571, 0.45238095238095244, 0.6966490299823633], 'Recall': [0.6785714285714286, 0.6785714285714286, 0.6071428571428571, 0.5357142857142857, 0.7037037037037037], 'AUROC': [0.6833333333333333, 0.7555555555555555, 0.6524064171122994, 0.45454545454545453, 0.6529411764705882]}, 'xgboost': {'Accuracy': [0.7142857142857143, 0.5357142857142857, 0.5357142857142857, 0.5714285714285714, 0.7407407407407407], 'F1': [0.7142857142857143, 0.5401360544217688, 0.49719887955182074, 0.4897959183673469, 0.6930720589257175], 'Precision': [0.7142857142857143, 0.5458365164247517, 0.4897186147186147, 0.4952380952380952, 0.8163580246913581], 'Recall': [0.7142857142857143, 0.5357142857142857, 0.5357142857142857, 0.5714285714285714, 0.7407407407407407], 'AUROC': [0.6666666666666667, 0.6166666666666667, 0.679144385026738, 0.5668449197860963, 0.5470588235294117]}}\n",
      "======= Predicting StfHisGrade with model version 70 =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:01:12 | patch_ds:LIDCPatchAugDataset] patient split: train:699, val:88, test:88\n",
      "[05-19 17:01:12 | patch_ds:LNDbPatch32AugDataset] patient split: train:168, val:22, test:22\n",
      "[05-19 17:01:12 | patch_stanfordradiogenomics:StanfordRadiogenomicsPatchAugDataset] patient split: train:100, test:43\n",
      "[05-19 17:01:12 | export:  Exporter] initializing embeddings\n",
      "[05-19 17:01:16 | patch_ds:LIDCPatchAugDataset] patient split: train:699, val:88, test:88\n",
      "[05-19 17:01:16 | patch_ds:LNDbPatch32AugDataset] patient split: train:168, val:22, test:22\n",
      "[05-19 17:01:16 | patch_stanfordradiogenomics:StanfordRadiogenomicsPatchAugDataset] patient split: train:100, test:43\n",
      "[05-19 17:01:16 | application_cross_validation:ApplicationCV] -----CV prediction for task StfHisGrade-----\n",
      "[05-19 17:01:16 | application:ApplicationCV] Loading best hparams ...\n",
      "[05-19 17:01:16 | cv_models:cv_predict_task] models used ['logistic_regression', 'k_nearest_neighbors', 'svc', 'random_forest', 'mlp', 'xgboost']\n",
      "[05-19 17:01:17 | cv_models:cv_predict_task] Before transform: X shape = train:(100, 4096), val:(43, 4096); Y shape = train:(100,), val:(43,)\n",
      "[05-19 17:01:17 | models:data_summary] X shape = train:(87, 4096), val:(37, 4096); Y shape = train:(87,), val:(37,)\n",
      "Y classes = \n",
      " train: \n",
      "  value count\n",
      "0    G1    16\n",
      "1    G2    54\n",
      "2    G3    17; \n",
      " val: \n",
      "  value count\n",
      "0    G1    12\n",
      "1    G2    15\n",
      "2    G3    10\n",
      "[05-19 17:01:17 | cv_models:cv_predict_eval_with_model] ======logistic_regression======\n",
      "[05-19 17:01:17 | models:predict_with_model] ======logistic_regression======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | 4.0 secs.\n",
      "initializing | 8.0 secs.\n",
      "train Counter({'G2': 55, 'G1': 23, 'G3': 21}) test Counter({'G2': 14, 'G3': 6, 'G1': 5})\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[05-19 17:01:20 | models:grid_cv_model] best parameters: {'predictor__C': 0.1}\n",
      "[05-19 17:01:20 | models:predict_with_model] result for CV:{'split0_test_score': array([0.60606061, 0.63636364]), 'split1_test_score': array([0.51515152, 0.51515152]), 'split2_test_score': array([0.54545455, 0.54545455]), 'mean_test_score': array([0.55555556, 0.56565657]), 'std_test_score': array([0.03779452, 0.05150525]), 'rank_test_score': array([2, 1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:01:21 | models:predict_with_model] result for validation set:{'Accuracy': 0.56, 'F1': 0.4237837837837838, 'Precision': 0.3408695652173913, 'Recall': 0.56, 'AUROC': 0.4582105263157895}\n",
      "[05-19 17:01:21 | models:predict_with_model] ======logistic_regression======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "train Counter({'G2': 55, 'G3': 22, 'G1': 22}) test Counter({'G2': 14, 'G1': 6, 'G3': 5})\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[05-19 17:01:24 | models:grid_cv_model] best parameters: {'predictor__C': 0.01}\n",
      "[05-19 17:01:24 | models:predict_with_model] result for CV:{'split0_test_score': array([0.57575758, 0.57575758]), 'split1_test_score': array([0.51515152, 0.51515152]), 'split2_test_score': array([0.57575758, 0.57575758]), 'mean_test_score': array([0.55555556, 0.55555556]), 'std_test_score': array([0.02856997, 0.02856997]), 'rank_test_score': array([1, 1], dtype=int32)}\n",
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:01:24 | models:predict_with_model] result for validation set:{'Accuracy': 0.56, 'F1': 0.40205128205128204, 'Precision': 0.31360000000000005, 'Recall': 0.56, 'AUROC': 0.5}\n",
      "[05-19 17:01:24 | models:predict_with_model] ======logistic_regression======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "train Counter({'G2': 55, 'G3': 22, 'G1': 22}) test Counter({'G2': 14, 'G1': 6, 'G3': 5})\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[05-19 17:01:28 | models:grid_cv_model] best parameters: {'predictor__C': 0.1}\n",
      "[05-19 17:01:28 | models:predict_with_model] result for CV:{'split0_test_score': array([0.60606061, 0.60606061]), 'split1_test_score': array([0.48484848, 0.48484848]), 'split2_test_score': array([0.57575758, 0.60606061]), 'mean_test_score': array([0.55555556, 0.56565657]), 'std_test_score': array([0.05150525, 0.05713994]), 'rank_test_score': array([2, 1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[05-19 17:01:29 | models:predict_with_model] result for validation set:{'Accuracy': 0.36, 'F1': 0.29647058823529415, 'Precision': 0.252, 'Recall': 0.36, 'AUROC': 0.25445933014354066}\n",
      "[05-19 17:01:29 | models:predict_with_model] ======logistic_regression======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "train Counter({'G2': 55, 'G3': 22, 'G1': 22}) test Counter({'G2': 14, 'G1': 6, 'G3': 5})\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[05-19 17:01:32 | models:grid_cv_model] best parameters: {'predictor__C': 0.01}\n",
      "[05-19 17:01:32 | models:predict_with_model] result for CV:{'split0_test_score': array([0.63636364, 0.63636364]), 'split1_test_score': array([0.51515152, 0.48484848]), 'split2_test_score': array([0.51515152, 0.51515152]), 'mean_test_score': array([0.55555556, 0.54545455]), 'std_test_score': array([0.05713994, 0.06546203]), 'rank_test_score': array([1, 2], dtype=int32)}\n",
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:01:32 | models:predict_with_model] result for validation set:{'Accuracy': 0.56, 'F1': 0.40205128205128204, 'Precision': 0.31360000000000005, 'Recall': 0.56, 'AUROC': 0.5}\n",
      "[05-19 17:01:32 | models:predict_with_model] ======logistic_regression======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "train Counter({'G2': 56, 'G1': 23, 'G3': 21}) test Counter({'G2': 13, 'G3': 6, 'G1': 5})\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[05-19 17:01:35 | models:grid_cv_model] best parameters: {'predictor__C': 0.01}\n",
      "[05-19 17:01:35 | models:predict_with_model] result for CV:{'split0_test_score': array([0.52941176, 0.52941176]), 'split1_test_score': array([0.66666667, 0.66666667]), 'split2_test_score': array([0.48484848, 0.48484848]), 'mean_test_score': array([0.56030897, 0.56030897]), 'std_test_score': array([0.07737545, 0.07737545]), 'rank_test_score': array([1, 1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:01:35 | models:predict_with_model] result for validation set:{'Accuracy': 0.5416666666666666, 'F1': 0.38063063063063063, 'Precision': 0.29340277777777773, 'Recall': 0.5416666666666666, 'AUROC': 0.5}\n",
      "[05-19 17:01:35 | cv_models:cv_predict_eval_with_model] ======k_nearest_neighbors======\n",
      "[05-19 17:01:35 | models:predict_with_model] ======k_nearest_neighbors======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "train Counter({'G2': 55, 'G1': 23, 'G3': 21}) test Counter({'G2': 14, 'G3': 6, 'G1': 5})\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:01:37 | models:grid_cv_model] best parameters: {'predictor__n_neighbors': 10, 'predictor__p': 5}\n",
      "[05-19 17:01:37 | models:predict_with_model] result for CV:{'split0_test_score': array([0.51515152, 0.48484848, 0.54545455, 0.48484848, 0.48484848,\n",
      "       0.54545455, 0.51515152, 0.51515152, 0.54545455, 0.48484848,\n",
      "       0.54545455, 0.66666667]), 'split1_test_score': array([0.36363636, 0.33333333, 0.45454545, 0.3030303 , 0.3030303 ,\n",
      "       0.45454545, 0.39393939, 0.33333333, 0.45454545, 0.36363636,\n",
      "       0.36363636, 0.42424242]), 'split2_test_score': array([0.33333333, 0.33333333, 0.45454545, 0.45454545, 0.45454545,\n",
      "       0.48484848, 0.45454545, 0.45454545, 0.48484848, 0.45454545,\n",
      "       0.48484848, 0.45454545]), 'mean_test_score': array([0.4040404 , 0.38383838, 0.48484848, 0.41414141, 0.41414141,\n",
      "       0.49494949, 0.45454545, 0.43434343, 0.49494949, 0.43434343,\n",
      "       0.46464646, 0.51515152]), 'std_test_score': array([0.07953543, 0.07142493, 0.04285496, 0.07953543, 0.07953543,\n",
      "       0.03779452, 0.04948464, 0.07558904, 0.03779452, 0.05150525,\n",
      "       0.07558904, 0.10784928]), 'rank_test_score': array([11, 12,  4,  9,  9,  2,  6,  7,  2,  7,  5,  1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:01:37 | models:predict_with_model] result for validation set:{'Accuracy': 0.52, 'F1': 0.38315789473684203, 'Precision': 0.30333333333333334, 'Recall': 0.52, 'AUROC': 0.4332488038277512}\n",
      "[05-19 17:01:37 | models:predict_with_model] ======k_nearest_neighbors======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Counter({'G2': 55, 'G3': 22, 'G1': 22}) test Counter({'G2': 14, 'G1': 6, 'G3': 5})\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:01:39 | models:grid_cv_model] best parameters: {'predictor__n_neighbors': 10, 'predictor__p': 1}\n",
      "[05-19 17:01:39 | models:predict_with_model] result for CV:{'split0_test_score': array([0.27272727, 0.27272727, 0.3030303 , 0.36363636, 0.3030303 ,\n",
      "       0.27272727, 0.39393939, 0.39393939, 0.39393939, 0.39393939,\n",
      "       0.39393939, 0.45454545]), 'split1_test_score': array([0.36363636, 0.48484848, 0.3030303 , 0.39393939, 0.42424242,\n",
      "       0.39393939, 0.45454545, 0.48484848, 0.48484848, 0.51515152,\n",
      "       0.45454545, 0.42424242]), 'split2_test_score': array([0.27272727, 0.27272727, 0.36363636, 0.36363636, 0.27272727,\n",
      "       0.3030303 , 0.36363636, 0.36363636, 0.24242424, 0.45454545,\n",
      "       0.45454545, 0.39393939]), 'mean_test_score': array([0.3030303 , 0.34343434, 0.32323232, 0.37373737, 0.33333333,\n",
      "       0.32323232, 0.4040404 , 0.41414141, 0.37373737, 0.45454545,\n",
      "       0.43434343, 0.42424242]), 'std_test_score': array([0.04285496, 0.0999949 , 0.02856997, 0.01428499, 0.06546203,\n",
      "       0.05150525, 0.03779452, 0.05150525, 0.0999949 , 0.04948464,\n",
      "       0.02856997, 0.02474232]), 'rank_test_score': array([12,  8, 10,  6,  9, 10,  5,  4,  6,  1,  2,  3], dtype=int32)}\n",
      "[05-19 17:01:39 | models:predict_with_model] result for validation set:{'Accuracy': 0.48, 'F1': 0.4480000000000001, 'Precision': 0.43777777777777777, 'Recall': 0.48, 'AUROC': 0.4281483253588517}\n",
      "[05-19 17:01:39 | models:predict_with_model] ======k_nearest_neighbors======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "train Counter({'G2': 55, 'G3': 22, 'G1': 22}) test Counter({'G2': 14, 'G1': 6, 'G3': 5})\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:01:41 | models:grid_cv_model] best parameters: {'predictor__n_neighbors': 5, 'predictor__p': 2}\n",
      "[05-19 17:01:41 | models:predict_with_model] result for CV:{'split0_test_score': array([0.57575758, 0.57575758, 0.51515152, 0.63636364, 0.66666667,\n",
      "       0.57575758, 0.60606061, 0.60606061, 0.63636364, 0.57575758,\n",
      "       0.60606061, 0.54545455]), 'split1_test_score': array([0.45454545, 0.45454545, 0.36363636, 0.45454545, 0.54545455,\n",
      "       0.48484848, 0.51515152, 0.45454545, 0.48484848, 0.48484848,\n",
      "       0.45454545, 0.45454545]), 'split2_test_score': array([0.42424242, 0.48484848, 0.39393939, 0.54545455, 0.48484848,\n",
      "       0.45454545, 0.54545455, 0.57575758, 0.57575758, 0.51515152,\n",
      "       0.57575758, 0.57575758]), 'mean_test_score': array([0.48484848, 0.50505051, 0.42424242, 0.54545455, 0.56565657,\n",
      "       0.50505051, 0.55555556, 0.54545455, 0.56565657, 0.52525253,\n",
      "       0.54545455, 0.52525253]), 'std_test_score': array([0.06546203, 0.05150525, 0.06546203, 0.07422696, 0.07558904,\n",
      "       0.05150525, 0.03779452, 0.06546203, 0.06226681, 0.03779452,\n",
      "       0.06546203, 0.05150525]), 'rank_test_score': array([11,  9, 12,  4,  1,  9,  3,  4,  1,  7,  4,  7], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:01:41 | models:predict_with_model] result for validation set:{'Accuracy': 0.44, 'F1': 0.38739393939393935, 'Precision': 0.35473684210526313, 'Recall': 0.44, 'AUROC': 0.4393014354066985}\n",
      "[05-19 17:01:41 | models:predict_with_model] ======k_nearest_neighbors======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Counter({'G2': 55, 'G3': 22, 'G1': 22}) test Counter({'G2': 14, 'G1': 6, 'G3': 5})\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:01:43 | models:grid_cv_model] best parameters: {'predictor__n_neighbors': 5, 'predictor__p': 1}\n",
      "[05-19 17:01:43 | models:predict_with_model] result for CV:{'split0_test_score': array([0.39393939, 0.54545455, 0.42424242, 0.60606061, 0.51515152,\n",
      "       0.33333333, 0.51515152, 0.51515152, 0.45454545, 0.54545455,\n",
      "       0.51515152, 0.51515152]), 'split1_test_score': array([0.27272727, 0.24242424, 0.33333333, 0.33333333, 0.33333333,\n",
      "       0.36363636, 0.33333333, 0.33333333, 0.3030303 , 0.36363636,\n",
      "       0.39393939, 0.33333333]), 'split2_test_score': array([0.42424242, 0.36363636, 0.42424242, 0.51515152, 0.54545455,\n",
      "       0.45454545, 0.45454545, 0.48484848, 0.57575758, 0.51515152,\n",
      "       0.51515152, 0.48484848]), 'mean_test_score': array([0.36363636, 0.38383838, 0.39393939, 0.48484848, 0.46464646,\n",
      "       0.38383838, 0.43434343, 0.44444444, 0.44444444, 0.47474747,\n",
      "       0.47474747, 0.44444444]), 'std_test_score': array([0.06546203, 0.12453362, 0.04285496, 0.11338356, 0.09367291,\n",
      "       0.05150525, 0.07558904, 0.07953543, 0.1115693 , 0.07953543,\n",
      "       0.05713994, 0.07953543]), 'rank_test_score': array([12, 11,  9,  1,  4, 10,  8,  6,  5,  2,  2,  6], dtype=int32)}\n",
      "[05-19 17:01:43 | models:predict_with_model] result for validation set:{'Accuracy': 0.44, 'F1': 0.434679802955665, 'Precision': 0.45866666666666667, 'Recall': 0.44, 'AUROC': 0.5818803827751197}\n",
      "[05-19 17:01:43 | models:predict_with_model] ======k_nearest_neighbors======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "train Counter({'G2': 56, 'G1': 23, 'G3': 21}) test Counter({'G2': 13, 'G3': 6, 'G1': 5})\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:01:45 | models:grid_cv_model] best parameters: {'predictor__n_neighbors': 10, 'predictor__p': 5}\n",
      "[05-19 17:01:45 | models:predict_with_model] result for CV:{'split0_test_score': array([0.44117647, 0.41176471, 0.47058824, 0.44117647, 0.44117647,\n",
      "       0.55882353, 0.44117647, 0.44117647, 0.55882353, 0.44117647,\n",
      "       0.47058824, 0.55882353]), 'split1_test_score': array([0.36363636, 0.42424242, 0.36363636, 0.39393939, 0.36363636,\n",
      "       0.36363636, 0.36363636, 0.36363636, 0.42424242, 0.39393939,\n",
      "       0.48484848, 0.48484848]), 'split2_test_score': array([0.3030303 , 0.42424242, 0.42424242, 0.36363636, 0.42424242,\n",
      "       0.48484848, 0.33333333, 0.39393939, 0.42424242, 0.45454545,\n",
      "       0.45454545, 0.45454545]), 'mean_test_score': array([0.36928105, 0.42008318, 0.41948901, 0.39958408, 0.40968509,\n",
      "       0.46910279, 0.37938206, 0.39958408, 0.46910279, 0.42988711,\n",
      "       0.46999406, 0.49940582]), 'std_test_score': array([0.056539  , 0.00588205, 0.0437921 , 0.03190626, 0.03328718,\n",
      "       0.0804589 , 0.04541278, 0.03190626, 0.06344214, 0.02599822,\n",
      "       0.01237829, 0.04379815]), 'rank_test_score': array([12,  6,  7,  9,  8,  4, 11,  9,  3,  5,  2,  1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:01:45 | models:predict_with_model] result for validation set:{'Accuracy': 0.4583333333333333, 'F1': 0.34047619047619043, 'Precision': 0.2708333333333333, 'Recall': 0.4583333333333333, 'AUROC': 0.4262858851674641}\n",
      "[05-19 17:01:45 | cv_models:cv_predict_eval_with_model] ======svc======\n",
      "[05-19 17:01:45 | models:predict_with_model] ======svc======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Counter({'G2': 55, 'G1': 23, 'G3': 21}) test Counter({'G2': 14, 'G3': 6, 'G1': 5})\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:01:46 | models:grid_cv_model] best parameters: {'predictor__C': 0.01, 'predictor__degree': 1}\n",
      "[05-19 17:01:46 | models:predict_with_model] result for CV:{'split0_test_score': array([0.60606061, 0.60606061, 0.60606061, 0.60606061, 0.60606061,\n",
      "       0.60606061, 0.60606061, 0.60606061, 0.60606061]), 'split1_test_score': array([0.51515152, 0.51515152, 0.51515152, 0.51515152, 0.51515152,\n",
      "       0.51515152, 0.51515152, 0.51515152, 0.51515152]), 'split2_test_score': array([0.54545455, 0.54545455, 0.54545455, 0.54545455, 0.54545455,\n",
      "       0.54545455, 0.54545455, 0.54545455, 0.54545455]), 'mean_test_score': array([0.55555556, 0.55555556, 0.55555556, 0.55555556, 0.55555556,\n",
      "       0.55555556, 0.55555556, 0.55555556, 0.55555556]), 'std_test_score': array([0.03779452, 0.03779452, 0.03779452, 0.03779452, 0.03779452,\n",
      "       0.03779452, 0.03779452, 0.03779452, 0.03779452]), 'rank_test_score': array([1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)}\n",
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:01:46 | models:predict_with_model] result for validation set:{'Accuracy': 0.56, 'F1': 0.40205128205128204, 'Precision': 0.31360000000000005, 'Recall': 0.56, 'AUROC': 0.5787751196172249}\n",
      "[05-19 17:01:46 | models:predict_with_model] ======svc======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "train Counter({'G2': 55, 'G3': 22, 'G1': 22}) test Counter({'G2': 14, 'G1': 6, 'G3': 5})\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:01:48 | models:grid_cv_model] best parameters: {'predictor__C': 0.01, 'predictor__degree': 1}\n",
      "[05-19 17:01:48 | models:predict_with_model] result for CV:{'split0_test_score': array([0.57575758, 0.57575758, 0.57575758, 0.57575758, 0.57575758,\n",
      "       0.57575758, 0.57575758, 0.57575758, 0.57575758]), 'split1_test_score': array([0.51515152, 0.51515152, 0.51515152, 0.51515152, 0.51515152,\n",
      "       0.51515152, 0.51515152, 0.51515152, 0.51515152]), 'split2_test_score': array([0.57575758, 0.57575758, 0.57575758, 0.57575758, 0.57575758,\n",
      "       0.57575758, 0.57575758, 0.57575758, 0.57575758]), 'mean_test_score': array([0.55555556, 0.55555556, 0.55555556, 0.55555556, 0.55555556,\n",
      "       0.55555556, 0.55555556, 0.55555556, 0.55555556]), 'std_test_score': array([0.02856997, 0.02856997, 0.02856997, 0.02856997, 0.02856997,\n",
      "       0.02856997, 0.02856997, 0.02856997, 0.02856997]), 'rank_test_score': array([1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:01:48 | models:predict_with_model] result for validation set:{'Accuracy': 0.56, 'F1': 0.40205128205128204, 'Precision': 0.31360000000000005, 'Recall': 0.56, 'AUROC': 0.6385167464114833}\n",
      "[05-19 17:01:48 | models:predict_with_model] ======svc======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "train Counter({'G2': 55, 'G3': 22, 'G1': 22}) test Counter({'G2': 14, 'G1': 6, 'G3': 5})\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:01:50 | models:grid_cv_model] best parameters: {'predictor__C': 0.01, 'predictor__degree': 1}\n",
      "[05-19 17:01:50 | models:predict_with_model] result for CV:{'split0_test_score': array([0.60606061, 0.60606061, 0.60606061, 0.60606061, 0.60606061,\n",
      "       0.60606061, 0.60606061, 0.60606061, 0.60606061]), 'split1_test_score': array([0.48484848, 0.48484848, 0.48484848, 0.48484848, 0.48484848,\n",
      "       0.48484848, 0.48484848, 0.48484848, 0.48484848]), 'split2_test_score': array([0.57575758, 0.57575758, 0.57575758, 0.57575758, 0.57575758,\n",
      "       0.57575758, 0.57575758, 0.57575758, 0.57575758]), 'mean_test_score': array([0.55555556, 0.55555556, 0.55555556, 0.55555556, 0.55555556,\n",
      "       0.55555556, 0.55555556, 0.55555556, 0.55555556]), 'std_test_score': array([0.05150525, 0.05150525, 0.05150525, 0.05150525, 0.05150525,\n",
      "       0.05150525, 0.05150525, 0.05150525, 0.05150525]), 'rank_test_score': array([1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)}\n",
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:01:50 | models:predict_with_model] result for validation set:{'Accuracy': 0.56, 'F1': 0.40205128205128204, 'Precision': 0.31360000000000005, 'Recall': 0.56, 'AUROC': 0.26773205741626793}\n",
      "[05-19 17:01:50 | models:predict_with_model] ======svc======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "train Counter({'G2': 55, 'G3': 22, 'G1': 22}) test Counter({'G2': 14, 'G1': 6, 'G3': 5})\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:01:51 | models:grid_cv_model] best parameters: {'predictor__C': 0.01, 'predictor__degree': 1}\n",
      "[05-19 17:01:51 | models:predict_with_model] result for CV:{'split0_test_score': array([0.63636364, 0.63636364, 0.63636364, 0.63636364, 0.63636364,\n",
      "       0.63636364, 0.63636364, 0.63636364, 0.63636364]), 'split1_test_score': array([0.51515152, 0.51515152, 0.51515152, 0.51515152, 0.51515152,\n",
      "       0.51515152, 0.51515152, 0.51515152, 0.51515152]), 'split2_test_score': array([0.51515152, 0.51515152, 0.51515152, 0.51515152, 0.51515152,\n",
      "       0.51515152, 0.51515152, 0.51515152, 0.51515152]), 'mean_test_score': array([0.55555556, 0.55555556, 0.55555556, 0.55555556, 0.55555556,\n",
      "       0.55555556, 0.55555556, 0.55555556, 0.55555556]), 'std_test_score': array([0.05713994, 0.05713994, 0.05713994, 0.05713994, 0.05713994,\n",
      "       0.05713994, 0.05713994, 0.05713994, 0.05713994]), 'rank_test_score': array([1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:01:52 | models:predict_with_model] result for validation set:{'Accuracy': 0.56, 'F1': 0.40205128205128204, 'Precision': 0.31360000000000005, 'Recall': 0.56, 'AUROC': 0.46922488038277504}\n",
      "[05-19 17:01:52 | models:predict_with_model] ======svc======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "train Counter({'G2': 56, 'G1': 23, 'G3': 21}) test Counter({'G2': 13, 'G3': 6, 'G1': 5})\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:01:53 | models:grid_cv_model] best parameters: {'predictor__C': 0.01, 'predictor__degree': 1}\n",
      "[05-19 17:01:53 | models:predict_with_model] result for CV:{'split0_test_score': array([0.52941176, 0.52941176, 0.52941176, 0.52941176, 0.52941176,\n",
      "       0.52941176, 0.52941176, 0.52941176, 0.52941176]), 'split1_test_score': array([0.66666667, 0.66666667, 0.66666667, 0.66666667, 0.66666667,\n",
      "       0.66666667, 0.66666667, 0.66666667, 0.66666667]), 'split2_test_score': array([0.48484848, 0.48484848, 0.48484848, 0.48484848, 0.48484848,\n",
      "       0.48484848, 0.48484848, 0.48484848, 0.48484848]), 'mean_test_score': array([0.56030897, 0.56030897, 0.56030897, 0.56030897, 0.56030897,\n",
      "       0.56030897, 0.56030897, 0.56030897, 0.56030897]), 'std_test_score': array([0.07737545, 0.07737545, 0.07737545, 0.07737545, 0.07737545,\n",
      "       0.07737545, 0.07737545, 0.07737545, 0.07737545]), 'rank_test_score': array([1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)}\n",
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:01:53 | models:predict_with_model] result for validation set:{'Accuracy': 0.5416666666666666, 'F1': 0.38063063063063063, 'Precision': 0.29340277777777773, 'Recall': 0.5416666666666666, 'AUROC': 0.6745746943115365}\n",
      "[05-19 17:01:53 | cv_models:cv_predict_eval_with_model] ======random_forest======\n",
      "[05-19 17:01:53 | models:predict_with_model] ======random_forest======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "train Counter({'G2': 55, 'G1': 23, 'G3': 21}) test Counter({'G2': 14, 'G3': 6, 'G1': 5})\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:02:26 | models:grid_cv_model] best parameters: {'predictor__max_depth': 10, 'predictor__max_features': 'auto', 'predictor__min_samples_leaf': 1, 'predictor__n_estimators': 1000}\n",
      "[05-19 17:02:26 | models:predict_with_model] result for CV:{'split0_test_score': array([0.51515152, 0.51515152, 0.51515152, 0.54545455, 0.54545455,\n",
      "       0.57575758, 0.57575758, 0.57575758, 0.51515152, 0.51515152,\n",
      "       0.51515152, 0.54545455, 0.54545455, 0.57575758, 0.57575758,\n",
      "       0.57575758]), 'split1_test_score': array([0.48484848, 0.51515152, 0.48484848, 0.51515152, 0.54545455,\n",
      "       0.51515152, 0.51515152, 0.51515152, 0.48484848, 0.51515152,\n",
      "       0.48484848, 0.51515152, 0.54545455, 0.51515152, 0.51515152,\n",
      "       0.51515152]), 'split2_test_score': array([0.54545455, 0.54545455, 0.57575758, 0.60606061, 0.57575758,\n",
      "       0.54545455, 0.57575758, 0.54545455, 0.54545455, 0.54545455,\n",
      "       0.57575758, 0.60606061, 0.57575758, 0.54545455, 0.57575758,\n",
      "       0.54545455]), 'mean_test_score': array([0.51515152, 0.52525253, 0.52525253, 0.55555556, 0.55555556,\n",
      "       0.54545455, 0.55555556, 0.54545455, 0.51515152, 0.52525253,\n",
      "       0.52525253, 0.55555556, 0.55555556, 0.54545455, 0.55555556,\n",
      "       0.54545455]), 'std_test_score': array([0.02474232, 0.01428499, 0.03779452, 0.03779452, 0.01428499,\n",
      "       0.02474232, 0.02856997, 0.02474232, 0.02474232, 0.01428499,\n",
      "       0.03779452, 0.03779452, 0.01428499, 0.02474232, 0.02856997,\n",
      "       0.02474232]), 'rank_test_score': array([15, 11, 11,  1,  1,  7,  1,  7, 15, 11, 11,  1,  1,  7,  1,  7],\n",
      "      dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:02:28 | models:predict_with_model] result for validation set:{'Accuracy': 0.56, 'F1': 0.4126315789473684, 'Precision': 0.3266666666666667, 'Recall': 0.56, 'AUROC': 0.4390909090909091}\n",
      "[05-19 17:02:28 | models:predict_with_model] ======random_forest======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Counter({'G2': 55, 'G3': 22, 'G1': 22}) test Counter({'G2': 14, 'G1': 6, 'G3': 5})\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:03:00 | models:grid_cv_model] best parameters: {'predictor__max_depth': 10, 'predictor__max_features': 'auto', 'predictor__min_samples_leaf': 1, 'predictor__n_estimators': 100}\n",
      "[05-19 17:03:00 | models:predict_with_model] result for CV:{'split0_test_score': array([0.48484848, 0.48484848, 0.48484848, 0.48484848, 0.51515152,\n",
      "       0.51515152, 0.48484848, 0.48484848, 0.48484848, 0.48484848,\n",
      "       0.48484848, 0.48484848, 0.51515152, 0.51515152, 0.48484848,\n",
      "       0.48484848]), 'split1_test_score': array([0.51515152, 0.51515152, 0.51515152, 0.51515152, 0.51515152,\n",
      "       0.51515152, 0.51515152, 0.51515152, 0.51515152, 0.51515152,\n",
      "       0.51515152, 0.51515152, 0.51515152, 0.51515152, 0.51515152,\n",
      "       0.51515152]), 'split2_test_score': array([0.60606061, 0.60606061, 0.60606061, 0.57575758, 0.57575758,\n",
      "       0.57575758, 0.57575758, 0.57575758, 0.60606061, 0.60606061,\n",
      "       0.60606061, 0.57575758, 0.57575758, 0.57575758, 0.57575758,\n",
      "       0.57575758]), 'mean_test_score': array([0.53535354, 0.53535354, 0.53535354, 0.52525253, 0.53535354,\n",
      "       0.53535354, 0.52525253, 0.52525253, 0.53535354, 0.53535354,\n",
      "       0.53535354, 0.52525253, 0.53535354, 0.53535354, 0.52525253,\n",
      "       0.52525253]), 'std_test_score': array([0.05150525, 0.05150525, 0.05150525, 0.03779452, 0.02856997,\n",
      "       0.02856997, 0.03779452, 0.03779452, 0.05150525, 0.05150525,\n",
      "       0.05150525, 0.03779452, 0.02856997, 0.02856997, 0.03779452,\n",
      "       0.03779452]), 'rank_test_score': array([ 1,  1,  1, 11,  1,  1, 11, 11,  1,  1,  1, 11,  1,  1, 11, 11],\n",
      "      dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:03:00 | models:predict_with_model] result for validation set:{'Accuracy': 0.64, 'F1': 0.559021879021879, 'Precision': 0.7808695652173913, 'Recall': 0.64, 'AUROC': 0.5469665071770334}\n",
      "[05-19 17:03:00 | models:predict_with_model] ======random_forest======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "train Counter({'G2': 55, 'G3': 22, 'G1': 22}) test Counter({'G2': 14, 'G1': 6, 'G3': 5})\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.9s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:03:33 | models:grid_cv_model] best parameters: {'predictor__max_depth': 10, 'predictor__max_features': 'auto', 'predictor__min_samples_leaf': 1, 'predictor__n_estimators': 500}\n",
      "[05-19 17:03:33 | models:predict_with_model] result for CV:{'split0_test_score': array([0.60606061, 0.63636364, 0.63636364, 0.60606061, 0.63636364,\n",
      "       0.63636364, 0.63636364, 0.63636364, 0.60606061, 0.63636364,\n",
      "       0.63636364, 0.60606061, 0.63636364, 0.63636364, 0.63636364,\n",
      "       0.63636364]), 'split1_test_score': array([0.48484848, 0.48484848, 0.51515152, 0.48484848, 0.48484848,\n",
      "       0.48484848, 0.48484848, 0.48484848, 0.48484848, 0.48484848,\n",
      "       0.51515152, 0.48484848, 0.48484848, 0.48484848, 0.48484848,\n",
      "       0.48484848]), 'split2_test_score': array([0.57575758, 0.57575758, 0.57575758, 0.57575758, 0.57575758,\n",
      "       0.54545455, 0.54545455, 0.54545455, 0.57575758, 0.57575758,\n",
      "       0.57575758, 0.57575758, 0.57575758, 0.54545455, 0.54545455,\n",
      "       0.54545455]), 'mean_test_score': array([0.55555556, 0.56565657, 0.57575758, 0.55555556, 0.56565657,\n",
      "       0.55555556, 0.55555556, 0.55555556, 0.55555556, 0.56565657,\n",
      "       0.57575758, 0.55555556, 0.56565657, 0.55555556, 0.55555556,\n",
      "       0.55555556]), 'std_test_score': array([0.05150525, 0.06226681, 0.04948464, 0.05150525, 0.06226681,\n",
      "       0.06226681, 0.06226681, 0.06226681, 0.05150525, 0.06226681,\n",
      "       0.04948464, 0.05150525, 0.06226681, 0.06226681, 0.06226681,\n",
      "       0.06226681]), 'rank_test_score': array([7, 3, 1, 7, 3, 7, 7, 7, 7, 3, 1, 7, 3, 7, 7, 7], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:03:34 | models:predict_with_model] result for validation set:{'Accuracy': 0.48, 'F1': 0.36324324324324325, 'Precision': 0.29217391304347823, 'Recall': 0.48, 'AUROC': 0.3441100478468899}\n",
      "[05-19 17:03:34 | models:predict_with_model] ======random_forest======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "train Counter({'G2': 55, 'G3': 22, 'G1': 22}) test Counter({'G2': 14, 'G1': 6, 'G3': 5})\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:04:07 | models:grid_cv_model] best parameters: {'predictor__max_depth': 10, 'predictor__max_features': 'auto', 'predictor__min_samples_leaf': 4, 'predictor__n_estimators': 1000}\n",
      "[05-19 17:04:07 | models:predict_with_model] result for CV:{'split0_test_score': array([0.51515152, 0.54545455, 0.54545455, 0.54545455, 0.48484848,\n",
      "       0.48484848, 0.54545455, 0.57575758, 0.51515152, 0.54545455,\n",
      "       0.54545455, 0.54545455, 0.48484848, 0.48484848, 0.54545455,\n",
      "       0.57575758]), 'split1_test_score': array([0.45454545, 0.48484848, 0.48484848, 0.48484848, 0.48484848,\n",
      "       0.48484848, 0.48484848, 0.48484848, 0.45454545, 0.48484848,\n",
      "       0.48484848, 0.48484848, 0.48484848, 0.48484848, 0.48484848,\n",
      "       0.48484848]), 'split2_test_score': array([0.51515152, 0.51515152, 0.51515152, 0.51515152, 0.51515152,\n",
      "       0.51515152, 0.51515152, 0.51515152, 0.51515152, 0.51515152,\n",
      "       0.51515152, 0.51515152, 0.51515152, 0.51515152, 0.51515152,\n",
      "       0.51515152]), 'mean_test_score': array([0.49494949, 0.51515152, 0.51515152, 0.51515152, 0.49494949,\n",
      "       0.49494949, 0.51515152, 0.52525253, 0.49494949, 0.51515152,\n",
      "       0.51515152, 0.51515152, 0.49494949, 0.49494949, 0.51515152,\n",
      "       0.52525253]), 'std_test_score': array([0.02856997, 0.02474232, 0.02474232, 0.02474232, 0.01428499,\n",
      "       0.01428499, 0.02474232, 0.03779452, 0.02856997, 0.02474232,\n",
      "       0.02474232, 0.02474232, 0.01428499, 0.01428499, 0.02474232,\n",
      "       0.03779452]), 'rank_test_score': array([11,  3,  3,  3, 11, 11,  3,  1, 11,  3,  3,  3, 11, 11,  3,  1],\n",
      "      dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:04:09 | models:predict_with_model] result for validation set:{'Accuracy': 0.56, 'F1': 0.40205128205128204, 'Precision': 0.31360000000000005, 'Recall': 0.56, 'AUROC': 0.6057416267942584}\n",
      "[05-19 17:04:09 | models:predict_with_model] ======random_forest======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Counter({'G2': 56, 'G1': 23, 'G3': 21}) test Counter({'G2': 13, 'G3': 6, 'G1': 5})\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:04:41 | models:grid_cv_model] best parameters: {'predictor__max_depth': 10, 'predictor__max_features': 'auto', 'predictor__min_samples_leaf': 1, 'predictor__n_estimators': 100}\n",
      "[05-19 17:04:41 | models:predict_with_model] result for CV:{'split0_test_score': array([0.52941176, 0.52941176, 0.52941176, 0.52941176, 0.52941176,\n",
      "       0.52941176, 0.52941176, 0.52941176, 0.52941176, 0.52941176,\n",
      "       0.52941176, 0.52941176, 0.52941176, 0.52941176, 0.52941176,\n",
      "       0.52941176]), 'split1_test_score': array([0.60606061, 0.51515152, 0.57575758, 0.51515152, 0.57575758,\n",
      "       0.54545455, 0.60606061, 0.60606061, 0.60606061, 0.51515152,\n",
      "       0.57575758, 0.51515152, 0.57575758, 0.54545455, 0.60606061,\n",
      "       0.60606061]), 'split2_test_score': array([0.48484848, 0.48484848, 0.48484848, 0.48484848, 0.48484848,\n",
      "       0.48484848, 0.48484848, 0.48484848, 0.48484848, 0.48484848,\n",
      "       0.48484848, 0.48484848, 0.48484848, 0.48484848, 0.48484848,\n",
      "       0.48484848]), 'mean_test_score': array([0.54010695, 0.50980392, 0.53000594, 0.50980392, 0.53000594,\n",
      "       0.51990493, 0.54010695, 0.54010695, 0.54010695, 0.50980392,\n",
      "       0.53000594, 0.50980392, 0.53000594, 0.51990493, 0.54010695,\n",
      "       0.54010695]), 'std_test_score': array([0.0500592 , 0.01858169, 0.03711586, 0.01858169, 0.03711586,\n",
      "       0.02563927, 0.0500592 , 0.0500592 , 0.0500592 , 0.01858169,\n",
      "       0.03711586, 0.01858169, 0.03711586, 0.02563927, 0.0500592 ,\n",
      "       0.0500592 ]), 'rank_test_score': array([ 1, 13,  7, 13,  7, 11,  1,  1,  1, 13,  7, 13,  7, 11,  1,  1],\n",
      "      dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:04:41 | models:predict_with_model] result for validation set:{'Accuracy': 0.5416666666666666, 'F1': 0.38063063063063063, 'Precision': 0.29340277777777773, 'Recall': 0.5416666666666666, 'AUROC': 0.5016613503455608}\n",
      "[05-19 17:04:41 | cv_models:cv_predict_eval_with_model] ======mlp======\n",
      "[05-19 17:04:41 | models:predict_with_model] ======mlp======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Counter({'G2': 55, 'G1': 23, 'G3': 21}) test Counter({'G2': 14, 'G3': 6, 'G1': 5})\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.9s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.9s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:04:53 | models:grid_cv_model] best parameters: {'predictor__hidden_layer_sizes': (400, 40)}\n",
      "[05-19 17:04:53 | models:predict_with_model] result for CV:{'split0_test_score': array([0.24242424, 0.42424242, 0.36363636, 0.39393939]), 'split1_test_score': array([0.3030303 , 0.39393939, 0.48484848, 0.48484848]), 'split2_test_score': array([0.48484848, 0.57575758, 0.3030303 , 0.54545455]), 'mean_test_score': array([0.34343434, 0.46464646, 0.38383838, 0.47474747]), 'std_test_score': array([0.1030105 , 0.07953543, 0.07558904, 0.06226681]), 'rank_test_score': array([4, 2, 3, 1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:04:55 | models:predict_with_model] result for validation set:{'Accuracy': 0.36, 'F1': 0.3526018808777429, 'Precision': 0.34666666666666673, 'Recall': 0.36, 'AUROC': 0.404421052631579}\n",
      "[05-19 17:04:55 | models:predict_with_model] ======mlp======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.8s\n",
      "train Counter({'G2': 55, 'G3': 22, 'G1': 22}) test Counter({'G2': 14, 'G1': 6, 'G3': 5})\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.3s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.3s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:05:05 | models:grid_cv_model] best parameters: {'predictor__hidden_layer_sizes': (400, 40)}\n",
      "[05-19 17:05:05 | models:predict_with_model] result for CV:{'split0_test_score': array([0.36363636, 0.3030303 , 0.3030303 , 0.51515152]), 'split1_test_score': array([0.36363636, 0.24242424, 0.27272727, 0.42424242]), 'split2_test_score': array([0.24242424, 0.39393939, 0.45454545, 0.33333333]), 'mean_test_score': array([0.32323232, 0.31313131, 0.34343434, 0.42424242]), 'std_test_score': array([0.05713994, 0.06226681, 0.07953543, 0.07422696]), 'rank_test_score': array([3, 4, 2, 1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:05:07 | models:predict_with_model] result for validation set:{'Accuracy': 0.52, 'F1': 0.38315789473684203, 'Precision': 0.30333333333333334, 'Recall': 0.52, 'AUROC': 0.545291866028708}\n",
      "[05-19 17:05:07 | models:predict_with_model] ======mlp======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.4s\n",
      "train Counter({'G2': 55, 'G3': 22, 'G1': 22}) test Counter({'G2': 14, 'G1': 6, 'G3': 5})\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:05:18 | models:grid_cv_model] best parameters: {'predictor__hidden_layer_sizes': (400, 40)}\n",
      "[05-19 17:05:18 | models:predict_with_model] result for CV:{'split0_test_score': array([0.3030303 , 0.54545455, 0.57575758, 0.60606061]), 'split1_test_score': array([0.39393939, 0.36363636, 0.36363636, 0.51515152]), 'split2_test_score': array([0.36363636, 0.54545455, 0.42424242, 0.60606061]), 'mean_test_score': array([0.35353535, 0.48484848, 0.45454545, 0.57575758]), 'std_test_score': array([0.03779452, 0.08570991, 0.08920971, 0.04285496]), 'rank_test_score': array([4, 2, 3, 1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   2.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:05:20 | models:predict_with_model] result for validation set:{'Accuracy': 0.24, 'F1': 0.22399999999999998, 'Precision': 0.21, 'Recall': 0.24, 'AUROC': 0.3547464114832536}\n",
      "[05-19 17:05:20 | models:predict_with_model] ======mlp======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   2.3s\n",
      "train Counter({'G2': 55, 'G3': 22, 'G1': 22}) test Counter({'G2': 14, 'G1': 6, 'G3': 5})\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.9s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   1.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.3s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.5s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.5s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:05:31 | models:grid_cv_model] best parameters: {'predictor__hidden_layer_sizes': (400, 40)}\n",
      "[05-19 17:05:31 | models:predict_with_model] result for CV:{'split0_test_score': array([0.33333333, 0.45454545, 0.36363636, 0.42424242]), 'split1_test_score': array([0.42424242, 0.3030303 , 0.3030303 , 0.51515152]), 'split2_test_score': array([0.42424242, 0.3030303 , 0.39393939, 0.60606061]), 'mean_test_score': array([0.39393939, 0.35353535, 0.35353535, 0.51515152]), 'std_test_score': array([0.04285496, 0.07142493, 0.03779452, 0.07422696]), 'rank_test_score': array([2, 3, 3, 1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:05:33 | models:predict_with_model] result for validation set:{'Accuracy': 0.56, 'F1': 0.45065637065637054, 'Precision': 0.4165217391304348, 'Recall': 0.56, 'AUROC': 0.5855598086124402}\n",
      "[05-19 17:05:33 | models:predict_with_model] ======mlp======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.6s\n",
      "train Counter({'G2': 56, 'G1': 23, 'G3': 21}) test Counter({'G2': 13, 'G3': 6, 'G1': 5})\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.6s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   1.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.8s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   2.0s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   2.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:05:44 | models:grid_cv_model] best parameters: {'predictor__hidden_layer_sizes': (100, 20)}\n",
      "[05-19 17:05:44 | models:predict_with_model] result for CV:{'split0_test_score': array([0.20588235, 0.47058824, 0.32352941, 0.47058824]), 'split1_test_score': array([0.51515152, 0.54545455, 0.39393939, 0.42424242]), 'split2_test_score': array([0.3030303 , 0.39393939, 0.33333333, 0.45454545]), 'mean_test_score': array([0.34135472, 0.46999406, 0.35026738, 0.44979204]), 'std_test_score': array([0.1291341 , 0.06185723, 0.03113907, 0.01921683]), 'rank_test_score': array([4, 1, 3, 2], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:05:45 | models:predict_with_model] result for validation set:{'Accuracy': 0.4583333333333333, 'F1': 0.3885416666666666, 'Precision': 0.34758771929824556, 'Recall': 0.4583333333333333, 'AUROC': 0.363835725677831}\n",
      "[05-19 17:05:45 | cv_models:cv_predict_eval_with_model] ======xgboost======\n",
      "[05-19 17:05:45 | models:predict_with_model] ======xgboost======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "train Counter({'G2': 55, 'G1': 23, 'G3': 21}) test Counter({'G2': 14, 'G3': 6, 'G1': 5})\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:05:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.2s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:05:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.2s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:05:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.1s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:05:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.9s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:05:49] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.1s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:05:50] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   1.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:05:51] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:05:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:05:53] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:05:54] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:05:54] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:05:55] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:05:55] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[05-19 17:05:57 | models:grid_cv_model] best parameters: {'predictor__learning_rate': 0.01, 'predictor__n_estimators': 100, 'predictor__reg_alpha': 10}\n",
      "[05-19 17:05:57 | models:predict_with_model] result for CV:{'split0_test_score': array([0.54545455, 0.6969697 , 0.51515152, 0.66666667]), 'split1_test_score': array([0.45454545, 0.42424242, 0.45454545, 0.45454545]), 'split2_test_score': array([0.39393939, 0.54545455, 0.51515152, 0.54545455]), 'mean_test_score': array([0.46464646, 0.55555556, 0.49494949, 0.55555556]), 'std_test_score': array([0.06226681, 0.1115693 , 0.02856997, 0.08689217]), 'rank_test_score': array([4, 1, 3, 2], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:05:57] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:05:59 | models:predict_with_model] result for validation set:{'Accuracy': 0.56, 'F1': 0.40205128205128204, 'Precision': 0.31360000000000005, 'Recall': 0.56, 'AUROC': 0.37950239234449756}\n",
      "[05-19 17:05:59 | models:predict_with_model] ======xgboost======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.9s\n",
      "train Counter({'G2': 55, 'G3': 22, 'G1': 22}) test Counter({'G2': 14, 'G1': 6, 'G3': 5})\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:05:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.1s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:06:00] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.2s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:06:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.2s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:06:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.9s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:06:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.2s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:06:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   1.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:06:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:06:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:06:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:06:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:06:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:06:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:06:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[05-19 17:06:10 | models:grid_cv_model] best parameters: {'predictor__learning_rate': 0.1, 'predictor__n_estimators': 100, 'predictor__reg_alpha': 10}\n",
      "[05-19 17:06:10 | models:predict_with_model] result for CV:{'split0_test_score': array([0.51515152, 0.48484848, 0.51515152, 0.57575758]), 'split1_test_score': array([0.60606061, 0.51515152, 0.51515152, 0.51515152]), 'split2_test_score': array([0.51515152, 0.57575758, 0.54545455, 0.57575758]), 'mean_test_score': array([0.54545455, 0.52525253, 0.52525253, 0.55555556]), 'std_test_score': array([0.04285496, 0.03779452, 0.01428499, 0.02856997]), 'rank_test_score': array([2, 3, 3, 1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:06:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:06:11 | models:predict_with_model] result for validation set:{'Accuracy': 0.52, 'F1': 0.38315789473684203, 'Precision': 0.30333333333333334, 'Recall': 0.52, 'AUROC': 0.4640095693779904}\n",
      "[05-19 17:06:11 | models:predict_with_model] ======xgboost======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "train Counter({'G2': 55, 'G3': 22, 'G1': 22}) test Counter({'G2': 14, 'G1': 6, 'G3': 5})\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:06:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.1s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:06:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.1s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:06:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.1s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:06:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.9s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:06:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   1.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:06:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   1.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:06:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:06:18] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:06:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:06:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:06:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:06:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:06:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[05-19 17:06:22 | models:grid_cv_model] best parameters: {'predictor__learning_rate': 0.1, 'predictor__n_estimators': 100, 'predictor__reg_alpha': 1}\n",
      "[05-19 17:06:22 | models:predict_with_model] result for CV:{'split0_test_score': array([0.51515152, 0.57575758, 0.51515152, 0.57575758]), 'split1_test_score': array([0.51515152, 0.45454545, 0.60606061, 0.45454545]), 'split2_test_score': array([0.60606061, 0.57575758, 0.54545455, 0.57575758]), 'mean_test_score': array([0.54545455, 0.53535354, 0.55555556, 0.53535354]), 'std_test_score': array([0.04285496, 0.05713994, 0.03779452, 0.05713994]), 'rank_test_score': array([2, 3, 1, 3], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:06:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[05-19 17:06:24 | models:predict_with_model] result for validation set:{'Accuracy': 0.44, 'F1': 0.35200000000000004, 'Precision': 0.29333333333333333, 'Recall': 0.44, 'AUROC': 0.3016076555023923}\n",
      "[05-19 17:06:24 | models:predict_with_model] ======xgboost======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.2s\n",
      "train Counter({'G2': 55, 'G3': 22, 'G1': 22}) test Counter({'G2': 14, 'G1': 6, 'G3': 5})\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:06:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.1s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:06:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.2s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:06:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.1s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:06:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   1.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:06:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.1s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:06:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.9s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:06:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:06:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:06:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:06:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:06:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:06:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:06:34] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[05-19 17:06:35 | models:grid_cv_model] best parameters: {'predictor__learning_rate': 0.1, 'predictor__n_estimators': 100, 'predictor__reg_alpha': 10}\n",
      "[05-19 17:06:35 | models:predict_with_model] result for CV:{'split0_test_score': array([0.45454545, 0.60606061, 0.51515152, 0.63636364]), 'split1_test_score': array([0.42424242, 0.51515152, 0.42424242, 0.51515152]), 'split2_test_score': array([0.45454545, 0.51515152, 0.48484848, 0.51515152]), 'mean_test_score': array([0.44444444, 0.54545455, 0.47474747, 0.55555556]), 'std_test_score': array([0.01428499, 0.04285496, 0.03779452, 0.05713994]), 'rank_test_score': array([4, 2, 3, 1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:06:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:06:35 | models:predict_with_model] result for validation set:{'Accuracy': 0.56, 'F1': 0.40205128205128204, 'Precision': 0.31360000000000005, 'Recall': 0.56, 'AUROC': 0.4696650717703349}\n",
      "[05-19 17:06:35 | models:predict_with_model] ======xgboost======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "train Counter({'G2': 56, 'G1': 23, 'G3': 21}) test Counter({'G2': 13, 'G3': 6, 'G1': 5})\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:06:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.1s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:06:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.2s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:06:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.1s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:06:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.1s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:06:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:06:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   1.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:06:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:06:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:06:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:06:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:06:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:06:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:06:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[05-19 17:06:47 | models:grid_cv_model] best parameters: {'predictor__learning_rate': 0.1, 'predictor__n_estimators': 100, 'predictor__reg_alpha': 10}\n",
      "[05-19 17:06:47 | models:predict_with_model] result for CV:{'split0_test_score': array([0.47058824, 0.52941176, 0.5       , 0.52941176]), 'split1_test_score': array([0.48484848, 0.57575758, 0.60606061, 0.57575758]), 'split2_test_score': array([0.45454545, 0.39393939, 0.42424242, 0.48484848]), 'mean_test_score': array([0.46999406, 0.49970291, 0.51010101, 0.53000594]), 'std_test_score': array([0.01237829, 0.0771424 , 0.07456981, 0.03711586]), 'rank_test_score': array([4, 3, 2, 1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:06:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:06:47 | models:predict_with_model] result for validation set:{'Accuracy': 0.5416666666666666, 'F1': 0.38063063063063063, 'Precision': 0.29340277777777773, 'Recall': 0.5416666666666666, 'AUROC': 0.34883926989190145}\n",
      "[05-19 17:06:47 | application_cross_validation:ApplicationCV] Saved results to /labs/gevaertlab/users/yyhhli/code/vae/applications/results/VAE3D32AUG_70/StfHisGrade.cv_result_dict.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "{'__dict': {}, 'logistic_regression': {'Accuracy': [0.56, 0.56, 0.36, 0.56, 0.5416666666666666], 'F1': [0.4237837837837838, 0.40205128205128204, 0.29647058823529415, 0.40205128205128204, 0.38063063063063063], 'Precision': [0.3408695652173913, 0.31360000000000005, 0.252, 0.31360000000000005, 0.29340277777777773], 'Recall': [0.56, 0.56, 0.36, 0.56, 0.5416666666666666], 'AUROC': [0.4582105263157895, 0.5, 0.25445933014354066, 0.5, 0.5]}, 'k_nearest_neighbors': {'Accuracy': [0.52, 0.48, 0.44, 0.44, 0.4583333333333333], 'F1': [0.38315789473684203, 0.4480000000000001, 0.38739393939393935, 0.434679802955665, 0.34047619047619043], 'Precision': [0.30333333333333334, 0.43777777777777777, 0.35473684210526313, 0.45866666666666667, 0.2708333333333333], 'Recall': [0.52, 0.48, 0.44, 0.44, 0.4583333333333333], 'AUROC': [0.4332488038277512, 0.4281483253588517, 0.4393014354066985, 0.5818803827751197, 0.4262858851674641]}, 'svc': {'Accuracy': [0.56, 0.56, 0.56, 0.56, 0.5416666666666666], 'F1': [0.40205128205128204, 0.40205128205128204, 0.40205128205128204, 0.40205128205128204, 0.38063063063063063], 'Precision': [0.31360000000000005, 0.31360000000000005, 0.31360000000000005, 0.31360000000000005, 0.29340277777777773], 'Recall': [0.56, 0.56, 0.56, 0.56, 0.5416666666666666], 'AUROC': [0.5787751196172249, 0.6385167464114833, 0.26773205741626793, 0.46922488038277504, 0.6745746943115365]}, 'random_forest': {'Accuracy': [0.56, 0.64, 0.48, 0.56, 0.5416666666666666], 'F1': [0.4126315789473684, 0.559021879021879, 0.36324324324324325, 0.40205128205128204, 0.38063063063063063], 'Precision': [0.3266666666666667, 0.7808695652173913, 0.29217391304347823, 0.31360000000000005, 0.29340277777777773], 'Recall': [0.56, 0.64, 0.48, 0.56, 0.5416666666666666], 'AUROC': [0.4390909090909091, 0.5469665071770334, 0.3441100478468899, 0.6057416267942584, 0.5016613503455608]}, 'mlp': {'Accuracy': [0.36, 0.52, 0.24, 0.56, 0.4583333333333333], 'F1': [0.3526018808777429, 0.38315789473684203, 0.22399999999999998, 0.45065637065637054, 0.3885416666666666], 'Precision': [0.34666666666666673, 0.30333333333333334, 0.21, 0.4165217391304348, 0.34758771929824556], 'Recall': [0.36, 0.52, 0.24, 0.56, 0.4583333333333333], 'AUROC': [0.404421052631579, 0.545291866028708, 0.3547464114832536, 0.5855598086124402, 0.363835725677831]}, 'xgboost': {'Accuracy': [0.56, 0.52, 0.44, 0.56, 0.5416666666666666], 'F1': [0.40205128205128204, 0.38315789473684203, 0.35200000000000004, 0.40205128205128204, 0.38063063063063063], 'Precision': [0.31360000000000005, 0.30333333333333334, 0.29333333333333333, 0.31360000000000005, 0.29340277777777773], 'Recall': [0.56, 0.52, 0.44, 0.56, 0.5416666666666666], 'AUROC': [0.37950239234449756, 0.4640095693779904, 0.3016076555023923, 0.4696650717703349, 0.34883926989190145]}}\n",
      "======= Predicting StfNStage with model version 70 =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:06:51 | patch_ds:LIDCPatchAugDataset] patient split: train:699, val:88, test:88\n",
      "[05-19 17:06:51 | patch_ds:LNDbPatch32AugDataset] patient split: train:168, val:22, test:22\n",
      "[05-19 17:06:51 | patch_stanfordradiogenomics:StanfordRadiogenomicsPatchAugDataset] patient split: train:100, test:43\n",
      "[05-19 17:06:51 | export:  Exporter] initializing embeddings\n",
      "[05-19 17:06:55 | patch_ds:LIDCPatchAugDataset] patient split: train:699, val:88, test:88\n",
      "[05-19 17:06:55 | patch_ds:LNDbPatch32AugDataset] patient split: train:168, val:22, test:22\n",
      "[05-19 17:06:55 | patch_stanfordradiogenomics:StanfordRadiogenomicsPatchAugDataset] patient split: train:100, test:43\n",
      "[05-19 17:06:56 | application_cross_validation:ApplicationCV] -----CV prediction for task StfNStage-----\n",
      "[05-19 17:06:56 | application:ApplicationCV] Loading best hparams ...\n",
      "[05-19 17:06:56 | cv_models:cv_predict_task] models used ['logistic_regression', 'k_nearest_neighbors', 'svc', 'random_forest', 'mlp', 'xgboost']\n",
      "[05-19 17:06:56 | cv_models:cv_predict_task] Before transform: X shape = train:(100, 4096), val:(43, 4096); Y shape = train:(100,), val:(43,)\n",
      "[05-19 17:06:56 | models:data_summary] X shape = train:(100, 4096), val:(43, 4096); Y shape = train:(100,), val:(43,)\n",
      "Y classes = \n",
      " train: \n",
      "  value count\n",
      "0    N0    80\n",
      "1   N1+    20; \n",
      " val: \n",
      "  value count\n",
      "0    N0    35\n",
      "1   N1+     8\n",
      "[05-19 17:06:56 | cv_models:cv_predict_eval_with_model] ======logistic_regression======\n",
      "[05-19 17:06:56 | models:predict_with_model] ======logistic_regression======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | 4.0 secs.\n",
      "initializing | 8.0 secs.\n",
      "train Counter({'N0': 92, 'N1+': 22}) test Counter({'N0': 23, 'N1+': 6})\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[05-19 17:06:58 | models:grid_cv_model] best parameters: {'predictor__C': 0.01}\n",
      "[05-19 17:06:58 | models:predict_with_model] result for CV:{'split0_test_score': array([0.89473684, 0.89473684]), 'split1_test_score': array([0.78947368, 0.78947368]), 'split2_test_score': array([0.73684211, 0.73684211]), 'mean_test_score': array([0.80701754, 0.80701754]), 'std_test_score': array([0.06564311, 0.06564311]), 'rank_test_score': array([1, 1], dtype=int32)}\n",
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:06:58 | models:predict_with_model] result for validation set:{'Accuracy': 0.7931034482758621, 'F1': 0.7015915119363395, 'Precision': 0.6290130796670631, 'Recall': 0.7931034482758621, 'AUROC': 0.5}\n",
      "[05-19 17:06:58 | models:predict_with_model] ======logistic_regression======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "train Counter({'N0': 92, 'N1+': 22}) test Counter({'N0': 23, 'N1+': 6})\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[05-19 17:07:00 | models:grid_cv_model] best parameters: {'predictor__C': 0.01}\n",
      "[05-19 17:07:00 | models:predict_with_model] result for CV:{'split0_test_score': array([0.76315789, 0.76315789]), 'split1_test_score': array([0.89473684, 0.89473684]), 'split2_test_score': array([0.76315789, 0.76315789]), 'mean_test_score': array([0.80701754, 0.80701754]), 'std_test_score': array([0.06202691, 0.06202691]), 'rank_test_score': array([1, 1], dtype=int32)}\n",
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:07:00 | models:predict_with_model] result for validation set:{'Accuracy': 0.7931034482758621, 'F1': 0.7015915119363395, 'Precision': 0.6290130796670631, 'Recall': 0.7931034482758621, 'AUROC': 0.5}\n",
      "[05-19 17:07:00 | models:predict_with_model] ======logistic_regression======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "train Counter({'N0': 92, 'N1+': 22}) test Counter({'N0': 23, 'N1+': 6})\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[05-19 17:07:02 | models:grid_cv_model] best parameters: {'predictor__C': 0.01}\n",
      "[05-19 17:07:02 | models:predict_with_model] result for CV:{'split0_test_score': array([0.76315789, 0.76315789]), 'split1_test_score': array([0.81578947, 0.81578947]), 'split2_test_score': array([0.84210526, 0.78947368]), 'mean_test_score': array([0.80701754, 0.78947368]), 'std_test_score': array([0.03282156, 0.02148675]), 'rank_test_score': array([1, 2], dtype=int32)}\n",
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:07:02 | models:predict_with_model] result for validation set:{'Accuracy': 0.7931034482758621, 'F1': 0.7015915119363395, 'Precision': 0.6290130796670631, 'Recall': 0.7931034482758621, 'AUROC': 0.5}\n",
      "[05-19 17:07:02 | models:predict_with_model] ======logistic_regression======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "train Counter({'N0': 92, 'N1+': 23}) test Counter({'N0': 23, 'N1+': 5})\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[05-19 17:07:04 | models:grid_cv_model] best parameters: {'predictor__C': 0.01}\n",
      "[05-19 17:07:04 | models:predict_with_model] result for CV:{'split0_test_score': array([0.79487179, 0.79487179]), 'split1_test_score': array([0.78947368, 0.78947368]), 'split2_test_score': array([0.81578947, 0.78947368]), 'mean_test_score': array([0.80004498, 0.79127305]), 'std_test_score': array([0.01134906, 0.00254469]), 'rank_test_score': array([1, 2], dtype=int32)}\n",
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:07:04 | models:predict_with_model] result for validation set:{'Accuracy': 0.8214285714285714, 'F1': 0.7408963585434174, 'Precision': 0.6747448979591837, 'Recall': 0.8214285714285714, 'AUROC': 0.5}\n",
      "[05-19 17:07:04 | models:predict_with_model] ======logistic_regression======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "train Counter({'N0': 92, 'N1+': 23}) test Counter({'N0': 23, 'N1+': 5})\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[05-19 17:07:06 | models:grid_cv_model] best parameters: {'predictor__C': 0.01}\n",
      "[05-19 17:07:06 | models:predict_with_model] result for CV:{'split0_test_score': array([0.76923077, 0.76923077]), 'split1_test_score': array([0.73684211, 0.73684211]), 'split2_test_score': array([0.89473684, 0.78947368]), 'mean_test_score': array([0.80026991, 0.76518219]), 'std_test_score': array([0.06809434, 0.02167662]), 'rank_test_score': array([1, 2], dtype=int32)}\n",
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:07:06 | models:predict_with_model] result for validation set:{'Accuracy': 0.8214285714285714, 'F1': 0.7408963585434174, 'Precision': 0.6747448979591837, 'Recall': 0.8214285714285714, 'AUROC': 0.5}\n",
      "[05-19 17:07:06 | cv_models:cv_predict_eval_with_model] ======k_nearest_neighbors======\n",
      "[05-19 17:07:06 | models:predict_with_model] ======k_nearest_neighbors======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "train Counter({'N0': 92, 'N1+': 22}) test Counter({'N0': 23, 'N1+': 6})\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:07:09 | models:grid_cv_model] best parameters: {'predictor__n_neighbors': 10, 'predictor__p': 5}\n",
      "[05-19 17:07:09 | models:predict_with_model] result for CV:{'split0_test_score': array([0.86842105, 0.81578947, 0.78947368, 0.86842105, 0.81578947,\n",
      "       0.86842105, 0.84210526, 0.84210526, 0.81578947, 0.89473684,\n",
      "       0.89473684, 0.89473684]), 'split1_test_score': array([0.63157895, 0.63157895, 0.71052632, 0.71052632, 0.65789474,\n",
      "       0.68421053, 0.73684211, 0.71052632, 0.68421053, 0.76315789,\n",
      "       0.76315789, 0.78947368]), 'split2_test_score': array([0.78947368, 0.71052632, 0.76315789, 0.71052632, 0.68421053,\n",
      "       0.71052632, 0.76315789, 0.76315789, 0.76315789, 0.73684211,\n",
      "       0.73684211, 0.73684211]), 'mean_test_score': array([0.76315789, 0.71929825, 0.75438596, 0.76315789, 0.71929825,\n",
      "       0.75438596, 0.78070175, 0.77192982, 0.75438596, 0.79824561,\n",
      "       0.79824561, 0.80701754]), 'std_test_score': array([0.09846467, 0.07545899, 0.03282156, 0.07443229, 0.06907024,\n",
      "       0.08134753, 0.04472824, 0.05407381, 0.05407381, 0.06907024,\n",
      "       0.06907024, 0.06564311]), 'rank_test_score': array([ 6, 11,  9,  6, 11,  8,  4,  5,  9,  2,  2,  1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:07:09 | models:predict_with_model] result for validation set:{'Accuracy': 0.7931034482758621, 'F1': 0.7015915119363395, 'Precision': 0.6290130796670631, 'Recall': 0.7931034482758621, 'AUROC': 0.6268115942028986}\n",
      "[05-19 17:07:09 | models:predict_with_model] ======k_nearest_neighbors======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Counter({'N0': 92, 'N1+': 22}) test Counter({'N0': 23, 'N1+': 6})\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:07:11 | models:grid_cv_model] best parameters: {'predictor__n_neighbors': 10, 'predictor__p': 1}\n",
      "[05-19 17:07:11 | models:predict_with_model] result for CV:{'split0_test_score': array([0.73684211, 0.71052632, 0.73684211, 0.78947368, 0.73684211,\n",
      "       0.76315789, 0.78947368, 0.76315789, 0.76315789, 0.76315789,\n",
      "       0.76315789, 0.76315789]), 'split1_test_score': array([0.89473684, 0.84210526, 0.71052632, 0.89473684, 0.86842105,\n",
      "       0.84210526, 0.84210526, 0.84210526, 0.81578947, 0.86842105,\n",
      "       0.86842105, 0.89473684]), 'split2_test_score': array([0.68421053, 0.71052632, 0.76315789, 0.73684211, 0.71052632,\n",
      "       0.73684211, 0.76315789, 0.76315789, 0.68421053, 0.78947368,\n",
      "       0.78947368, 0.76315789]), 'mean_test_score': array([0.77192982, 0.75438596, 0.73684211, 0.80701754, 0.77192982,\n",
      "       0.78070175, 0.79824561, 0.78947368, 0.75438596, 0.80701754,\n",
      "       0.80701754, 0.80701754]), 'std_test_score': array([0.08945648, 0.06202691, 0.02148675, 0.06564311, 0.06907024,\n",
      "       0.04472824, 0.03282156, 0.03721615, 0.05407381, 0.04472824,\n",
      "       0.04472824, 0.06202691]), 'rank_test_score': array([ 8, 10, 12,  3,  8,  7,  5,  6, 10,  1,  1,  3], dtype=int32)}\n",
      "[05-19 17:07:11 | models:predict_with_model] result for validation set:{'Accuracy': 0.8275862068965517, 'F1': 0.7744615087414277, 'Precision': 0.8583743842364532, 'Recall': 0.8275862068965517, 'AUROC': 0.6304347826086957}\n",
      "[05-19 17:07:11 | models:predict_with_model] ======k_nearest_neighbors======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "train Counter({'N0': 92, 'N1+': 22}) test Counter({'N0': 23, 'N1+': 6})\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:07:13 | models:grid_cv_model] best parameters: {'predictor__n_neighbors': 7, 'predictor__p': 2}\n",
      "[05-19 17:07:13 | models:predict_with_model] result for CV:{'split0_test_score': array([0.68421053, 0.65789474, 0.71052632, 0.65789474, 0.78947368,\n",
      "       0.76315789, 0.78947368, 0.76315789, 0.76315789, 0.73684211,\n",
      "       0.78947368, 0.76315789]), 'split1_test_score': array([0.76315789, 0.78947368, 0.76315789, 0.78947368, 0.81578947,\n",
      "       0.81578947, 0.81578947, 0.84210526, 0.78947368, 0.81578947,\n",
      "       0.81578947, 0.81578947]), 'split2_test_score': array([0.73684211, 0.76315789, 0.78947368, 0.76315789, 0.76315789,\n",
      "       0.78947368, 0.78947368, 0.84210526, 0.84210526, 0.81578947,\n",
      "       0.81578947, 0.84210526]), 'mean_test_score': array([0.72807018, 0.73684211, 0.75438596, 0.73684211, 0.78947368,\n",
      "       0.78947368, 0.79824561, 0.81578947, 0.79824561, 0.78947368,\n",
      "       0.80701754, 0.80701754]), 'std_test_score': array([0.03282156, 0.0568486 , 0.03282156, 0.0568486 , 0.02148675,\n",
      "       0.02148675, 0.01240538, 0.03721615, 0.03282156, 0.03721615,\n",
      "       0.01240538, 0.03282156]), 'rank_test_score': array([12, 10,  9, 10,  6,  6,  5,  1,  4,  6,  2,  2], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:07:13 | models:predict_with_model] result for validation set:{'Accuracy': 0.8275862068965517, 'F1': 0.7744615087414277, 'Precision': 0.8583743842364532, 'Recall': 0.8275862068965517, 'AUROC': 0.7210144927536233}\n",
      "[05-19 17:07:13 | models:predict_with_model] ======k_nearest_neighbors======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Counter({'N0': 92, 'N1+': 23}) test Counter({'N0': 23, 'N1+': 5})\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:07:16 | models:grid_cv_model] best parameters: {'predictor__n_neighbors': 10, 'predictor__p': 5}\n",
      "[05-19 17:07:16 | models:predict_with_model] result for CV:{'split0_test_score': array([0.82051282, 0.79487179, 0.66666667, 0.76923077, 0.79487179,\n",
      "       0.66666667, 0.79487179, 0.79487179, 0.71794872, 0.79487179,\n",
      "       0.79487179, 0.71794872]), 'split1_test_score': array([0.73684211, 0.71052632, 0.73684211, 0.73684211, 0.68421053,\n",
      "       0.76315789, 0.73684211, 0.71052632, 0.76315789, 0.78947368,\n",
      "       0.78947368, 0.78947368]), 'split2_test_score': array([0.55263158, 0.57894737, 0.47368421, 0.63157895, 0.63157895,\n",
      "       0.57894737, 0.63157895, 0.68421053, 0.65789474, 0.68421053,\n",
      "       0.73684211, 0.81578947]), 'mean_test_score': array([0.70332883, 0.69478183, 0.62573099, 0.71255061, 0.70355376,\n",
      "       0.66959064, 0.72109762, 0.72986955, 0.71300045, 0.75618534,\n",
      "       0.77372919, 0.77440396]), 'std_test_score': array([0.11190009, 0.08885102, 0.1112649 , 0.05876259, 0.06805272,\n",
      "       0.07523205, 0.06758725, 0.0472024 , 0.04311571, 0.05094157,\n",
      "       0.02617604, 0.04134026]), 'rank_test_score': array([ 9, 10, 12,  7,  8, 11,  5,  4,  6,  3,  2,  1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:07:16 | models:predict_with_model] result for validation set:{'Accuracy': 0.8214285714285714, 'F1': 0.7408963585434174, 'Precision': 0.6747448979591837, 'Recall': 0.8214285714285714, 'AUROC': 0.7608695652173914}\n",
      "[05-19 17:07:16 | models:predict_with_model] ======k_nearest_neighbors======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Counter({'N0': 92, 'N1+': 23}) test Counter({'N0': 23, 'N1+': 5})\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:07:18 | models:grid_cv_model] best parameters: {'predictor__n_neighbors': 10, 'predictor__p': 1}\n",
      "[05-19 17:07:18 | models:predict_with_model] result for CV:{'split0_test_score': array([0.79487179, 0.84615385, 0.76923077, 0.76923077, 0.76923077,\n",
      "       0.71794872, 0.76923077, 0.79487179, 0.74358974, 0.76923077,\n",
      "       0.76923077, 0.74358974]), 'split1_test_score': array([0.73684211, 0.73684211, 0.73684211, 0.73684211, 0.73684211,\n",
      "       0.71052632, 0.73684211, 0.73684211, 0.73684211, 0.73684211,\n",
      "       0.73684211, 0.73684211]), 'split2_test_score': array([0.81578947, 0.73684211, 0.65789474, 0.73684211, 0.71052632,\n",
      "       0.78947368, 0.76315789, 0.78947368, 0.81578947, 0.86842105,\n",
      "       0.84210526, 0.84210526]), 'mean_test_score': array([0.78250112, 0.77327935, 0.72132254, 0.74763833, 0.7388664 ,\n",
      "       0.73931624, 0.75641026, 0.77372919, 0.76540711, 0.79149798,\n",
      "       0.78272605, 0.77417904]), 'std_test_score': array([0.03339608, 0.05153005, 0.04675875, 0.01526816, 0.0240087 ,\n",
      "       0.03559588, 0.01405713, 0.02617604, 0.03573206, 0.05597694,\n",
      "       0.04402026, 0.04811003]), 'rank_test_score': array([ 3,  6, 12,  9, 11, 10,  8,  5,  7,  1,  2,  4], dtype=int32)}\n",
      "[05-19 17:07:18 | models:predict_with_model] result for validation set:{'Accuracy': 0.7857142857142857, 'F1': 0.722857142857143, 'Precision': 0.6693121693121693, 'Recall': 0.7857142857142857, 'AUROC': 0.5391304347826087}\n",
      "[05-19 17:07:18 | cv_models:cv_predict_eval_with_model] ======svc======\n",
      "[05-19 17:07:18 | models:predict_with_model] ======svc======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "train Counter({'N0': 92, 'N1+': 22}) test Counter({'N0': 23, 'N1+': 6})\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:07:20 | models:grid_cv_model] best parameters: {'predictor__C': 0.01, 'predictor__degree': 1}\n",
      "[05-19 17:07:20 | models:predict_with_model] result for CV:{'split0_test_score': array([0.89473684, 0.89473684, 0.89473684, 0.89473684, 0.89473684,\n",
      "       0.89473684, 0.89473684, 0.89473684, 0.89473684]), 'split1_test_score': array([0.78947368, 0.78947368, 0.78947368, 0.78947368, 0.78947368,\n",
      "       0.78947368, 0.78947368, 0.78947368, 0.78947368]), 'split2_test_score': array([0.73684211, 0.73684211, 0.73684211, 0.73684211, 0.73684211,\n",
      "       0.73684211, 0.73684211, 0.73684211, 0.73684211]), 'mean_test_score': array([0.80701754, 0.80701754, 0.80701754, 0.80701754, 0.80701754,\n",
      "       0.80701754, 0.80701754, 0.80701754, 0.80701754]), 'std_test_score': array([0.06564311, 0.06564311, 0.06564311, 0.06564311, 0.06564311,\n",
      "       0.06564311, 0.06564311, 0.06564311, 0.06564311]), 'rank_test_score': array([1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:07:20 | models:predict_with_model] result for validation set:{'Accuracy': 0.7931034482758621, 'F1': 0.7015915119363395, 'Precision': 0.6290130796670631, 'Recall': 0.7931034482758621, 'AUROC': 0.6956521739130436}\n",
      "[05-19 17:07:20 | models:predict_with_model] ======svc======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "train Counter({'N0': 92, 'N1+': 22}) test Counter({'N0': 23, 'N1+': 6})\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:07:21 | models:grid_cv_model] best parameters: {'predictor__C': 0.01, 'predictor__degree': 1}\n",
      "[05-19 17:07:21 | models:predict_with_model] result for CV:{'split0_test_score': array([0.76315789, 0.76315789, 0.76315789, 0.76315789, 0.76315789,\n",
      "       0.76315789, 0.76315789, 0.76315789, 0.76315789]), 'split1_test_score': array([0.89473684, 0.89473684, 0.89473684, 0.89473684, 0.89473684,\n",
      "       0.89473684, 0.89473684, 0.89473684, 0.89473684]), 'split2_test_score': array([0.76315789, 0.76315789, 0.76315789, 0.76315789, 0.76315789,\n",
      "       0.76315789, 0.76315789, 0.76315789, 0.76315789]), 'mean_test_score': array([0.80701754, 0.80701754, 0.80701754, 0.80701754, 0.80701754,\n",
      "       0.80701754, 0.80701754, 0.80701754, 0.80701754]), 'std_test_score': array([0.06202691, 0.06202691, 0.06202691, 0.06202691, 0.06202691,\n",
      "       0.06202691, 0.06202691, 0.06202691, 0.06202691]), 'rank_test_score': array([1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)}\n",
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:07:22 | models:predict_with_model] result for validation set:{'Accuracy': 0.7931034482758621, 'F1': 0.7015915119363395, 'Precision': 0.6290130796670631, 'Recall': 0.7931034482758621, 'AUROC': 0.6304347826086957}\n",
      "[05-19 17:07:22 | models:predict_with_model] ======svc======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "train Counter({'N0': 92, 'N1+': 22}) test Counter({'N0': 23, 'N1+': 6})\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:07:23 | models:grid_cv_model] best parameters: {'predictor__C': 0.01, 'predictor__degree': 1}\n",
      "[05-19 17:07:23 | models:predict_with_model] result for CV:{'split0_test_score': array([0.76315789, 0.76315789, 0.76315789, 0.76315789, 0.76315789,\n",
      "       0.76315789, 0.76315789, 0.76315789, 0.76315789]), 'split1_test_score': array([0.81578947, 0.81578947, 0.81578947, 0.81578947, 0.81578947,\n",
      "       0.81578947, 0.81578947, 0.81578947, 0.81578947]), 'split2_test_score': array([0.84210526, 0.84210526, 0.84210526, 0.84210526, 0.84210526,\n",
      "       0.84210526, 0.84210526, 0.84210526, 0.84210526]), 'mean_test_score': array([0.80701754, 0.80701754, 0.80701754, 0.80701754, 0.80701754,\n",
      "       0.80701754, 0.80701754, 0.80701754, 0.80701754]), 'std_test_score': array([0.03282156, 0.03282156, 0.03282156, 0.03282156, 0.03282156,\n",
      "       0.03282156, 0.03282156, 0.03282156, 0.03282156]), 'rank_test_score': array([1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:07:23 | models:predict_with_model] result for validation set:{'Accuracy': 0.7931034482758621, 'F1': 0.7015915119363395, 'Precision': 0.6290130796670631, 'Recall': 0.7931034482758621, 'AUROC': 0.7246376811594203}\n",
      "[05-19 17:07:23 | models:predict_with_model] ======svc======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "train Counter({'N0': 92, 'N1+': 23}) test Counter({'N0': 23, 'N1+': 5})\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:07:25 | models:grid_cv_model] best parameters: {'predictor__C': 0.01, 'predictor__degree': 1}\n",
      "[05-19 17:07:25 | models:predict_with_model] result for CV:{'split0_test_score': array([0.79487179, 0.79487179, 0.79487179, 0.79487179, 0.79487179,\n",
      "       0.79487179, 0.79487179, 0.79487179, 0.79487179]), 'split1_test_score': array([0.78947368, 0.78947368, 0.78947368, 0.78947368, 0.78947368,\n",
      "       0.78947368, 0.78947368, 0.78947368, 0.78947368]), 'split2_test_score': array([0.81578947, 0.81578947, 0.81578947, 0.81578947, 0.81578947,\n",
      "       0.81578947, 0.81578947, 0.81578947, 0.81578947]), 'mean_test_score': array([0.80004498, 0.80004498, 0.80004498, 0.80004498, 0.80004498,\n",
      "       0.80004498, 0.80004498, 0.80004498, 0.80004498]), 'std_test_score': array([0.01134906, 0.01134906, 0.01134906, 0.01134906, 0.01134906,\n",
      "       0.01134906, 0.01134906, 0.01134906, 0.01134906]), 'rank_test_score': array([1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)}\n",
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:07:25 | models:predict_with_model] result for validation set:{'Accuracy': 0.8214285714285714, 'F1': 0.7408963585434174, 'Precision': 0.6747448979591837, 'Recall': 0.8214285714285714, 'AUROC': 0.8347826086956522}\n",
      "[05-19 17:07:25 | models:predict_with_model] ======svc======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "train Counter({'N0': 92, 'N1+': 23}) test Counter({'N0': 23, 'N1+': 5})\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:07:26 | models:grid_cv_model] best parameters: {'predictor__C': 0.01, 'predictor__degree': 1}\n",
      "[05-19 17:07:26 | models:predict_with_model] result for CV:{'split0_test_score': array([0.76923077, 0.76923077, 0.76923077, 0.76923077, 0.76923077,\n",
      "       0.76923077, 0.76923077, 0.76923077, 0.76923077]), 'split1_test_score': array([0.73684211, 0.73684211, 0.73684211, 0.73684211, 0.73684211,\n",
      "       0.73684211, 0.73684211, 0.73684211, 0.73684211]), 'split2_test_score': array([0.89473684, 0.89473684, 0.89473684, 0.89473684, 0.89473684,\n",
      "       0.89473684, 0.89473684, 0.89473684, 0.89473684]), 'mean_test_score': array([0.80026991, 0.80026991, 0.80026991, 0.80026991, 0.80026991,\n",
      "       0.80026991, 0.80026991, 0.80026991, 0.80026991]), 'std_test_score': array([0.06809434, 0.06809434, 0.06809434, 0.06809434, 0.06809434,\n",
      "       0.06809434, 0.06809434, 0.06809434, 0.06809434]), 'rank_test_score': array([1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:07:27 | models:predict_with_model] result for validation set:{'Accuracy': 0.8214285714285714, 'F1': 0.7408963585434174, 'Precision': 0.6747448979591837, 'Recall': 0.8214285714285714, 'AUROC': 0.5478260869565218}\n",
      "[05-19 17:07:27 | cv_models:cv_predict_eval_with_model] ======random_forest======\n",
      "[05-19 17:07:27 | models:predict_with_model] ======random_forest======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "train Counter({'N0': 92, 'N1+': 22}) test Counter({'N0': 23, 'N1+': 6})\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:07:59 | models:grid_cv_model] best parameters: {'predictor__max_depth': 10, 'predictor__max_features': 'auto', 'predictor__min_samples_leaf': 1, 'predictor__n_estimators': 200}\n",
      "[05-19 17:07:59 | models:predict_with_model] result for CV:{'split0_test_score': array([0.89473684, 0.92105263, 0.86842105, 0.86842105, 0.89473684,\n",
      "       0.89473684, 0.89473684, 0.89473684, 0.89473684, 0.92105263,\n",
      "       0.86842105, 0.86842105, 0.89473684, 0.89473684, 0.89473684,\n",
      "       0.89473684]), 'split1_test_score': array([0.76315789, 0.76315789, 0.76315789, 0.76315789, 0.78947368,\n",
      "       0.78947368, 0.78947368, 0.78947368, 0.76315789, 0.76315789,\n",
      "       0.76315789, 0.76315789, 0.78947368, 0.78947368, 0.78947368,\n",
      "       0.78947368]), 'split2_test_score': array([0.73684211, 0.73684211, 0.73684211, 0.73684211, 0.73684211,\n",
      "       0.73684211, 0.73684211, 0.73684211, 0.73684211, 0.73684211,\n",
      "       0.73684211, 0.73684211, 0.73684211, 0.73684211, 0.73684211,\n",
      "       0.73684211]), 'mean_test_score': array([0.79824561, 0.80701754, 0.78947368, 0.78947368, 0.80701754,\n",
      "       0.80701754, 0.80701754, 0.80701754, 0.79824561, 0.80701754,\n",
      "       0.78947368, 0.78947368, 0.80701754, 0.80701754, 0.80701754,\n",
      "       0.80701754]), 'std_test_score': array([0.06907024, 0.08134753, 0.0568486 , 0.0568486 , 0.06564311,\n",
      "       0.06564311, 0.06564311, 0.06564311, 0.06907024, 0.08134753,\n",
      "       0.0568486 , 0.0568486 , 0.06564311, 0.06564311, 0.06564311,\n",
      "       0.06564311]), 'rank_test_score': array([11,  1, 13, 13,  1,  1,  1,  1, 11,  1, 13, 13,  1,  1,  1,  1],\n",
      "      dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:07:59 | models:predict_with_model] result for validation set:{'Accuracy': 0.7931034482758621, 'F1': 0.7015915119363395, 'Precision': 0.6290130796670631, 'Recall': 0.7931034482758621, 'AUROC': 0.641304347826087}\n",
      "[05-19 17:07:59 | models:predict_with_model] ======random_forest======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "train Counter({'N0': 92, 'N1+': 22}) test Counter({'N0': 23, 'N1+': 6})\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:08:31 | models:grid_cv_model] best parameters: {'predictor__max_depth': 10, 'predictor__max_features': 'auto', 'predictor__min_samples_leaf': 1, 'predictor__n_estimators': 200}\n",
      "[05-19 17:08:31 | models:predict_with_model] result for CV:{'split0_test_score': array([0.76315789, 0.76315789, 0.76315789, 0.76315789, 0.76315789,\n",
      "       0.76315789, 0.76315789, 0.76315789, 0.76315789, 0.76315789,\n",
      "       0.76315789, 0.76315789, 0.76315789, 0.76315789, 0.76315789,\n",
      "       0.76315789]), 'split1_test_score': array([0.86842105, 0.89473684, 0.89473684, 0.89473684, 0.89473684,\n",
      "       0.89473684, 0.89473684, 0.89473684, 0.86842105, 0.89473684,\n",
      "       0.89473684, 0.89473684, 0.89473684, 0.89473684, 0.89473684,\n",
      "       0.89473684]), 'split2_test_score': array([0.76315789, 0.76315789, 0.76315789, 0.76315789, 0.76315789,\n",
      "       0.76315789, 0.76315789, 0.76315789, 0.76315789, 0.76315789,\n",
      "       0.76315789, 0.76315789, 0.76315789, 0.76315789, 0.76315789,\n",
      "       0.76315789]), 'mean_test_score': array([0.79824561, 0.80701754, 0.80701754, 0.80701754, 0.80701754,\n",
      "       0.80701754, 0.80701754, 0.80701754, 0.79824561, 0.80701754,\n",
      "       0.80701754, 0.80701754, 0.80701754, 0.80701754, 0.80701754,\n",
      "       0.80701754]), 'std_test_score': array([0.04962153, 0.06202691, 0.06202691, 0.06202691, 0.06202691,\n",
      "       0.06202691, 0.06202691, 0.06202691, 0.04962153, 0.06202691,\n",
      "       0.06202691, 0.06202691, 0.06202691, 0.06202691, 0.06202691,\n",
      "       0.06202691]), 'rank_test_score': array([15,  1,  1,  1,  1,  1,  1,  1, 15,  1,  1,  1,  1,  1,  1,  1],\n",
      "      dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:08:32 | models:predict_with_model] result for validation set:{'Accuracy': 0.7931034482758621, 'F1': 0.7015915119363395, 'Precision': 0.6290130796670631, 'Recall': 0.7931034482758621, 'AUROC': 0.818840579710145}\n",
      "[05-19 17:08:32 | models:predict_with_model] ======random_forest======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "train Counter({'N0': 92, 'N1+': 22}) test Counter({'N0': 23, 'N1+': 6})\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:09:04 | models:grid_cv_model] best parameters: {'predictor__max_depth': 10, 'predictor__max_features': 'auto', 'predictor__min_samples_leaf': 4, 'predictor__n_estimators': 200}\n",
      "[05-19 17:09:04 | models:predict_with_model] result for CV:{'split0_test_score': array([0.76315789, 0.76315789, 0.76315789, 0.76315789, 0.76315789,\n",
      "       0.76315789, 0.76315789, 0.76315789, 0.76315789, 0.76315789,\n",
      "       0.76315789, 0.76315789, 0.76315789, 0.76315789, 0.76315789,\n",
      "       0.76315789]), 'split1_test_score': array([0.81578947, 0.81578947, 0.78947368, 0.78947368, 0.78947368,\n",
      "       0.78947368, 0.78947368, 0.78947368, 0.81578947, 0.81578947,\n",
      "       0.78947368, 0.78947368, 0.78947368, 0.78947368, 0.78947368,\n",
      "       0.78947368]), 'split2_test_score': array([0.78947368, 0.76315789, 0.73684211, 0.73684211, 0.76315789,\n",
      "       0.81578947, 0.78947368, 0.73684211, 0.78947368, 0.76315789,\n",
      "       0.73684211, 0.73684211, 0.76315789, 0.81578947, 0.78947368,\n",
      "       0.73684211]), 'mean_test_score': array([0.78947368, 0.78070175, 0.76315789, 0.76315789, 0.77192982,\n",
      "       0.78947368, 0.78070175, 0.76315789, 0.78947368, 0.78070175,\n",
      "       0.76315789, 0.76315789, 0.77192982, 0.78947368, 0.78070175,\n",
      "       0.76315789]), 'std_test_score': array([0.02148675, 0.02481076, 0.02148675, 0.02148675, 0.01240538,\n",
      "       0.02148675, 0.01240538, 0.02148675, 0.02148675, 0.02481076,\n",
      "       0.02148675, 0.02148675, 0.01240538, 0.02148675, 0.01240538,\n",
      "       0.02148675]), 'rank_test_score': array([ 3,  5, 11, 11,  9,  1,  5, 11,  3,  5, 11, 11,  9,  1,  5, 11],\n",
      "      dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:09:04 | models:predict_with_model] result for validation set:{'Accuracy': 0.6896551724137931, 'F1': 0.6474313863476425, 'Precision': 0.610079575596817, 'Recall': 0.6896551724137931, 'AUROC': 0.6521739130434783}\n",
      "[05-19 17:09:04 | models:predict_with_model] ======random_forest======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "train Counter({'N0': 92, 'N1+': 23}) test Counter({'N0': 23, 'N1+': 5})\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.2s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:09:36 | models:grid_cv_model] best parameters: {'predictor__max_depth': 10, 'predictor__max_features': 'auto', 'predictor__min_samples_leaf': 1, 'predictor__n_estimators': 100}\n",
      "[05-19 17:09:36 | models:predict_with_model] result for CV:{'split0_test_score': array([0.79487179, 0.79487179, 0.79487179, 0.79487179, 0.79487179,\n",
      "       0.79487179, 0.79487179, 0.79487179, 0.79487179, 0.79487179,\n",
      "       0.79487179, 0.79487179, 0.79487179, 0.79487179, 0.79487179,\n",
      "       0.79487179]), 'split1_test_score': array([0.78947368, 0.78947368, 0.78947368, 0.78947368, 0.78947368,\n",
      "       0.78947368, 0.78947368, 0.78947368, 0.78947368, 0.78947368,\n",
      "       0.78947368, 0.78947368, 0.78947368, 0.78947368, 0.78947368,\n",
      "       0.78947368]), 'split2_test_score': array([0.81578947, 0.81578947, 0.81578947, 0.81578947, 0.81578947,\n",
      "       0.81578947, 0.81578947, 0.81578947, 0.81578947, 0.81578947,\n",
      "       0.81578947, 0.81578947, 0.81578947, 0.81578947, 0.81578947,\n",
      "       0.81578947]), 'mean_test_score': array([0.80004498, 0.80004498, 0.80004498, 0.80004498, 0.80004498,\n",
      "       0.80004498, 0.80004498, 0.80004498, 0.80004498, 0.80004498,\n",
      "       0.80004498, 0.80004498, 0.80004498, 0.80004498, 0.80004498,\n",
      "       0.80004498]), 'std_test_score': array([0.01134906, 0.01134906, 0.01134906, 0.01134906, 0.01134906,\n",
      "       0.01134906, 0.01134906, 0.01134906, 0.01134906, 0.01134906,\n",
      "       0.01134906, 0.01134906, 0.01134906, 0.01134906, 0.01134906,\n",
      "       0.01134906]), 'rank_test_score': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:09:36 | models:predict_with_model] result for validation set:{'Accuracy': 0.8214285714285714, 'F1': 0.7408963585434174, 'Precision': 0.6747448979591837, 'Recall': 0.8214285714285714, 'AUROC': 0.5782608695652174}\n",
      "[05-19 17:09:36 | models:predict_with_model] ======random_forest======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "train Counter({'N0': 92, 'N1+': 23}) test Counter({'N0': 23, 'N1+': 5})\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:10:09 | models:grid_cv_model] best parameters: {'predictor__max_depth': 10, 'predictor__max_features': 'auto', 'predictor__min_samples_leaf': 1, 'predictor__n_estimators': 100}\n",
      "[05-19 17:10:09 | models:predict_with_model] result for CV:{'split0_test_score': array([0.76923077, 0.76923077, 0.76923077, 0.76923077, 0.76923077,\n",
      "       0.76923077, 0.76923077, 0.76923077, 0.76923077, 0.76923077,\n",
      "       0.76923077, 0.76923077, 0.76923077, 0.76923077, 0.76923077,\n",
      "       0.76923077]), 'split1_test_score': array([0.73684211, 0.73684211, 0.73684211, 0.73684211, 0.73684211,\n",
      "       0.73684211, 0.73684211, 0.73684211, 0.73684211, 0.73684211,\n",
      "       0.73684211, 0.73684211, 0.73684211, 0.73684211, 0.73684211,\n",
      "       0.73684211]), 'split2_test_score': array([0.86842105, 0.84210526, 0.81578947, 0.81578947, 0.86842105,\n",
      "       0.81578947, 0.84210526, 0.81578947, 0.86842105, 0.84210526,\n",
      "       0.81578947, 0.81578947, 0.86842105, 0.81578947, 0.84210526,\n",
      "       0.81578947]), 'mean_test_score': array([0.79149798, 0.78272605, 0.77395412, 0.77395412, 0.79149798,\n",
      "       0.77395412, 0.78272605, 0.77395412, 0.79149798, 0.78272605,\n",
      "       0.77395412, 0.77395412, 0.79149798, 0.77395412, 0.78272605,\n",
      "       0.77395412]), 'std_test_score': array([0.05597694, 0.04402026, 0.03240272, 0.03240272, 0.05597694,\n",
      "       0.03240272, 0.04402026, 0.03240272, 0.05597694, 0.04402026,\n",
      "       0.03240272, 0.03240272, 0.05597694, 0.03240272, 0.04402026,\n",
      "       0.03240272]), 'rank_test_score': array([1, 5, 9, 9, 1, 9, 5, 9, 1, 5, 9, 9, 1, 9, 5, 9], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:10:09 | models:predict_with_model] result for validation set:{'Accuracy': 0.8214285714285714, 'F1': 0.7408963585434174, 'Precision': 0.6747448979591837, 'Recall': 0.8214285714285714, 'AUROC': 0.48695652173913045}\n",
      "[05-19 17:10:09 | cv_models:cv_predict_eval_with_model] ======mlp======\n",
      "[05-19 17:10:09 | models:predict_with_model] ======mlp======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Counter({'N0': 92, 'N1+': 22}) test Counter({'N0': 23, 'N1+': 6})\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.3s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.5s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.6s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:10:18 | models:grid_cv_model] best parameters: {'predictor__hidden_layer_sizes': (200, 20)}\n",
      "[05-19 17:10:18 | models:predict_with_model] result for CV:{'split0_test_score': array([0.76315789, 0.76315789, 0.86842105, 0.84210526]), 'split1_test_score': array([0.65789474, 0.76315789, 0.68421053, 0.73684211]), 'split2_test_score': array([0.68421053, 0.73684211, 0.78947368, 0.73684211]), 'mean_test_score': array([0.70175439, 0.75438596, 0.78070175, 0.77192982]), 'std_test_score': array([0.04472824, 0.01240538, 0.07545899, 0.04962153]), 'rank_test_score': array([4, 3, 1, 2], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:10:19 | models:predict_with_model] result for validation set:{'Accuracy': 0.7931034482758621, 'F1': 0.7015915119363395, 'Precision': 0.6290130796670631, 'Recall': 0.7931034482758621, 'AUROC': 0.6014492753623188}\n",
      "[05-19 17:10:19 | models:predict_with_model] ======mlp======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.1s\n",
      "train Counter({'N0': 92, 'N1+': 22}) test Counter({'N0': 23, 'N1+': 6})\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.5s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.5s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:10:29 | models:grid_cv_model] best parameters: {'predictor__hidden_layer_sizes': (100, 20)}\n",
      "[05-19 17:10:29 | models:predict_with_model] result for CV:{'split0_test_score': array([0.73684211, 0.73684211, 0.76315789, 0.76315789]), 'split1_test_score': array([0.84210526, 0.92105263, 0.84210526, 0.89473684]), 'split2_test_score': array([0.73684211, 0.73684211, 0.73684211, 0.71052632]), 'mean_test_score': array([0.77192982, 0.79824561, 0.78070175, 0.78947368]), 'std_test_score': array([0.04962153, 0.08683767, 0.04472824, 0.07747159]), 'rank_test_score': array([4, 1, 3, 2], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:10:30 | models:predict_with_model] result for validation set:{'Accuracy': 0.7586206896551724, 'F1': 0.7257799671592775, 'Precision': 0.7095490716180372, 'Recall': 0.7586206896551724, 'AUROC': 0.6884057971014492}\n",
      "[05-19 17:10:30 | models:predict_with_model] ======mlp======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "train Counter({'N0': 92, 'N1+': 22}) test Counter({'N0': 23, 'N1+': 6})\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.5s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.5s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   2.1s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   2.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:10:41 | models:grid_cv_model] best parameters: {'predictor__hidden_layer_sizes': (100, 10)}\n",
      "[05-19 17:10:41 | models:predict_with_model] result for CV:{'split0_test_score': array([0.76315789, 0.65789474, 0.71052632, 0.78947368]), 'split1_test_score': array([0.76315789, 0.73684211, 0.73684211, 0.68421053]), 'split2_test_score': array([0.73684211, 0.60526316, 0.52631579, 0.71052632]), 'mean_test_score': array([0.75438596, 0.66666667, 0.65789474, 0.72807018]), 'std_test_score': array([0.01240538, 0.05407381, 0.09365858, 0.04472824]), 'rank_test_score': array([1, 3, 4, 2], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:10:41 | models:predict_with_model] result for validation set:{'Accuracy': 0.6896551724137931, 'F1': 0.6981432360742706, 'Precision': 0.7080161218092254, 'Recall': 0.6896551724137931, 'AUROC': 0.5869565217391304}\n",
      "[05-19 17:10:41 | models:predict_with_model] ======mlp======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "train Counter({'N0': 92, 'N1+': 23}) test Counter({'N0': 23, 'N1+': 5})\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   2.0s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   2.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.6s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.5s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:10:53 | models:grid_cv_model] best parameters: {'predictor__hidden_layer_sizes': (400, 40)}\n",
      "[05-19 17:10:53 | models:predict_with_model] result for CV:{'split0_test_score': array([0.79487179, 0.82051282, 0.74358974, 0.79487179]), 'split1_test_score': array([0.73684211, 0.65789474, 0.68421053, 0.73684211]), 'split2_test_score': array([0.63157895, 0.71052632, 0.5       , 0.86842105]), 'mean_test_score': array([0.72109762, 0.72964462, 0.64260009, 0.80004498]), 'std_test_score': array([0.06758725, 0.06775098, 0.10370652, 0.05384129]), 'rank_test_score': array([3, 2, 4, 1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:10:54 | models:predict_with_model] result for validation set:{'Accuracy': 0.8214285714285714, 'F1': 0.7886297376093295, 'Precision': 0.7843406593406593, 'Recall': 0.8214285714285714, 'AUROC': 0.6695652173913044}\n",
      "[05-19 17:10:54 | models:predict_with_model] ======mlp======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.5s\n",
      "train Counter({'N0': 92, 'N1+': 23}) test Counter({'N0': 23, 'N1+': 5})\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   1.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.5s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.5s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:11:05 | models:grid_cv_model] best parameters: {'predictor__hidden_layer_sizes': (100, 20)}\n",
      "[05-19 17:11:05 | models:predict_with_model] result for CV:{'split0_test_score': array([0.82051282, 0.66666667, 0.71794872, 0.79487179]), 'split1_test_score': array([0.73684211, 0.73684211, 0.68421053, 0.71052632]), 'split2_test_score': array([0.65789474, 0.81578947, 0.78947368, 0.52631579]), 'mean_test_score': array([0.73841655, 0.73976608, 0.73054431, 0.67723797]), 'std_test_score': array([0.06639789, 0.06091423, 0.04388675, 0.11213583]), 'rank_test_score': array([2, 1, 3, 4], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:11:05 | models:predict_with_model] result for validation set:{'Accuracy': 0.6785714285714286, 'F1': 0.6896103896103897, 'Precision': 0.7018398268398268, 'Recall': 0.6785714285714286, 'AUROC': 0.6086956521739131}\n",
      "[05-19 17:11:05 | cv_models:cv_predict_eval_with_model] ======xgboost======\n",
      "[05-19 17:11:05 | models:predict_with_model] ======xgboost======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "train Counter({'N0': 92, 'N1+': 22}) test Counter({'N0': 23, 'N1+': 6})\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:11:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:11:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:11:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:11:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:11:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:11:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:11:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:11:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:11:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:11:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:11:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:11:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:11:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[05-19 17:11:10 | models:grid_cv_model] best parameters: {'predictor__learning_rate': 0.01, 'predictor__n_estimators': 100, 'predictor__reg_alpha': 10}\n",
      "[05-19 17:11:10 | models:predict_with_model] result for CV:{'split0_test_score': array([0.73684211, 0.89473684, 0.84210526, 0.89473684]), 'split1_test_score': array([0.78947368, 0.78947368, 0.73684211, 0.78947368]), 'split2_test_score': array([0.71052632, 0.73684211, 0.71052632, 0.73684211]), 'mean_test_score': array([0.74561404, 0.80701754, 0.76315789, 0.80701754]), 'std_test_score': array([0.03282156, 0.06564311, 0.0568486 , 0.06564311]), 'rank_test_score': array([4, 1, 3, 1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:11:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:11:11 | models:predict_with_model] result for validation set:{'Accuracy': 0.7931034482758621, 'F1': 0.7015915119363395, 'Precision': 0.6290130796670631, 'Recall': 0.7931034482758621, 'AUROC': 0.35507246376811596}\n",
      "[05-19 17:11:11 | models:predict_with_model] ======xgboost======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "train Counter({'N0': 92, 'N1+': 22}) test Counter({'N0': 23, 'N1+': 6})\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:11:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:11:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:11:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:11:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:11:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:11:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:11:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:11:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:11:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:11:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:11:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:11:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:11:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[05-19 17:11:17 | models:grid_cv_model] best parameters: {'predictor__learning_rate': 0.01, 'predictor__n_estimators': 100, 'predictor__reg_alpha': 10}\n",
      "[05-19 17:11:17 | models:predict_with_model] result for CV:{'split0_test_score': array([0.73684211, 0.76315789, 0.76315789, 0.76315789]), 'split1_test_score': array([0.86842105, 0.89473684, 0.89473684, 0.89473684]), 'split2_test_score': array([0.73684211, 0.76315789, 0.73684211, 0.76315789]), 'mean_test_score': array([0.78070175, 0.80701754, 0.79824561, 0.80701754]), 'std_test_score': array([0.06202691, 0.06202691, 0.06907024, 0.06202691]), 'rank_test_score': array([4, 1, 3, 1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:11:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:11:17 | models:predict_with_model] result for validation set:{'Accuracy': 0.7931034482758621, 'F1': 0.7015915119363395, 'Precision': 0.6290130796670631, 'Recall': 0.7931034482758621, 'AUROC': 0.5}\n",
      "[05-19 17:11:17 | models:predict_with_model] ======xgboost======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "train Counter({'N0': 92, 'N1+': 22}) test Counter({'N0': 23, 'N1+': 6})\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:11:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:11:18] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:11:18] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:11:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:11:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:11:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:11:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:11:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:11:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:11:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:11:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:11:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:11:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[05-19 17:11:23 | models:grid_cv_model] best parameters: {'predictor__learning_rate': 0.01, 'predictor__n_estimators': 100, 'predictor__reg_alpha': 10}\n",
      "[05-19 17:11:23 | models:predict_with_model] result for CV:{'split0_test_score': array([0.71052632, 0.76315789, 0.76315789, 0.76315789]), 'split1_test_score': array([0.84210526, 0.81578947, 0.81578947, 0.81578947]), 'split2_test_score': array([0.65789474, 0.84210526, 0.73684211, 0.84210526]), 'mean_test_score': array([0.73684211, 0.80701754, 0.77192982, 0.80701754]), 'std_test_score': array([0.07747159, 0.03282156, 0.03282156, 0.03282156]), 'rank_test_score': array([4, 1, 3, 1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:11:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:11:24 | models:predict_with_model] result for validation set:{'Accuracy': 0.7931034482758621, 'F1': 0.7015915119363395, 'Precision': 0.6290130796670631, 'Recall': 0.7931034482758621, 'AUROC': 0.644927536231884}\n",
      "[05-19 17:11:24 | models:predict_with_model] ======xgboost======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "train Counter({'N0': 92, 'N1+': 23}) test Counter({'N0': 23, 'N1+': 5})\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:11:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:11:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:11:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:11:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:11:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:11:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:11:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:11:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:11:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:11:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:11:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:11:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:11:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[05-19 17:11:29 | models:grid_cv_model] best parameters: {'predictor__learning_rate': 0.1, 'predictor__n_estimators': 100, 'predictor__reg_alpha': 1}\n",
      "[05-19 17:11:29 | models:predict_with_model] result for CV:{'split0_test_score': array([0.76923077, 0.79487179, 0.79487179, 0.79487179]), 'split1_test_score': array([0.78947368, 0.78947368, 0.78947368, 0.78947368]), 'split2_test_score': array([0.76315789, 0.81578947, 0.84210526, 0.81578947]), 'mean_test_score': array([0.77395412, 0.80004498, 0.80881691, 0.80004498]), 'std_test_score': array([0.01125056, 0.01134906, 0.02364136, 0.01134906]), 'rank_test_score': array([4, 2, 1, 2], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:11:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:11:29 | models:predict_with_model] result for validation set:{'Accuracy': 0.8214285714285714, 'F1': 0.7408963585434174, 'Precision': 0.6747448979591837, 'Recall': 0.8214285714285714, 'AUROC': 0.7652173913043478}\n",
      "[05-19 17:11:29 | models:predict_with_model] ======xgboost======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "train Counter({'N0': 92, 'N1+': 23}) test Counter({'N0': 23, 'N1+': 5})\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:11:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:11:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:11:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:11:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:11:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:11:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:11:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:11:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:11:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:11:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:11:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:11:34] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:11:34] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[05-19 17:11:35 | models:grid_cv_model] best parameters: {'predictor__learning_rate': 0.01, 'predictor__n_estimators': 100, 'predictor__reg_alpha': 1}\n",
      "[05-19 17:11:35 | models:predict_with_model] result for CV:{'split0_test_score': array([0.76923077, 0.76923077, 0.76923077, 0.76923077]), 'split1_test_score': array([0.76315789, 0.73684211, 0.73684211, 0.73684211]), 'split2_test_score': array([0.89473684, 0.89473684, 0.81578947, 0.89473684]), 'mean_test_score': array([0.80904184, 0.80026991, 0.77395412, 0.80026991]), 'std_test_score': array([0.06064622, 0.06809434, 0.03240272, 0.06809434]), 'rank_test_score': array([1, 2, 4, 2], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:11:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[05-19 17:11:35 | models:predict_with_model] result for validation set:{'Accuracy': 0.7857142857142857, 'F1': 0.722857142857143, 'Precision': 0.6693121693121693, 'Recall': 0.7857142857142857, 'AUROC': 0.6086956521739131}\n",
      "[05-19 17:11:35 | application_cross_validation:ApplicationCV] Saved results to /labs/gevaertlab/users/yyhhli/code/vae/applications/results/VAE3D32AUG_70/StfNStage.cv_result_dict.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "{'__dict': {}, 'logistic_regression': {'Accuracy': [0.7931034482758621, 0.7931034482758621, 0.7931034482758621, 0.8214285714285714, 0.8214285714285714], 'F1': [0.7015915119363395, 0.7015915119363395, 0.7015915119363395, 0.7408963585434174, 0.7408963585434174], 'Precision': [0.6290130796670631, 0.6290130796670631, 0.6290130796670631, 0.6747448979591837, 0.6747448979591837], 'Recall': [0.7931034482758621, 0.7931034482758621, 0.7931034482758621, 0.8214285714285714, 0.8214285714285714], 'AUROC': [0.5, 0.5, 0.5, 0.5, 0.5]}, 'k_nearest_neighbors': {'Accuracy': [0.7931034482758621, 0.8275862068965517, 0.8275862068965517, 0.8214285714285714, 0.7857142857142857], 'F1': [0.7015915119363395, 0.7744615087414277, 0.7744615087414277, 0.7408963585434174, 0.722857142857143], 'Precision': [0.6290130796670631, 0.8583743842364532, 0.8583743842364532, 0.6747448979591837, 0.6693121693121693], 'Recall': [0.7931034482758621, 0.8275862068965517, 0.8275862068965517, 0.8214285714285714, 0.7857142857142857], 'AUROC': [0.6268115942028986, 0.6304347826086957, 0.7210144927536233, 0.7608695652173914, 0.5391304347826087]}, 'svc': {'Accuracy': [0.7931034482758621, 0.7931034482758621, 0.7931034482758621, 0.8214285714285714, 0.8214285714285714], 'F1': [0.7015915119363395, 0.7015915119363395, 0.7015915119363395, 0.7408963585434174, 0.7408963585434174], 'Precision': [0.6290130796670631, 0.6290130796670631, 0.6290130796670631, 0.6747448979591837, 0.6747448979591837], 'Recall': [0.7931034482758621, 0.7931034482758621, 0.7931034482758621, 0.8214285714285714, 0.8214285714285714], 'AUROC': [0.6956521739130436, 0.6304347826086957, 0.7246376811594203, 0.8347826086956522, 0.5478260869565218]}, 'random_forest': {'Accuracy': [0.7931034482758621, 0.7931034482758621, 0.6896551724137931, 0.8214285714285714, 0.8214285714285714], 'F1': [0.7015915119363395, 0.7015915119363395, 0.6474313863476425, 0.7408963585434174, 0.7408963585434174], 'Precision': [0.6290130796670631, 0.6290130796670631, 0.610079575596817, 0.6747448979591837, 0.6747448979591837], 'Recall': [0.7931034482758621, 0.7931034482758621, 0.6896551724137931, 0.8214285714285714, 0.8214285714285714], 'AUROC': [0.641304347826087, 0.818840579710145, 0.6521739130434783, 0.5782608695652174, 0.48695652173913045]}, 'mlp': {'Accuracy': [0.7931034482758621, 0.7586206896551724, 0.6896551724137931, 0.8214285714285714, 0.6785714285714286], 'F1': [0.7015915119363395, 0.7257799671592775, 0.6981432360742706, 0.7886297376093295, 0.6896103896103897], 'Precision': [0.6290130796670631, 0.7095490716180372, 0.7080161218092254, 0.7843406593406593, 0.7018398268398268], 'Recall': [0.7931034482758621, 0.7586206896551724, 0.6896551724137931, 0.8214285714285714, 0.6785714285714286], 'AUROC': [0.6014492753623188, 0.6884057971014492, 0.5869565217391304, 0.6695652173913044, 0.6086956521739131]}, 'xgboost': {'Accuracy': [0.7931034482758621, 0.7931034482758621, 0.7931034482758621, 0.8214285714285714, 0.7857142857142857], 'F1': [0.7015915119363395, 0.7015915119363395, 0.7015915119363395, 0.7408963585434174, 0.722857142857143], 'Precision': [0.6290130796670631, 0.6290130796670631, 0.6290130796670631, 0.6747448979591837, 0.6693121693121693], 'Recall': [0.7931034482758621, 0.7931034482758621, 0.7931034482758621, 0.8214285714285714, 0.7857142857142857], 'AUROC': [0.35507246376811596, 0.5, 0.644927536231884, 0.7652173913043478, 0.6086956521739131]}}\n",
      "======= Predicting StfTStage with model version 70 =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:11:39 | patch_ds:LIDCPatchAugDataset] patient split: train:699, val:88, test:88\n",
      "[05-19 17:11:39 | patch_ds:LNDbPatch32AugDataset] patient split: train:168, val:22, test:22\n",
      "[05-19 17:11:39 | patch_stanfordradiogenomics:StanfordRadiogenomicsPatchAugDataset] patient split: train:100, test:43\n",
      "[05-19 17:11:39 | export:  Exporter] initializing embeddings\n",
      "[05-19 17:11:42 | patch_ds:LIDCPatchAugDataset] patient split: train:699, val:88, test:88\n",
      "[05-19 17:11:43 | patch_ds:LNDbPatch32AugDataset] patient split: train:168, val:22, test:22\n",
      "[05-19 17:11:43 | patch_stanfordradiogenomics:StanfordRadiogenomicsPatchAugDataset] patient split: train:100, test:43\n",
      "[05-19 17:11:43 | application_cross_validation:ApplicationCV] -----CV prediction for task StfTStage-----\n",
      "[05-19 17:11:43 | application:ApplicationCV] Loading best hparams ...\n",
      "[05-19 17:11:43 | cv_models:cv_predict_task] models used ['logistic_regression', 'k_nearest_neighbors', 'svc', 'random_forest', 'mlp', 'xgboost']\n",
      "[05-19 17:11:43 | cv_models:cv_predict_task] Before transform: X shape = train:(100, 4096), val:(43, 4096); Y shape = train:(100,), val:(43,)\n",
      "[05-19 17:11:43 | models:data_summary] X shape = train:(97, 4096), val:(40, 4096); Y shape = train:(97,), val:(40,)\n",
      "Y classes = \n",
      " train: \n",
      "  value count\n",
      "0    T1    48\n",
      "1   T2+    49; \n",
      " val: \n",
      "  value count\n",
      "0    T1    19\n",
      "1   T2+    21\n",
      "[05-19 17:11:43 | cv_models:cv_predict_eval_with_model] ======logistic_regression======\n",
      "[05-19 17:11:43 | models:predict_with_model] ======logistic_regression======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | 4.0 secs.\n",
      "initializing | 8.0 secs.\n",
      "train Counter({'T2+': 56, 'T1': 53}) test Counter({'T1': 14, 'T2+': 14})\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[05-19 17:11:46 | models:grid_cv_model] best parameters: {'predictor__C': 0.1}\n",
      "[05-19 17:11:46 | models:predict_with_model] result for CV:{'split0_test_score': array([0.51351351, 0.62162162]), 'split1_test_score': array([0.5       , 0.66666667]), 'split2_test_score': array([0.52777778, 0.63888889]), 'mean_test_score': array([0.51376376, 0.64239239]), 'std_test_score': array([0.01134161, 0.01855568]), 'rank_test_score': array([2, 1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[05-19 17:11:47 | models:predict_with_model] result for validation set:{'Accuracy': 0.6785714285714286, 'F1': 0.6781609195402298, 'Precision': 0.6794871794871794, 'Recall': 0.6785714285714286, 'AUROC': 0.6479591836734694}\n",
      "[05-19 17:11:47 | models:predict_with_model] ======logistic_regression======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "train Counter({'T2+': 56, 'T1': 53}) test Counter({'T1': 14, 'T2+': 14})\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[05-19 17:11:49 | models:grid_cv_model] best parameters: {'predictor__C': 0.1}\n",
      "[05-19 17:11:49 | models:predict_with_model] result for CV:{'split0_test_score': array([0.45945946, 0.7027027 ]), 'split1_test_score': array([0.47222222, 0.75      ]), 'split2_test_score': array([0.47222222, 0.63888889]), 'mean_test_score': array([0.46796797, 0.6971972 ]), 'std_test_score': array([0.00601642, 0.04552767]), 'rank_test_score': array([2, 1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[05-19 17:11:50 | models:predict_with_model] result for validation set:{'Accuracy': 0.5, 'F1': 0.49743589743589745, 'Precision': 0.5, 'Recall': 0.5, 'AUROC': 0.5408163265306123}\n",
      "[05-19 17:11:50 | models:predict_with_model] ======logistic_regression======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "train Counter({'T2+': 56, 'T1': 54}) test Counter({'T2+': 14, 'T1': 13})\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[05-19 17:11:52 | models:grid_cv_model] best parameters: {'predictor__C': 0.1}\n",
      "[05-19 17:11:52 | models:predict_with_model] result for CV:{'split0_test_score': array([0.48648649, 0.62162162]), 'split1_test_score': array([0.51351351, 0.59459459]), 'split2_test_score': array([0.47222222, 0.5       ]), 'mean_test_score': array([0.49074074, 0.57207207]), 'std_test_score': array([0.01712341, 0.05214341]), 'rank_test_score': array([2, 1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[05-19 17:11:53 | models:predict_with_model] result for validation set:{'Accuracy': 0.5925925925925926, 'F1': 0.5914687100893997, 'Precision': 0.5919753086419753, 'Recall': 0.5925925925925926, 'AUROC': 0.6978021978021978}\n",
      "[05-19 17:11:53 | models:predict_with_model] ======logistic_regression======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "train Counter({'T2+': 56, 'T1': 54}) test Counter({'T2+': 14, 'T1': 13})\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[05-19 17:11:56 | models:grid_cv_model] best parameters: {'predictor__C': 0.1}\n",
      "[05-19 17:11:56 | models:predict_with_model] result for CV:{'split0_test_score': array([0.51351351, 0.56756757]), 'split1_test_score': array([0.37837838, 0.54054054]), 'split2_test_score': array([0.41666667, 0.5       ]), 'mean_test_score': array([0.43618619, 0.53603604]), 'std_test_score': array([0.05686906, 0.02776763]), 'rank_test_score': array([2, 1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[05-19 17:11:57 | models:predict_with_model] result for validation set:{'Accuracy': 0.7777777777777778, 'F1': 0.7771672771672771, 'Precision': 0.7851851851851853, 'Recall': 0.7777777777777778, 'AUROC': 0.7967032967032966}\n",
      "[05-19 17:11:57 | models:predict_with_model] ======logistic_regression======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "train Counter({'T2+': 56, 'T1': 54}) test Counter({'T2+': 14, 'T1': 13})\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[05-19 17:11:59 | models:grid_cv_model] best parameters: {'predictor__C': 0.1}\n",
      "[05-19 17:11:59 | models:predict_with_model] result for CV:{'split0_test_score': array([0.56756757, 0.64864865]), 'split1_test_score': array([0.45945946, 0.64864865]), 'split2_test_score': array([0.41666667, 0.55555556]), 'mean_test_score': array([0.48123123, 0.61761762]), 'std_test_score': array([0.06349949, 0.0438845 ]), 'rank_test_score': array([2, 1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[05-19 17:12:00 | models:predict_with_model] result for validation set:{'Accuracy': 0.6666666666666666, 'F1': 0.6639080459770115, 'Precision': 0.678030303030303, 'Recall': 0.6666666666666666, 'AUROC': 0.6263736263736264}\n",
      "[05-19 17:12:00 | cv_models:cv_predict_eval_with_model] ======k_nearest_neighbors======\n",
      "[05-19 17:12:00 | models:predict_with_model] ======k_nearest_neighbors======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "train Counter({'T2+': 56, 'T1': 53}) test Counter({'T1': 14, 'T2+': 14})\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:12:02 | models:grid_cv_model] best parameters: {'predictor__n_neighbors': 3, 'predictor__p': 5}\n",
      "[05-19 17:12:02 | models:predict_with_model] result for CV:{'split0_test_score': array([0.59459459, 0.62162162, 0.67567568, 0.62162162, 0.67567568,\n",
      "       0.56756757, 0.59459459, 0.62162162, 0.62162162, 0.67567568,\n",
      "       0.7027027 , 0.64864865]), 'split1_test_score': array([0.52777778, 0.63888889, 0.52777778, 0.58333333, 0.58333333,\n",
      "       0.5       , 0.58333333, 0.52777778, 0.55555556, 0.63888889,\n",
      "       0.5       , 0.58333333]), 'split2_test_score': array([0.61111111, 0.63888889, 0.80555556, 0.61111111, 0.63888889,\n",
      "       0.72222222, 0.61111111, 0.66666667, 0.66666667, 0.58333333,\n",
      "       0.55555556, 0.66666667]), 'mean_test_score': array([0.57782783, 0.63313313, 0.66966967, 0.60535536, 0.63263263,\n",
      "       0.5965966 , 0.59634635, 0.60535536, 0.61461461, 0.63263263,\n",
      "       0.58608609, 0.63288288]), 'std_test_score': array([0.03602735, 0.00813987, 0.1134818 , 0.01615229, 0.03795728,\n",
      "       0.09301503, 0.01140768, 0.057856  , 0.04563072, 0.03795728,\n",
      "       0.08552263, 0.03580066]), 'rank_test_score': array([12,  2,  1,  7,  4,  9, 10,  7,  6,  4, 11,  3], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:12:03 | models:predict_with_model] result for validation set:{'Accuracy': 0.6428571428571429, 'F1': 0.6410256410256411, 'Precision': 0.6458333333333333, 'Recall': 0.6428571428571429, 'AUROC': 0.7091836734693877}\n",
      "[05-19 17:12:03 | models:predict_with_model] ======k_nearest_neighbors======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Counter({'T2+': 56, 'T1': 53}) test Counter({'T1': 14, 'T2+': 14})\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:12:05 | models:grid_cv_model] best parameters: {'predictor__n_neighbors': 7, 'predictor__p': 1}\n",
      "[05-19 17:12:05 | models:predict_with_model] result for CV:{'split0_test_score': array([0.62162162, 0.56756757, 0.56756757, 0.54054054, 0.54054054,\n",
      "       0.59459459, 0.59459459, 0.59459459, 0.59459459, 0.62162162,\n",
      "       0.59459459, 0.56756757]), 'split1_test_score': array([0.69444444, 0.69444444, 0.75      , 0.72222222, 0.72222222,\n",
      "       0.72222222, 0.72222222, 0.75      , 0.72222222, 0.75      ,\n",
      "       0.72222222, 0.66666667]), 'split2_test_score': array([0.61111111, 0.55555556, 0.63888889, 0.66666667, 0.61111111,\n",
      "       0.63888889, 0.69444444, 0.61111111, 0.61111111, 0.61111111,\n",
      "       0.66666667, 0.63888889]), 'mean_test_score': array([0.64239239, 0.60585586, 0.65215215, 0.64314314, 0.62462462,\n",
      "       0.6519019 , 0.67042042, 0.6519019 , 0.64264264, 0.66091091,\n",
      "       0.66116116, 0.62437437]), 'std_test_score': array([0.03705563, 0.06283325, 0.0750659 , 0.07601349, 0.07478422,\n",
      "       0.05291003, 0.05480309, 0.06969279, 0.05667381, 0.06314147,\n",
      "       0.05224899, 0.04173856]), 'rank_test_score': array([ 9, 12,  4,  7, 10,  6,  1,  5,  8,  3,  2, 11], dtype=int32)}\n",
      "[05-19 17:12:05 | models:predict_with_model] result for validation set:{'Accuracy': 0.5357142857142857, 'F1': 0.520421607378129, 'Precision': 0.5409356725146199, 'Recall': 0.5357142857142857, 'AUROC': 0.6198979591836735}\n",
      "[05-19 17:12:05 | models:predict_with_model] ======k_nearest_neighbors======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "train Counter({'T2+': 56, 'T1': 54}) test Counter({'T2+': 14, 'T1': 13})\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:12:07 | models:grid_cv_model] best parameters: {'predictor__n_neighbors': 7, 'predictor__p': 5}\n",
      "[05-19 17:12:07 | models:predict_with_model] result for CV:{'split0_test_score': array([0.62162162, 0.56756757, 0.54054054, 0.59459459, 0.56756757,\n",
      "       0.59459459, 0.56756757, 0.64864865, 0.62162162, 0.56756757,\n",
      "       0.51351351, 0.45945946]), 'split1_test_score': array([0.59459459, 0.64864865, 0.62162162, 0.54054054, 0.59459459,\n",
      "       0.56756757, 0.59459459, 0.54054054, 0.56756757, 0.54054054,\n",
      "       0.62162162, 0.59459459]), 'split2_test_score': array([0.58333333, 0.61111111, 0.61111111, 0.52777778, 0.58333333,\n",
      "       0.66666667, 0.52777778, 0.52777778, 0.77777778, 0.44444444,\n",
      "       0.52777778, 0.72222222]), 'mean_test_score': array([0.59984985, 0.60910911, 0.59109109, 0.5543043 , 0.58183183,\n",
      "       0.60960961, 0.56331331, 0.57232232, 0.65565566, 0.51751752,\n",
      "       0.5543043 , 0.59209209]), 'std_test_score': array([0.01606677, 0.03313147, 0.03600126, 0.02896207, 0.0110847 ,\n",
      "       0.04182699, 0.02744322, 0.05422179, 0.08912845, 0.05283541,\n",
      "       0.04795542, 0.10728704]), 'rank_test_score': array([ 4,  3,  6, 10,  7,  2,  9,  8,  1, 12, 10,  5], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:12:07 | models:predict_with_model] result for validation set:{'Accuracy': 0.7037037037037037, 'F1': 0.7012345679012347, 'Precision': 0.7066498316498316, 'Recall': 0.7037037037037037, 'AUROC': 0.6978021978021978}\n",
      "[05-19 17:12:07 | models:predict_with_model] ======k_nearest_neighbors======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Counter({'T2+': 56, 'T1': 54}) test Counter({'T2+': 14, 'T1': 13})\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:12:10 | models:grid_cv_model] best parameters: {'predictor__n_neighbors': 7, 'predictor__p': 5}\n",
      "[05-19 17:12:10 | models:predict_with_model] result for CV:{'split0_test_score': array([0.40540541, 0.43243243, 0.43243243, 0.45945946, 0.43243243,\n",
      "       0.51351351, 0.37837838, 0.40540541, 0.51351351, 0.45945946,\n",
      "       0.48648649, 0.51351351]), 'split1_test_score': array([0.48648649, 0.59459459, 0.59459459, 0.56756757, 0.62162162,\n",
      "       0.54054054, 0.59459459, 0.59459459, 0.56756757, 0.56756757,\n",
      "       0.54054054, 0.51351351]), 'split2_test_score': array([0.61111111, 0.66666667, 0.63888889, 0.69444444, 0.63888889,\n",
      "       0.61111111, 0.66666667, 0.72222222, 0.69444444, 0.69444444,\n",
      "       0.69444444, 0.69444444]), 'mean_test_score': array([0.501001  , 0.56456456, 0.55530531, 0.57382382, 0.56431431,\n",
      "       0.55505506, 0.54654655, 0.57407407, 0.59184184, 0.57382382,\n",
      "       0.57382382, 0.57382382]), 'std_test_score': array([0.08460383, 0.09795499, 0.08874609, 0.09603417, 0.09352063,\n",
      "       0.04114467, 0.12249897, 0.1301513 , 0.07583285, 0.09603417,\n",
      "       0.08810017, 0.08529166]), 'rank_test_score': array([12,  7,  9,  4,  8, 10, 11,  2,  1,  4,  3,  4], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:12:10 | models:predict_with_model] result for validation set:{'Accuracy': 0.6296296296296297, 'F1': 0.6296296296296297, 'Precision': 0.6296296296296297, 'Recall': 0.6296296296296297, 'AUROC': 0.7747252747252746}\n",
      "[05-19 17:12:10 | models:predict_with_model] ======k_nearest_neighbors======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Counter({'T2+': 56, 'T1': 54}) test Counter({'T2+': 14, 'T1': 13})\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:12:12 | models:grid_cv_model] best parameters: {'predictor__n_neighbors': 3, 'predictor__p': 5}\n",
      "[05-19 17:12:12 | models:predict_with_model] result for CV:{'split0_test_score': array([0.75675676, 0.62162162, 0.7027027 , 0.62162162, 0.59459459,\n",
      "       0.62162162, 0.56756757, 0.56756757, 0.59459459, 0.59459459,\n",
      "       0.59459459, 0.56756757]), 'split1_test_score': array([0.59459459, 0.64864865, 0.67567568, 0.51351351, 0.59459459,\n",
      "       0.64864865, 0.54054054, 0.56756757, 0.64864865, 0.56756757,\n",
      "       0.56756757, 0.48648649]), 'split2_test_score': array([0.44444444, 0.5       , 0.52777778, 0.55555556, 0.61111111,\n",
      "       0.52777778, 0.52777778, 0.5       , 0.63888889, 0.52777778,\n",
      "       0.47222222, 0.61111111]), 'mean_test_score': array([0.5985986 , 0.59009009, 0.63538539, 0.56356356, 0.6001001 ,\n",
      "       0.59934935, 0.5452953 , 0.54504505, 0.62737738, 0.56331331,\n",
      "       0.54479479, 0.55505506]), 'std_test_score': array([0.1275324 , 0.0646518 , 0.0768859 , 0.04449672, 0.00778596,\n",
      "       0.05179757, 0.0165884 , 0.03185166, 0.02352086, 0.02744322,\n",
      "       0.05248936, 0.05164137]), 'rank_test_score': array([ 5,  6,  1,  7,  3,  4, 10, 11,  2,  8, 12,  9], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:12:12 | models:predict_with_model] result for validation set:{'Accuracy': 0.48148148148148145, 'F1': 0.47716049382716047, 'Precision': 0.47811447811447816, 'Recall': 0.48148148148148145, 'AUROC': 0.510989010989011}\n",
      "[05-19 17:12:12 | cv_models:cv_predict_eval_with_model] ======svc======\n",
      "[05-19 17:12:12 | models:predict_with_model] ======svc======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Counter({'T2+': 56, 'T1': 53}) test Counter({'T1': 14, 'T2+': 14})\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:12:14 | models:grid_cv_model] best parameters: {'predictor__C': 1, 'predictor__degree': 1}\n",
      "[05-19 17:12:14 | models:predict_with_model] result for CV:{'split0_test_score': array([0.51351351, 0.51351351, 0.51351351, 0.51351351, 0.51351351,\n",
      "       0.51351351, 0.67567568, 0.67567568, 0.67567568]), 'split1_test_score': array([0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
      "       0.5       , 0.61111111, 0.61111111, 0.61111111]), 'split2_test_score': array([0.52777778, 0.52777778, 0.52777778, 0.52777778, 0.52777778,\n",
      "       0.52777778, 0.61111111, 0.61111111, 0.61111111]), 'mean_test_score': array([0.51376376, 0.51376376, 0.51376376, 0.51376376, 0.51376376,\n",
      "       0.51376376, 0.63263263, 0.63263263, 0.63263263]), 'std_test_score': array([0.01134161, 0.01134161, 0.01134161, 0.01134161, 0.01134161,\n",
      "       0.01134161, 0.03043603, 0.03043603, 0.03043603]), 'rank_test_score': array([4, 4, 4, 4, 4, 4, 1, 1, 1], dtype=int32)}\n",
      "[05-19 17:12:14 | models:predict_with_model] result for validation set:{'Accuracy': 0.6785714285714286, 'F1': 0.6781609195402298, 'Precision': 0.6794871794871794, 'Recall': 0.6785714285714286, 'AUROC': 0.7602040816326532}\n",
      "[05-19 17:12:14 | models:predict_with_model] ======svc======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "train Counter({'T2+': 56, 'T1': 53}) test Counter({'T1': 14, 'T2+': 14})\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:12:15 | models:grid_cv_model] best parameters: {'predictor__C': 1, 'predictor__degree': 1}\n",
      "[05-19 17:12:15 | models:predict_with_model] result for CV:{'split0_test_score': array([0.59459459, 0.59459459, 0.59459459, 0.59459459, 0.59459459,\n",
      "       0.59459459, 0.62162162, 0.62162162, 0.62162162]), 'split1_test_score': array([0.52777778, 0.52777778, 0.52777778, 0.52777778, 0.52777778,\n",
      "       0.52777778, 0.75      , 0.75      , 0.75      ]), 'split2_test_score': array([0.47222222, 0.47222222, 0.47222222, 0.47222222, 0.47222222,\n",
      "       0.47222222, 0.72222222, 0.72222222, 0.72222222]), 'mean_test_score': array([0.53153153, 0.53153153, 0.53153153, 0.53153153, 0.53153153,\n",
      "       0.53153153, 0.69794795, 0.69794795, 0.69794795]), 'std_test_score': array([0.05002877, 0.05002877, 0.05002877, 0.05002877, 0.05002877,\n",
      "       0.05002877, 0.05514939, 0.05514939, 0.05514939]), 'rank_test_score': array([4, 4, 4, 4, 4, 4, 1, 1, 1], dtype=int32)}\n",
      "[05-19 17:12:16 | models:predict_with_model] result for validation set:{'Accuracy': 0.5, 'F1': 0.5, 'Precision': 0.5, 'Recall': 0.5, 'AUROC': 0.44387755102040816}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:12:16 | models:predict_with_model] ======svc======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Counter({'T2+': 56, 'T1': 54}) test Counter({'T2+': 14, 'T1': 13})\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:12:17 | models:grid_cv_model] best parameters: {'predictor__C': 1, 'predictor__degree': 1}\n",
      "[05-19 17:12:17 | models:predict_with_model] result for CV:{'split0_test_score': array([0.48648649, 0.48648649, 0.48648649, 0.48648649, 0.48648649,\n",
      "       0.48648649, 0.64864865, 0.64864865, 0.64864865]), 'split1_test_score': array([0.51351351, 0.51351351, 0.51351351, 0.51351351, 0.51351351,\n",
      "       0.51351351, 0.54054054, 0.54054054, 0.54054054]), 'split2_test_score': array([0.66666667, 0.66666667, 0.66666667, 0.66666667, 0.66666667,\n",
      "       0.66666667, 0.77777778, 0.77777778, 0.77777778]), 'mean_test_score': array([0.55555556, 0.55555556, 0.55555556, 0.55555556, 0.55555556,\n",
      "       0.55555556, 0.65565566, 0.65565566, 0.65565566]), 'std_test_score': array([0.07933841, 0.07933841, 0.07933841, 0.07933841, 0.07933841,\n",
      "       0.07933841, 0.09697835, 0.09697835, 0.09697835]), 'rank_test_score': array([4, 4, 4, 4, 4, 4, 1, 1, 1], dtype=int32)}\n",
      "[05-19 17:12:17 | models:predict_with_model] result for validation set:{'Accuracy': 0.6666666666666666, 'F1': 0.6610565684899484, 'Precision': 0.6725490196078431, 'Recall': 0.6666666666666666, 'AUROC': 0.7582417582417583}\n",
      "[05-19 17:12:17 | models:predict_with_model] ======svc======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "train Counter({'T2+': 56, 'T1': 54}) test Counter({'T2+': 14, 'T1': 13})\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:12:19 | models:grid_cv_model] best parameters: {'predictor__C': 1, 'predictor__degree': 1}\n",
      "[05-19 17:12:19 | models:predict_with_model] result for CV:{'split0_test_score': array([0.48648649, 0.48648649, 0.48648649, 0.48648649, 0.48648649,\n",
      "       0.48648649, 0.59459459, 0.59459459, 0.59459459]), 'split1_test_score': array([0.37837838, 0.37837838, 0.37837838, 0.37837838, 0.37837838,\n",
      "       0.37837838, 0.59459459, 0.59459459, 0.59459459]), 'split2_test_score': array([0.41666667, 0.41666667, 0.41666667, 0.41666667, 0.41666667,\n",
      "       0.41666667, 0.61111111, 0.61111111, 0.61111111]), 'mean_test_score': array([0.42717718, 0.42717718, 0.42717718, 0.42717718, 0.42717718,\n",
      "       0.42717718, 0.6001001 , 0.6001001 , 0.6001001 ]), 'std_test_score': array([0.04475633, 0.04475633, 0.04475633, 0.04475633, 0.04475633,\n",
      "       0.04475633, 0.00778596, 0.00778596, 0.00778596]), 'rank_test_score': array([4, 4, 4, 4, 4, 4, 1, 1, 1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:12:19 | models:predict_with_model] result for validation set:{'Accuracy': 0.7407407407407407, 'F1': 0.7407407407407407, 'Precision': 0.7427757427757429, 'Recall': 0.7407407407407407, 'AUROC': 0.8076923076923077}\n",
      "[05-19 17:12:19 | models:predict_with_model] ======svc======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "train Counter({'T2+': 56, 'T1': 54}) test Counter({'T2+': 14, 'T1': 13})\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:12:20 | models:grid_cv_model] best parameters: {'predictor__C': 1, 'predictor__degree': 1}\n",
      "[05-19 17:12:20 | models:predict_with_model] result for CV:{'split0_test_score': array([0.43243243, 0.43243243, 0.43243243, 0.43243243, 0.43243243,\n",
      "       0.43243243, 0.56756757, 0.56756757, 0.56756757]), 'split1_test_score': array([0.45945946, 0.45945946, 0.45945946, 0.45945946, 0.45945946,\n",
      "       0.45945946, 0.78378378, 0.78378378, 0.78378378]), 'split2_test_score': array([0.41666667, 0.41666667, 0.41666667, 0.41666667, 0.41666667,\n",
      "       0.41666667, 0.55555556, 0.55555556, 0.55555556]), 'mean_test_score': array([0.43618619, 0.43618619, 0.43618619, 0.43618619, 0.43618619,\n",
      "       0.43618619, 0.63563564, 0.63563564, 0.63563564]), 'std_test_score': array([0.01767057, 0.01767057, 0.01767057, 0.01767057, 0.01767057,\n",
      "       0.01767057, 0.10487128, 0.10487128, 0.10487128]), 'rank_test_score': array([4, 4, 4, 4, 4, 4, 1, 1, 1], dtype=int32)}\n",
      "[05-19 17:12:20 | models:predict_with_model] result for validation set:{'Accuracy': 0.6666666666666666, 'F1': 0.6573165030388032, 'Precision': 0.697530864197531, 'Recall': 0.6666666666666666, 'AUROC': 0.7637362637362637}\n",
      "[05-19 17:12:20 | cv_models:cv_predict_eval_with_model] ======random_forest======\n",
      "[05-19 17:12:20 | models:predict_with_model] ======random_forest======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "train Counter({'T2+': 56, 'T1': 53}) test Counter({'T1': 14, 'T2+': 14})\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:12:54 | models:grid_cv_model] best parameters: {'predictor__max_depth': 10, 'predictor__max_features': 'auto', 'predictor__min_samples_leaf': 1, 'predictor__n_estimators': 500}\n",
      "[05-19 17:12:54 | models:predict_with_model] result for CV:{'split0_test_score': array([0.67567568, 0.62162162, 0.62162162, 0.62162162, 0.62162162,\n",
      "       0.62162162, 0.62162162, 0.64864865, 0.67567568, 0.62162162,\n",
      "       0.62162162, 0.62162162, 0.62162162, 0.62162162, 0.62162162,\n",
      "       0.64864865]), 'split1_test_score': array([0.58333333, 0.55555556, 0.66666667, 0.63888889, 0.63888889,\n",
      "       0.58333333, 0.66666667, 0.66666667, 0.58333333, 0.55555556,\n",
      "       0.66666667, 0.63888889, 0.63888889, 0.58333333, 0.66666667,\n",
      "       0.66666667]), 'split2_test_score': array([0.63888889, 0.63888889, 0.63888889, 0.63888889, 0.58333333,\n",
      "       0.58333333, 0.58333333, 0.61111111, 0.63888889, 0.63888889,\n",
      "       0.63888889, 0.63888889, 0.58333333, 0.58333333, 0.58333333,\n",
      "       0.61111111]), 'mean_test_score': array([0.63263263, 0.60535536, 0.64239239, 0.63313313, 0.61461461,\n",
      "       0.5960961 , 0.62387387, 0.64214214, 0.63263263, 0.60535536,\n",
      "       0.64239239, 0.63313313, 0.61461461, 0.5960961 , 0.62387387,\n",
      "       0.64214214]), 'std_test_score': array([0.03795728, 0.03591244, 0.01855568, 0.00813987, 0.02321535,\n",
      "       0.01804927, 0.03405795, 0.0231424 , 0.03795728, 0.03591244,\n",
      "       0.01855568, 0.00813987, 0.02321535, 0.01804927, 0.03405795,\n",
      "       0.0231424 ]), 'rank_test_score': array([ 7, 13,  1,  5, 11, 15,  9,  3,  7, 13,  1,  5, 11, 15,  9,  3],\n",
      "      dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:12:55 | models:predict_with_model] result for validation set:{'Accuracy': 0.75, 'F1': 0.7470967741935485, 'Precision': 0.7620320855614973, 'Recall': 0.75, 'AUROC': 0.7602040816326531}\n",
      "[05-19 17:12:55 | models:predict_with_model] ======random_forest======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "train Counter({'T2+': 56, 'T1': 53}) test Counter({'T1': 14, 'T2+': 14})\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:13:28 | models:grid_cv_model] best parameters: {'predictor__max_depth': 10, 'predictor__max_features': 'auto', 'predictor__min_samples_leaf': 1, 'predictor__n_estimators': 1000}\n",
      "[05-19 17:13:28 | models:predict_with_model] result for CV:{'split0_test_score': array([0.67567568, 0.64864865, 0.62162162, 0.64864865, 0.64864865,\n",
      "       0.67567568, 0.64864865, 0.64864865, 0.67567568, 0.64864865,\n",
      "       0.62162162, 0.64864865, 0.64864865, 0.67567568, 0.64864865,\n",
      "       0.64864865]), 'split1_test_score': array([0.72222222, 0.75      , 0.75      , 0.75      , 0.75      ,\n",
      "       0.75      , 0.75      , 0.75      , 0.72222222, 0.75      ,\n",
      "       0.75      , 0.75      , 0.75      , 0.75      , 0.75      ,\n",
      "       0.75      ]), 'split2_test_score': array([0.63888889, 0.66666667, 0.72222222, 0.75      , 0.66666667,\n",
      "       0.69444444, 0.69444444, 0.75      , 0.63888889, 0.66666667,\n",
      "       0.72222222, 0.75      , 0.66666667, 0.69444444, 0.69444444,\n",
      "       0.75      ]), 'mean_test_score': array([0.67892893, 0.68843844, 0.69794795, 0.71621622, 0.68843844,\n",
      "       0.70670671, 0.6976977 , 0.71621622, 0.67892893, 0.68843844,\n",
      "       0.69794795, 0.71621622, 0.68843844, 0.70670671, 0.6976977 ,\n",
      "       0.71621622]), 'std_test_score': array([0.03409838, 0.04414772, 0.05514939, 0.04777749, 0.04414772,\n",
      "       0.03155734, 0.04144041, 0.04777749, 0.03409838, 0.04414772,\n",
      "       0.05514939, 0.04777749, 0.04414772, 0.03155734, 0.04144041,\n",
      "       0.04777749]), 'rank_test_score': array([15, 11,  7,  1, 11,  5,  9,  1, 15, 11,  7,  1, 11,  5,  9,  1],\n",
      "      dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:13:30 | models:predict_with_model] result for validation set:{'Accuracy': 0.4642857142857143, 'F1': 0.46360153256704983, 'Precision': 0.4641025641025641, 'Recall': 0.4642857142857143, 'AUROC': 0.4489795918367347}\n",
      "[05-19 17:13:30 | models:predict_with_model] ======random_forest======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Counter({'T2+': 56, 'T1': 54}) test Counter({'T2+': 14, 'T1': 13})\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:14:02 | models:grid_cv_model] best parameters: {'predictor__max_depth': 10, 'predictor__max_features': 'auto', 'predictor__min_samples_leaf': 4, 'predictor__n_estimators': 500}\n",
      "[05-19 17:14:02 | models:predict_with_model] result for CV:{'split0_test_score': array([0.56756757, 0.56756757, 0.67567568, 0.64864865, 0.59459459,\n",
      "       0.56756757, 0.64864865, 0.64864865, 0.56756757, 0.56756757,\n",
      "       0.67567568, 0.64864865, 0.59459459, 0.56756757, 0.64864865,\n",
      "       0.64864865]), 'split1_test_score': array([0.48648649, 0.48648649, 0.51351351, 0.51351351, 0.51351351,\n",
      "       0.51351351, 0.51351351, 0.51351351, 0.48648649, 0.48648649,\n",
      "       0.51351351, 0.51351351, 0.51351351, 0.51351351, 0.51351351,\n",
      "       0.51351351]), 'split2_test_score': array([0.66666667, 0.77777778, 0.80555556, 0.77777778, 0.66666667,\n",
      "       0.80555556, 0.83333333, 0.83333333, 0.66666667, 0.77777778,\n",
      "       0.80555556, 0.77777778, 0.66666667, 0.80555556, 0.83333333,\n",
      "       0.83333333]), 'mean_test_score': array([0.57357357, 0.61061061, 0.66491491, 0.64664665, 0.59159159,\n",
      "       0.62887888, 0.66516517, 0.66516517, 0.57357357, 0.61061061,\n",
      "       0.66491491, 0.64664665, 0.59159159, 0.62887888, 0.66516517,\n",
      "       0.66516517]), 'std_test_score': array([0.07368075, 0.12275228, 0.11946822, 0.10789472, 0.06256056,\n",
      "       0.1268633 , 0.13108719, 0.13108719, 0.07368075, 0.12275228,\n",
      "       0.11946822, 0.10789472, 0.06256056, 0.1268633 , 0.13108719,\n",
      "       0.13108719]), 'rank_test_score': array([15, 11,  5,  7, 13,  9,  1,  1, 15, 11,  5,  7, 13,  9,  1,  1],\n",
      "      dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:14:03 | models:predict_with_model] result for validation set:{'Accuracy': 0.6296296296296297, 'F1': 0.6191077441077442, 'Precision': 0.6378600823045267, 'Recall': 0.6296296296296297, 'AUROC': 0.7582417582417583}\n",
      "[05-19 17:14:03 | models:predict_with_model] ======random_forest======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "train Counter({'T2+': 56, 'T1': 54}) test Counter({'T2+': 14, 'T1': 13})\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:14:36 | models:grid_cv_model] best parameters: {'predictor__max_depth': 10, 'predictor__max_features': 'auto', 'predictor__min_samples_leaf': 1, 'predictor__n_estimators': 100}\n",
      "[05-19 17:14:36 | models:predict_with_model] result for CV:{'split0_test_score': array([0.62162162, 0.56756757, 0.62162162, 0.62162162, 0.59459459,\n",
      "       0.54054054, 0.62162162, 0.59459459, 0.62162162, 0.56756757,\n",
      "       0.62162162, 0.62162162, 0.59459459, 0.54054054, 0.62162162,\n",
      "       0.59459459]), 'split1_test_score': array([0.51351351, 0.45945946, 0.51351351, 0.54054054, 0.51351351,\n",
      "       0.54054054, 0.56756757, 0.59459459, 0.51351351, 0.45945946,\n",
      "       0.51351351, 0.54054054, 0.51351351, 0.54054054, 0.56756757,\n",
      "       0.59459459]), 'split2_test_score': array([0.75      , 0.72222222, 0.61111111, 0.63888889, 0.63888889,\n",
      "       0.63888889, 0.63888889, 0.61111111, 0.75      , 0.72222222,\n",
      "       0.61111111, 0.63888889, 0.63888889, 0.63888889, 0.63888889,\n",
      "       0.61111111]), 'mean_test_score': array([0.62837838, 0.58308308, 0.58208208, 0.60035035, 0.58233233,\n",
      "       0.57332332, 0.60935936, 0.6001001 , 0.62837838, 0.58308308,\n",
      "       0.58208208, 0.60035035, 0.58233233, 0.57332332, 0.60935936,\n",
      "       0.6001001 ]), 'std_test_score': array([0.09666335, 0.10783202, 0.0486748 , 0.0428754 , 0.05191351,\n",
      "       0.04636186, 0.03038042, 0.00778596, 0.09666335, 0.10783202,\n",
      "       0.0486748 , 0.0428754 , 0.05191351, 0.04636186, 0.03038042,\n",
      "       0.00778596]), 'rank_test_score': array([ 1,  9, 13,  5, 11, 15,  3,  7,  1,  9, 13,  5, 11, 15,  3,  7],\n",
      "      dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:14:36 | models:predict_with_model] result for validation set:{'Accuracy': 0.6666666666666666, 'F1': 0.6657471264367816, 'Precision': 0.6666666666666666, 'Recall': 0.6666666666666666, 'AUROC': 0.7912087912087913}\n",
      "[05-19 17:14:36 | models:predict_with_model] ======random_forest======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Counter({'T2+': 56, 'T1': 54}) test Counter({'T2+': 14, 'T1': 13})\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:15:09 | models:grid_cv_model] best parameters: {'predictor__max_depth': 10, 'predictor__max_features': 'auto', 'predictor__min_samples_leaf': 4, 'predictor__n_estimators': 1000}\n",
      "[05-19 17:15:09 | models:predict_with_model] result for CV:{'split0_test_score': array([0.59459459, 0.56756757, 0.56756757, 0.59459459, 0.62162162,\n",
      "       0.56756757, 0.56756757, 0.59459459, 0.59459459, 0.56756757,\n",
      "       0.56756757, 0.59459459, 0.62162162, 0.56756757, 0.56756757,\n",
      "       0.59459459]), 'split1_test_score': array([0.64864865, 0.72972973, 0.72972973, 0.72972973, 0.64864865,\n",
      "       0.67567568, 0.7027027 , 0.72972973, 0.64864865, 0.72972973,\n",
      "       0.72972973, 0.72972973, 0.64864865, 0.67567568, 0.7027027 ,\n",
      "       0.72972973]), 'split2_test_score': array([0.61111111, 0.58333333, 0.55555556, 0.55555556, 0.58333333,\n",
      "       0.61111111, 0.55555556, 0.58333333, 0.61111111, 0.58333333,\n",
      "       0.55555556, 0.55555556, 0.58333333, 0.61111111, 0.55555556,\n",
      "       0.58333333]), 'mean_test_score': array([0.61811812, 0.62687688, 0.61761762, 0.62662663, 0.61786787,\n",
      "       0.61811812, 0.60860861, 0.63588589, 0.61811812, 0.62687688,\n",
      "       0.61761762, 0.62662663, 0.61786787, 0.61811812, 0.60860861,\n",
      "       0.63588589]), 'std_test_score': array([0.02261686, 0.0730122 , 0.07942676, 0.07462662, 0.02679665,\n",
      "       0.04441219, 0.06671505, 0.06651669, 0.02261686, 0.0730122 ,\n",
      "       0.07942676, 0.07462662, 0.02679665, 0.04441219, 0.06671505,\n",
      "       0.06651669]), 'rank_test_score': array([ 7,  3, 13,  5, 11,  9, 15,  1,  7,  3, 13,  5, 11,  9, 15,  1],\n",
      "      dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:15:11 | models:predict_with_model] result for validation set:{'Accuracy': 0.6666666666666666, 'F1': 0.6573165030388032, 'Precision': 0.697530864197531, 'Recall': 0.6666666666666666, 'AUROC': 0.7527472527472527}\n",
      "[05-19 17:15:11 | cv_models:cv_predict_eval_with_model] ======mlp======\n",
      "[05-19 17:15:11 | models:predict_with_model] ======mlp======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Counter({'T2+': 56, 'T1': 53}) test Counter({'T1': 14, 'T2+': 14})\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:15:21 | models:grid_cv_model] best parameters: {'predictor__hidden_layer_sizes': (100, 10)}\n",
      "[05-19 17:15:21 | models:predict_with_model] result for CV:{'split0_test_score': array([0.64864865, 0.64864865, 0.64864865, 0.62162162]), 'split1_test_score': array([0.66666667, 0.61111111, 0.63888889, 0.63888889]), 'split2_test_score': array([0.61111111, 0.66666667, 0.61111111, 0.61111111]), 'mean_test_score': array([0.64214214, 0.64214214, 0.63288288, 0.62387387]), 'std_test_score': array([0.0231424 , 0.0231424 , 0.01590222, 0.01145151]), 'rank_test_score': array([1, 1, 3, 4], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:15:22 | models:predict_with_model] result for validation set:{'Accuracy': 0.7142857142857143, 'F1': 0.7128205128205128, 'Precision': 0.71875, 'Recall': 0.7142857142857143, 'AUROC': 0.7244897959183674}\n",
      "[05-19 17:15:22 | models:predict_with_model] ======mlp======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "train Counter({'T2+': 56, 'T1': 53}) test Counter({'T1': 14, 'T2+': 14})\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.5s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   2.0s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   2.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.7s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:15:33 | models:grid_cv_model] best parameters: {'predictor__hidden_layer_sizes': (100, 10)}\n",
      "[05-19 17:15:33 | models:predict_with_model] result for CV:{'split0_test_score': array([0.64864865, 0.56756757, 0.51351351, 0.51351351]), 'split1_test_score': array([0.72222222, 0.77777778, 0.66666667, 0.77777778]), 'split2_test_score': array([0.66666667, 0.61111111, 0.75      , 0.69444444]), 'mean_test_score': array([0.67917918, 0.65215215, 0.64339339, 0.66191191]), 'std_test_score': array([0.0313123 , 0.09059197, 0.09793773, 0.1103107 ]), 'rank_test_score': array([1, 3, 4, 2], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:15:33 | models:predict_with_model] result for validation set:{'Accuracy': 0.6071428571428571, 'F1': 0.5942028985507246, 'Precision': 0.6228070175438596, 'Recall': 0.6071428571428571, 'AUROC': 0.6607142857142858}\n",
      "[05-19 17:15:33 | models:predict_with_model] ======mlp======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "train Counter({'T2+': 56, 'T1': 54}) test Counter({'T2+': 14, 'T1': 13})\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.5s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:15:44 | models:grid_cv_model] best parameters: {'predictor__hidden_layer_sizes': (100, 10)}\n",
      "[05-19 17:15:44 | models:predict_with_model] result for CV:{'split0_test_score': array([0.62162162, 0.64864865, 0.59459459, 0.54054054]), 'split1_test_score': array([0.56756757, 0.43243243, 0.45945946, 0.51351351]), 'split2_test_score': array([0.5       , 0.52777778, 0.52777778, 0.30555556]), 'mean_test_score': array([0.56306306, 0.53628629, 0.52727728, 0.4532032 ]), 'std_test_score': array([0.04975388, 0.0884747 , 0.05516982, 0.10498408]), 'rank_test_score': array([1, 2, 3, 4], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:15:44 | models:predict_with_model] result for validation set:{'Accuracy': 0.7037037037037037, 'F1': 0.7028897028897029, 'Precision': 0.7098765432098765, 'Recall': 0.7037037037037037, 'AUROC': 0.7912087912087913}\n",
      "[05-19 17:15:44 | models:predict_with_model] ======mlp======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "train Counter({'T2+': 56, 'T1': 54}) test Counter({'T2+': 14, 'T1': 13})\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.2s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.3s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.6s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:15:55 | models:grid_cv_model] best parameters: {'predictor__hidden_layer_sizes': (100, 10)}\n",
      "[05-19 17:15:55 | models:predict_with_model] result for CV:{'split0_test_score': array([0.72972973, 0.67567568, 0.59459459, 0.62162162]), 'split1_test_score': array([0.54054054, 0.59459459, 0.54054054, 0.59459459]), 'split2_test_score': array([0.58333333, 0.58333333, 0.58333333, 0.47222222]), 'mean_test_score': array([0.61786787, 0.61786787, 0.57282282, 0.56281281]), 'std_test_score': array([0.08100458, 0.04113402, 0.02328538, 0.06500055]), 'rank_test_score': array([1, 1, 3, 4], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:15:55 | models:predict_with_model] result for validation set:{'Accuracy': 0.6666666666666666, 'F1': 0.6666666666666666, 'Precision': 0.6684981684981685, 'Recall': 0.6666666666666666, 'AUROC': 0.7747252747252747}\n",
      "[05-19 17:15:55 | models:predict_with_model] ======mlp======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "train Counter({'T2+': 56, 'T1': 54}) test Counter({'T2+': 14, 'T1': 13})\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.3s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.3s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.1s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:16:07 | models:grid_cv_model] best parameters: {'predictor__hidden_layer_sizes': (400, 40)}\n",
      "[05-19 17:16:07 | models:predict_with_model] result for CV:{'split0_test_score': array([0.59459459, 0.56756757, 0.59459459, 0.54054054]), 'split1_test_score': array([0.45945946, 0.64864865, 0.43243243, 0.7027027 ]), 'split2_test_score': array([0.5       , 0.44444444, 0.63888889, 0.61111111]), 'mean_test_score': array([0.51801802, 0.55355355, 0.55530531, 0.61811812]), 'std_test_score': array([0.05662074, 0.0839529 , 0.08874609, 0.06638758]), 'rank_test_score': array([4, 3, 2, 1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   2.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:16:09 | models:predict_with_model] result for validation set:{'Accuracy': 0.5555555555555556, 'F1': 0.5189542483660131, 'Precision': 0.5978835978835979, 'Recall': 0.5555555555555556, 'AUROC': 0.6813186813186813}\n",
      "[05-19 17:16:09 | cv_models:cv_predict_eval_with_model] ======xgboost======\n",
      "[05-19 17:16:09 | models:predict_with_model] ======xgboost======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   2.5s\n",
      "train Counter({'T2+': 56, 'T1': 53}) test Counter({'T1': 14, 'T2+': 14})\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:16:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.9s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:16:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:16:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:16:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:16:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.3s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   1.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:16:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:16:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:16:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:16:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:16:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:16:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.9s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:16:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:16:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[05-19 17:16:18 | models:grid_cv_model] best parameters: {'predictor__learning_rate': 0.1, 'predictor__n_estimators': 100, 'predictor__reg_alpha': 1}\n",
      "[05-19 17:16:18 | models:predict_with_model] result for CV:{'split0_test_score': array([0.43243243, 0.48648649, 0.56756757, 0.48648649]), 'split1_test_score': array([0.63888889, 0.5       , 0.66666667, 0.5       ]), 'split2_test_score': array([0.41666667, 0.47222222, 0.47222222, 0.47222222]), 'mean_test_score': array([0.495996  , 0.48623624, 0.56881882, 0.48623624]), 'std_test_score': array([0.10124533, 0.01134161, 0.07938654, 0.01134161]), 'rank_test_score': array([2, 3, 1, 3], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:16:18] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[05-19 17:16:19 | models:predict_with_model] result for validation set:{'Accuracy': 0.6071428571428571, 'F1': 0.6066411238825032, 'Precision': 0.6076923076923079, 'Recall': 0.6071428571428571, 'AUROC': 0.6887755102040817}\n",
      "[05-19 17:16:19 | models:predict_with_model] ======xgboost======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "train Counter({'T2+': 56, 'T1': 53}) test Counter({'T1': 14, 'T2+': 14})\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:16:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:16:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:16:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   1.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:16:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:16:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:16:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:16:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:16:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.1s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:16:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:16:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:16:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:16:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:16:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[05-19 17:16:27 | models:grid_cv_model] best parameters: {'predictor__learning_rate': 0.1, 'predictor__n_estimators': 100, 'predictor__reg_alpha': 10}\n",
      "[05-19 17:16:27 | models:predict_with_model] result for CV:{'split0_test_score': array([0.56756757, 0.59459459, 0.54054054, 0.59459459]), 'split1_test_score': array([0.66666667, 0.72222222, 0.66666667, 0.72222222]), 'split2_test_score': array([0.55555556, 0.66666667, 0.66666667, 0.69444444]), 'mean_test_score': array([0.5965966 , 0.66116116, 0.62462462, 0.67042042]), 'std_test_score': array([0.04978911, 0.05224899, 0.05945643, 0.05480309]), 'rank_test_score': array([4, 2, 3, 1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:16:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[05-19 17:16:27 | models:predict_with_model] result for validation set:{'Accuracy': 0.5, 'F1': 0.49743589743589745, 'Precision': 0.5, 'Recall': 0.5, 'AUROC': 0.42857142857142855}\n",
      "[05-19 17:16:27 | models:predict_with_model] ======xgboost======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "train Counter({'T2+': 56, 'T1': 54}) test Counter({'T2+': 14, 'T1': 13})\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:16:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:16:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:16:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:16:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:16:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:16:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:16:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:16:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:16:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:16:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:16:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:16:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:16:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[05-19 17:16:32 | models:grid_cv_model] best parameters: {'predictor__learning_rate': 0.1, 'predictor__n_estimators': 100, 'predictor__reg_alpha': 1}\n",
      "[05-19 17:16:32 | models:predict_with_model] result for CV:{'split0_test_score': array([0.56756757, 0.56756757, 0.7027027 , 0.56756757]), 'split1_test_score': array([0.48648649, 0.48648649, 0.56756757, 0.48648649]), 'split2_test_score': array([0.55555556, 0.47222222, 0.63888889, 0.47222222]), 'mean_test_score': array([0.53653654, 0.50875876, 0.63638639, 0.50875876]), 'std_test_score': array([0.03572887, 0.04198987, 0.05519706, 0.04198987]), 'rank_test_score': array([2, 3, 1, 3], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:16:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[05-19 17:16:33 | models:predict_with_model] result for validation set:{'Accuracy': 0.5925925925925926, 'F1': 0.5914687100893997, 'Precision': 0.5919753086419753, 'Recall': 0.5925925925925926, 'AUROC': 0.6593406593406593}\n",
      "[05-19 17:16:33 | models:predict_with_model] ======xgboost======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "train Counter({'T2+': 56, 'T1': 54}) test Counter({'T2+': 14, 'T1': 13})\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:16:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:16:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:16:34] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:16:34] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:16:34] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:16:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:16:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:16:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:16:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:16:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:16:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:16:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:16:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[05-19 17:16:37 | models:grid_cv_model] best parameters: {'predictor__learning_rate': 0.01, 'predictor__n_estimators': 100, 'predictor__reg_alpha': 1}\n",
      "[05-19 17:16:37 | models:predict_with_model] result for CV:{'split0_test_score': array([0.64864865, 0.64864865, 0.54054054, 0.64864865]), 'split1_test_score': array([0.48648649, 0.37837838, 0.40540541, 0.37837838]), 'split2_test_score': array([0.47222222, 0.44444444, 0.47222222, 0.47222222]), 'mean_test_score': array([0.53578579, 0.49049049, 0.47272272, 0.49974975]), 'std_test_score': array([0.08001828, 0.1150411 , 0.05516982, 0.11204115]), 'rank_test_score': array([1, 3, 4, 2], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:16:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[05-19 17:16:38 | models:predict_with_model] result for validation set:{'Accuracy': 0.6666666666666666, 'F1': 0.6573165030388032, 'Precision': 0.697530864197531, 'Recall': 0.6666666666666666, 'AUROC': 0.7912087912087912}\n",
      "[05-19 17:16:38 | models:predict_with_model] ======xgboost======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "train Counter({'T2+': 56, 'T1': 54}) test Counter({'T2+': 14, 'T1': 13})\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:16:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:16:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:16:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:16:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:16:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:16:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:16:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:16:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:16:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:16:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:16:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:16:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:16:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[05-19 17:16:43 | models:grid_cv_model] best parameters: {'predictor__learning_rate': 0.1, 'predictor__n_estimators': 100, 'predictor__reg_alpha': 1}\n",
      "[05-19 17:16:43 | models:predict_with_model] result for CV:{'split0_test_score': array([0.56756757, 0.62162162, 0.54054054, 0.62162162]), 'split1_test_score': array([0.54054054, 0.45945946, 0.62162162, 0.45945946]), 'split2_test_score': array([0.52777778, 0.41666667, 0.61111111, 0.41666667]), 'mean_test_score': array([0.5452953 , 0.49924925, 0.59109109, 0.49924925]), 'std_test_score': array([0.0165884 , 0.08827629, 0.03600126, 0.08827629]), 'rank_test_score': array([2, 3, 1, 3], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:16:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[05-19 17:16:43 | models:predict_with_model] result for validation set:{'Accuracy': 0.6666666666666666, 'F1': 0.6666666666666666, 'Precision': 0.6684981684981685, 'Recall': 0.6666666666666666, 'AUROC': 0.631868131868132}\n",
      "[05-19 17:16:43 | application_cross_validation:ApplicationCV] Saved results to /labs/gevaertlab/users/yyhhli/code/vae/applications/results/VAE3D32AUG_70/StfTStage.cv_result_dict.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "{'__dict': {}, 'logistic_regression': {'Accuracy': [0.6785714285714286, 0.5, 0.5925925925925926, 0.7777777777777778, 0.6666666666666666], 'F1': [0.6781609195402298, 0.49743589743589745, 0.5914687100893997, 0.7771672771672771, 0.6639080459770115], 'Precision': [0.6794871794871794, 0.5, 0.5919753086419753, 0.7851851851851853, 0.678030303030303], 'Recall': [0.6785714285714286, 0.5, 0.5925925925925926, 0.7777777777777778, 0.6666666666666666], 'AUROC': [0.6479591836734694, 0.5408163265306123, 0.6978021978021978, 0.7967032967032966, 0.6263736263736264]}, 'k_nearest_neighbors': {'Accuracy': [0.6428571428571429, 0.5357142857142857, 0.7037037037037037, 0.6296296296296297, 0.48148148148148145], 'F1': [0.6410256410256411, 0.520421607378129, 0.7012345679012347, 0.6296296296296297, 0.47716049382716047], 'Precision': [0.6458333333333333, 0.5409356725146199, 0.7066498316498316, 0.6296296296296297, 0.47811447811447816], 'Recall': [0.6428571428571429, 0.5357142857142857, 0.7037037037037037, 0.6296296296296297, 0.48148148148148145], 'AUROC': [0.7091836734693877, 0.6198979591836735, 0.6978021978021978, 0.7747252747252746, 0.510989010989011]}, 'svc': {'Accuracy': [0.6785714285714286, 0.5, 0.6666666666666666, 0.7407407407407407, 0.6666666666666666], 'F1': [0.6781609195402298, 0.5, 0.6610565684899484, 0.7407407407407407, 0.6573165030388032], 'Precision': [0.6794871794871794, 0.5, 0.6725490196078431, 0.7427757427757429, 0.697530864197531], 'Recall': [0.6785714285714286, 0.5, 0.6666666666666666, 0.7407407407407407, 0.6666666666666666], 'AUROC': [0.7602040816326532, 0.44387755102040816, 0.7582417582417583, 0.8076923076923077, 0.7637362637362637]}, 'random_forest': {'Accuracy': [0.75, 0.4642857142857143, 0.6296296296296297, 0.6666666666666666, 0.6666666666666666], 'F1': [0.7470967741935485, 0.46360153256704983, 0.6191077441077442, 0.6657471264367816, 0.6573165030388032], 'Precision': [0.7620320855614973, 0.4641025641025641, 0.6378600823045267, 0.6666666666666666, 0.697530864197531], 'Recall': [0.75, 0.4642857142857143, 0.6296296296296297, 0.6666666666666666, 0.6666666666666666], 'AUROC': [0.7602040816326531, 0.4489795918367347, 0.7582417582417583, 0.7912087912087913, 0.7527472527472527]}, 'mlp': {'Accuracy': [0.7142857142857143, 0.6071428571428571, 0.7037037037037037, 0.6666666666666666, 0.5555555555555556], 'F1': [0.7128205128205128, 0.5942028985507246, 0.7028897028897029, 0.6666666666666666, 0.5189542483660131], 'Precision': [0.71875, 0.6228070175438596, 0.7098765432098765, 0.6684981684981685, 0.5978835978835979], 'Recall': [0.7142857142857143, 0.6071428571428571, 0.7037037037037037, 0.6666666666666666, 0.5555555555555556], 'AUROC': [0.7244897959183674, 0.6607142857142858, 0.7912087912087913, 0.7747252747252747, 0.6813186813186813]}, 'xgboost': {'Accuracy': [0.6071428571428571, 0.5, 0.5925925925925926, 0.6666666666666666, 0.6666666666666666], 'F1': [0.6066411238825032, 0.49743589743589745, 0.5914687100893997, 0.6573165030388032, 0.6666666666666666], 'Precision': [0.6076923076923079, 0.5, 0.5919753086419753, 0.697530864197531, 0.6684981684981685], 'Recall': [0.6071428571428571, 0.5, 0.5925925925925926, 0.6666666666666666, 0.6666666666666666], 'AUROC': [0.6887755102040817, 0.42857142857142855, 0.6593406593406593, 0.7912087912087912, 0.631868131868132]}}\n",
      "======= Predicting StfLymphInvasion with model version 70 =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:16:47 | patch_ds:LIDCPatchAugDataset] patient split: train:699, val:88, test:88\n",
      "[05-19 17:16:47 | patch_ds:LNDbPatch32AugDataset] patient split: train:168, val:22, test:22\n",
      "[05-19 17:16:47 | patch_stanfordradiogenomics:StanfordRadiogenomicsPatchAugDataset] patient split: train:100, test:43\n",
      "[05-19 17:16:47 | export:  Exporter] initializing embeddings\n",
      "[05-19 17:16:50 | patch_ds:LIDCPatchAugDataset] patient split: train:699, val:88, test:88\n",
      "[05-19 17:16:51 | patch_ds:LNDbPatch32AugDataset] patient split: train:168, val:22, test:22\n",
      "[05-19 17:16:51 | patch_stanfordradiogenomics:StanfordRadiogenomicsPatchAugDataset] patient split: train:100, test:43\n",
      "[05-19 17:16:51 | application_cross_validation:ApplicationCV] -----CV prediction for task StfLymphInvasion-----\n",
      "[05-19 17:16:51 | application:ApplicationCV] Loading best hparams ...\n",
      "[05-19 17:16:51 | cv_models:cv_predict_task] models used ['logistic_regression', 'k_nearest_neighbors', 'svc', 'random_forest', 'mlp', 'xgboost']\n",
      "[05-19 17:16:51 | cv_models:cv_predict_task] Before transform: X shape = train:(100, 4096), val:(43, 4096); Y shape = train:(100,), val:(43,)\n",
      "[05-19 17:16:51 | models:data_summary] X shape = train:(97, 4096), val:(41, 4096); Y shape = train:(97,), val:(41,)\n",
      "Y classes = \n",
      " train: \n",
      "     value count\n",
      "0   Absent    87\n",
      "1  Present    10; \n",
      " val: \n",
      "     value count\n",
      "0   Absent    34\n",
      "1  Present     7\n",
      "[05-19 17:16:51 | cv_models:cv_predict_eval_with_model] ======logistic_regression======\n",
      "[05-19 17:16:51 | models:predict_with_model] ======logistic_regression======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | 4.0 secs.\n",
      "initializing | 8.0 secs.\n",
      "train Counter({'Absent': 96, 'Present': 14}) test Counter({'Absent': 25, 'Present': 3})\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[05-19 17:16:53 | models:grid_cv_model] best parameters: {'predictor__C': 0.01}\n",
      "[05-19 17:16:53 | models:predict_with_model] result for CV:{'split0_test_score': array([0.91891892, 0.91891892]), 'split1_test_score': array([0.81081081, 0.81081081]), 'split2_test_score': array([0.88888889, 0.88888889]), 'mean_test_score': array([0.87287287, 0.87287287]), 'std_test_score': array([0.04556479, 0.04556479]), 'rank_test_score': array([1, 1], dtype=int32)}\n",
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:16:53 | models:predict_with_model] result for validation set:{'Accuracy': 0.8928571428571429, 'F1': 0.8423180592991916, 'Precision': 0.7971938775510204, 'Recall': 0.8928571428571429, 'AUROC': 0.5}\n",
      "[05-19 17:16:53 | models:predict_with_model] ======logistic_regression======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "train Counter({'Absent': 97, 'Present': 13}) test Counter({'Absent': 24, 'Present': 4})\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[05-19 17:16:55 | models:grid_cv_model] best parameters: {'predictor__C': 0.01}\n",
      "[05-19 17:16:55 | models:predict_with_model] result for CV:{'split0_test_score': array([0.91891892, 0.91891892]), 'split1_test_score': array([0.81081081, 0.81081081]), 'split2_test_score': array([0.91666667, 0.91666667]), 'mean_test_score': array([0.88213213, 0.88213213]), 'std_test_score': array([0.05044017, 0.05044017]), 'rank_test_score': array([1, 1], dtype=int32)}\n",
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:16:55 | models:predict_with_model] result for validation set:{'Accuracy': 0.8571428571428571, 'F1': 0.7912087912087912, 'Precision': 0.7346938775510203, 'Recall': 0.8571428571428571, 'AUROC': 0.5}\n",
      "[05-19 17:16:55 | models:predict_with_model] ======logistic_regression======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "train Counter({'Absent': 97, 'Present': 13}) test Counter({'Absent': 24, 'Present': 4})\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[05-19 17:16:57 | models:grid_cv_model] best parameters: {'predictor__C': 0.01}\n",
      "[05-19 17:16:57 | models:predict_with_model] result for CV:{'split0_test_score': array([0.89189189, 0.89189189]), 'split1_test_score': array([0.89189189, 0.89189189]), 'split2_test_score': array([0.86111111, 0.86111111]), 'mean_test_score': array([0.88163163, 0.88163163]), 'std_test_score': array([0.0145102, 0.0145102]), 'rank_test_score': array([1, 1], dtype=int32)}\n",
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:16:57 | models:predict_with_model] result for validation set:{'Accuracy': 0.8571428571428571, 'F1': 0.7912087912087912, 'Precision': 0.7346938775510203, 'Recall': 0.8571428571428571, 'AUROC': 0.5}\n",
      "[05-19 17:16:57 | models:predict_with_model] ======logistic_regression======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "train Counter({'Absent': 97, 'Present': 14}) test Counter({'Absent': 24, 'Present': 3})\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[05-19 17:16:58 | models:grid_cv_model] best parameters: {'predictor__C': 0.01}\n",
      "[05-19 17:16:58 | models:predict_with_model] result for CV:{'split0_test_score': array([0.91891892, 0.91891892]), 'split1_test_score': array([0.75675676, 0.75675676]), 'split2_test_score': array([0.94594595, 0.94594595]), 'mean_test_score': array([0.87387387, 0.87387387]), 'std_test_score': array([0.08354611, 0.08354611]), 'rank_test_score': array([1, 1], dtype=int32)}\n",
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:16:58 | models:predict_with_model] result for validation set:{'Accuracy': 0.8888888888888888, 'F1': 0.8366013071895424, 'Precision': 0.7901234567901234, 'Recall': 0.8888888888888888, 'AUROC': 0.5}\n",
      "[05-19 17:16:58 | models:predict_with_model] ======logistic_regression======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "train Counter({'Absent': 97, 'Present': 14}) test Counter({'Absent': 24, 'Present': 3})\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[05-19 17:17:00 | models:grid_cv_model] best parameters: {'predictor__C': 0.01}\n",
      "[05-19 17:17:00 | models:predict_with_model] result for CV:{'split0_test_score': array([0.89189189, 0.89189189]), 'split1_test_score': array([0.83783784, 0.83783784]), 'split2_test_score': array([0.89189189, 0.89189189]), 'mean_test_score': array([0.87387387, 0.87387387]), 'std_test_score': array([0.02548133, 0.02548133]), 'rank_test_score': array([1, 1], dtype=int32)}\n",
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:17:00 | models:predict_with_model] result for validation set:{'Accuracy': 0.8888888888888888, 'F1': 0.8366013071895424, 'Precision': 0.7901234567901234, 'Recall': 0.8888888888888888, 'AUROC': 0.5}\n",
      "[05-19 17:17:00 | cv_models:cv_predict_eval_with_model] ======k_nearest_neighbors======\n",
      "[05-19 17:17:00 | models:predict_with_model] ======k_nearest_neighbors======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "train Counter({'Absent': 96, 'Present': 14}) test Counter({'Absent': 25, 'Present': 3})\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:17:03 | models:grid_cv_model] best parameters: {'predictor__n_neighbors': 5, 'predictor__p': 2}\n",
      "[05-19 17:17:03 | models:predict_with_model] result for CV:{'split0_test_score': array([0.86486486, 0.86486486, 0.91891892, 0.91891892, 0.91891892,\n",
      "       0.91891892, 0.91891892, 0.91891892, 0.89189189, 0.91891892,\n",
      "       0.91891892, 0.91891892]), 'split1_test_score': array([0.72972973, 0.75675676, 0.81081081, 0.81081081, 0.81081081,\n",
      "       0.81081081, 0.81081081, 0.81081081, 0.81081081, 0.81081081,\n",
      "       0.81081081, 0.81081081]), 'split2_test_score': array([0.86111111, 0.88888889, 0.86111111, 0.86111111, 0.88888889,\n",
      "       0.88888889, 0.88888889, 0.88888889, 0.88888889, 0.88888889,\n",
      "       0.88888889, 0.88888889]), 'mean_test_score': array([0.81856857, 0.83683684, 0.86361361, 0.86361361, 0.87287287,\n",
      "       0.87287287, 0.87287287, 0.87287287, 0.86386386, 0.87287287,\n",
      "       0.87287287, 0.87287287]), 'std_test_score': array([0.06283723, 0.05746827, 0.04417041, 0.04417041, 0.04556479,\n",
      "       0.04556479, 0.04556479, 0.04556479, 0.0375342 , 0.04556479,\n",
      "       0.04556479, 0.04556479]), 'rank_test_score': array([12, 11,  9,  9,  1,  1,  1,  1,  8,  1,  1,  1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:17:03 | models:predict_with_model] result for validation set:{'Accuracy': 0.8928571428571429, 'F1': 0.8423180592991916, 'Precision': 0.7971938775510204, 'Recall': 0.8928571428571429, 'AUROC': 0.5399999999999999}\n",
      "[05-19 17:17:03 | models:predict_with_model] ======k_nearest_neighbors======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Counter({'Absent': 97, 'Present': 13}) test Counter({'Absent': 24, 'Present': 4})\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:17:05 | models:grid_cv_model] best parameters: {'predictor__n_neighbors': 3, 'predictor__p': 2}\n",
      "[05-19 17:17:05 | models:predict_with_model] result for CV:{'split0_test_score': array([0.91891892, 0.91891892, 0.91891892, 0.91891892, 0.91891892,\n",
      "       0.91891892, 0.91891892, 0.91891892, 0.91891892, 0.91891892,\n",
      "       0.91891892, 0.91891892]), 'split1_test_score': array([0.81081081, 0.81081081, 0.81081081, 0.81081081, 0.81081081,\n",
      "       0.81081081, 0.81081081, 0.81081081, 0.81081081, 0.81081081,\n",
      "       0.81081081, 0.81081081]), 'split2_test_score': array([0.91666667, 0.94444444, 0.94444444, 0.91666667, 0.91666667,\n",
      "       0.91666667, 0.91666667, 0.91666667, 0.91666667, 0.91666667,\n",
      "       0.91666667, 0.91666667]), 'mean_test_score': array([0.88213213, 0.89139139, 0.89139139, 0.88213213, 0.88213213,\n",
      "       0.88213213, 0.88213213, 0.88213213, 0.88213213, 0.88213213,\n",
      "       0.88213213, 0.88213213]), 'std_test_score': array([0.05044017, 0.05792415, 0.05792415, 0.05044017, 0.05044017,\n",
      "       0.05044017, 0.05044017, 0.05044017, 0.05044017, 0.05044017,\n",
      "       0.05044017, 0.05044017]), 'rank_test_score': array([3, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3], dtype=int32)}\n",
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:17:05 | models:predict_with_model] result for validation set:{'Accuracy': 0.8571428571428571, 'F1': 0.7912087912087912, 'Precision': 0.7346938775510203, 'Recall': 0.8571428571428571, 'AUROC': 0.4791666666666666}\n",
      "[05-19 17:17:05 | models:predict_with_model] ======k_nearest_neighbors======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "train Counter({'Absent': 97, 'Present': 13}) test Counter({'Absent': 24, 'Present': 4})\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:17:08 | models:grid_cv_model] best parameters: {'predictor__n_neighbors': 5, 'predictor__p': 1}\n",
      "[05-19 17:17:08 | models:predict_with_model] result for CV:{'split0_test_score': array([0.86486486, 0.81081081, 0.75675676, 0.89189189, 0.86486486,\n",
      "       0.89189189, 0.89189189, 0.89189189, 0.89189189, 0.89189189,\n",
      "       0.89189189, 0.89189189]), 'split1_test_score': array([0.83783784, 0.78378378, 0.81081081, 0.89189189, 0.89189189,\n",
      "       0.83783784, 0.89189189, 0.89189189, 0.89189189, 0.89189189,\n",
      "       0.89189189, 0.89189189]), 'split2_test_score': array([0.83333333, 0.86111111, 0.86111111, 0.86111111, 0.86111111,\n",
      "       0.86111111, 0.86111111, 0.86111111, 0.86111111, 0.86111111,\n",
      "       0.86111111, 0.86111111]), 'mean_test_score': array([0.84534535, 0.81856857, 0.80955956, 0.88163163, 0.87262262,\n",
      "       0.86361361, 0.88163163, 0.88163163, 0.88163163, 0.88163163,\n",
      "       0.88163163, 0.88163163]), 'std_test_score': array([0.01392435, 0.03204181, 0.04261167, 0.0145102 , 0.01371134,\n",
      "       0.02213831, 0.0145102 , 0.0145102 , 0.0145102 , 0.0145102 ,\n",
      "       0.0145102 , 0.0145102 ]), 'rank_test_score': array([10, 11, 12,  1,  8,  9,  1,  1,  1,  1,  1,  1], dtype=int32)}\n",
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:17:08 | models:predict_with_model] result for validation set:{'Accuracy': 0.8571428571428571, 'F1': 0.7912087912087912, 'Precision': 0.7346938775510203, 'Recall': 0.8571428571428571, 'AUROC': 0.38541666666666674}\n",
      "[05-19 17:17:08 | models:predict_with_model] ======k_nearest_neighbors======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "train Counter({'Absent': 97, 'Present': 14}) test Counter({'Absent': 24, 'Present': 3})\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:17:10 | models:grid_cv_model] best parameters: {'predictor__n_neighbors': 7, 'predictor__p': 1}\n",
      "[05-19 17:17:10 | models:predict_with_model] result for CV:{'split0_test_score': array([0.91891892, 0.91891892, 0.89189189, 0.91891892, 0.91891892,\n",
      "       0.89189189, 0.91891892, 0.91891892, 0.91891892, 0.91891892,\n",
      "       0.91891892, 0.91891892]), 'split1_test_score': array([0.75675676, 0.75675676, 0.75675676, 0.75675676, 0.75675676,\n",
      "       0.75675676, 0.75675676, 0.75675676, 0.75675676, 0.75675676,\n",
      "       0.75675676, 0.75675676]), 'split2_test_score': array([0.89189189, 0.86486486, 0.83783784, 0.91891892, 0.91891892,\n",
      "       0.94594595, 0.94594595, 0.91891892, 0.94594595, 0.94594595,\n",
      "       0.94594595, 0.94594595]), 'mean_test_score': array([0.85585586, 0.84684685, 0.82882883, 0.86486486, 0.86486486,\n",
      "       0.86486486, 0.87387387, 0.86486486, 0.87387387, 0.87387387,\n",
      "       0.87387387, 0.87387387]), 'std_test_score': array([0.07093701, 0.06741725, 0.05553526, 0.07644398, 0.07644398,\n",
      "       0.07956541, 0.08354611, 0.07644398, 0.08354611, 0.08354611,\n",
      "       0.08354611, 0.08354611]), 'rank_test_score': array([10, 11, 12,  6,  6,  6,  1,  6,  1,  1,  1,  1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:17:10 | models:predict_with_model] result for validation set:{'Accuracy': 0.8888888888888888, 'F1': 0.8366013071895424, 'Precision': 0.7901234567901234, 'Recall': 0.8888888888888888, 'AUROC': 0.8194444444444444}\n",
      "[05-19 17:17:10 | models:predict_with_model] ======k_nearest_neighbors======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Counter({'Absent': 97, 'Present': 14}) test Counter({'Absent': 24, 'Present': 3})\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:17:13 | models:grid_cv_model] best parameters: {'predictor__n_neighbors': 5, 'predictor__p': 1}\n",
      "[05-19 17:17:13 | models:predict_with_model] result for CV:{'split0_test_score': array([0.89189189, 0.83783784, 0.83783784, 0.89189189, 0.89189189,\n",
      "       0.89189189, 0.89189189, 0.89189189, 0.89189189, 0.89189189,\n",
      "       0.89189189, 0.89189189]), 'split1_test_score': array([0.81081081, 0.81081081, 0.75675676, 0.83783784, 0.83783784,\n",
      "       0.83783784, 0.83783784, 0.83783784, 0.83783784, 0.83783784,\n",
      "       0.83783784, 0.83783784]), 'split2_test_score': array([0.86486486, 0.86486486, 0.81081081, 0.89189189, 0.89189189,\n",
      "       0.83783784, 0.89189189, 0.89189189, 0.89189189, 0.89189189,\n",
      "       0.89189189, 0.89189189]), 'mean_test_score': array([0.85585586, 0.83783784, 0.8018018 , 0.87387387, 0.87387387,\n",
      "       0.85585586, 0.87387387, 0.87387387, 0.87387387, 0.87387387,\n",
      "       0.87387387, 0.87387387]), 'std_test_score': array([0.03370863, 0.02206748, 0.03370863, 0.02548133, 0.02548133,\n",
      "       0.02548133, 0.02548133, 0.02548133, 0.02548133, 0.02548133,\n",
      "       0.02548133, 0.02548133]), 'rank_test_score': array([ 9, 11, 12,  1,  1,  9,  1,  1,  1,  1,  1,  1], dtype=int32)}\n",
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:17:13 | models:predict_with_model] result for validation set:{'Accuracy': 0.8888888888888888, 'F1': 0.8366013071895424, 'Precision': 0.7901234567901234, 'Recall': 0.8888888888888888, 'AUROC': 0.3333333333333333}\n",
      "[05-19 17:17:13 | cv_models:cv_predict_eval_with_model] ======svc======\n",
      "[05-19 17:17:13 | models:predict_with_model] ======svc======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "train Counter({'Absent': 96, 'Present': 14}) test Counter({'Absent': 25, 'Present': 3})\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:17:14 | models:grid_cv_model] best parameters: {'predictor__C': 0.01, 'predictor__degree': 1}\n",
      "[05-19 17:17:14 | models:predict_with_model] result for CV:{'split0_test_score': array([0.91891892, 0.91891892, 0.91891892, 0.91891892, 0.91891892,\n",
      "       0.91891892, 0.91891892, 0.91891892, 0.91891892]), 'split1_test_score': array([0.81081081, 0.81081081, 0.81081081, 0.81081081, 0.81081081,\n",
      "       0.81081081, 0.81081081, 0.81081081, 0.81081081]), 'split2_test_score': array([0.88888889, 0.88888889, 0.88888889, 0.88888889, 0.88888889,\n",
      "       0.88888889, 0.88888889, 0.88888889, 0.88888889]), 'mean_test_score': array([0.87287287, 0.87287287, 0.87287287, 0.87287287, 0.87287287,\n",
      "       0.87287287, 0.87287287, 0.87287287, 0.87287287]), 'std_test_score': array([0.04556479, 0.04556479, 0.04556479, 0.04556479, 0.04556479,\n",
      "       0.04556479, 0.04556479, 0.04556479, 0.04556479]), 'rank_test_score': array([1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)}\n",
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:17:14 | models:predict_with_model] result for validation set:{'Accuracy': 0.8928571428571429, 'F1': 0.8423180592991916, 'Precision': 0.7971938775510204, 'Recall': 0.8928571428571429, 'AUROC': 0.6000000000000001}\n",
      "[05-19 17:17:14 | models:predict_with_model] ======svc======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "train Counter({'Absent': 97, 'Present': 13}) test Counter({'Absent': 24, 'Present': 4})\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:17:16 | models:grid_cv_model] best parameters: {'predictor__C': 0.01, 'predictor__degree': 1}\n",
      "[05-19 17:17:16 | models:predict_with_model] result for CV:{'split0_test_score': array([0.91891892, 0.91891892, 0.91891892, 0.91891892, 0.91891892,\n",
      "       0.91891892, 0.91891892, 0.91891892, 0.91891892]), 'split1_test_score': array([0.81081081, 0.81081081, 0.81081081, 0.81081081, 0.81081081,\n",
      "       0.81081081, 0.81081081, 0.81081081, 0.81081081]), 'split2_test_score': array([0.91666667, 0.91666667, 0.91666667, 0.91666667, 0.91666667,\n",
      "       0.91666667, 0.91666667, 0.91666667, 0.91666667]), 'mean_test_score': array([0.88213213, 0.88213213, 0.88213213, 0.88213213, 0.88213213,\n",
      "       0.88213213, 0.88213213, 0.88213213, 0.88213213]), 'std_test_score': array([0.05044017, 0.05044017, 0.05044017, 0.05044017, 0.05044017,\n",
      "       0.05044017, 0.05044017, 0.05044017, 0.05044017]), 'rank_test_score': array([1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:17:16 | models:predict_with_model] result for validation set:{'Accuracy': 0.8571428571428571, 'F1': 0.7912087912087912, 'Precision': 0.7346938775510203, 'Recall': 0.8571428571428571, 'AUROC': 0.5}\n",
      "[05-19 17:17:16 | models:predict_with_model] ======svc======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "train Counter({'Absent': 97, 'Present': 13}) test Counter({'Absent': 24, 'Present': 4})\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:17:17 | models:grid_cv_model] best parameters: {'predictor__C': 0.01, 'predictor__degree': 1}\n",
      "[05-19 17:17:17 | models:predict_with_model] result for CV:{'split0_test_score': array([0.89189189, 0.89189189, 0.89189189, 0.89189189, 0.89189189,\n",
      "       0.89189189, 0.89189189, 0.89189189, 0.89189189]), 'split1_test_score': array([0.89189189, 0.89189189, 0.89189189, 0.89189189, 0.89189189,\n",
      "       0.89189189, 0.89189189, 0.89189189, 0.89189189]), 'split2_test_score': array([0.86111111, 0.86111111, 0.86111111, 0.86111111, 0.86111111,\n",
      "       0.86111111, 0.86111111, 0.86111111, 0.86111111]), 'mean_test_score': array([0.88163163, 0.88163163, 0.88163163, 0.88163163, 0.88163163,\n",
      "       0.88163163, 0.88163163, 0.88163163, 0.88163163]), 'std_test_score': array([0.0145102, 0.0145102, 0.0145102, 0.0145102, 0.0145102, 0.0145102,\n",
      "       0.0145102, 0.0145102, 0.0145102]), 'rank_test_score': array([1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)}\n",
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:17:17 | models:predict_with_model] result for validation set:{'Accuracy': 0.8571428571428571, 'F1': 0.7912087912087912, 'Precision': 0.7346938775510203, 'Recall': 0.8571428571428571, 'AUROC': 0.44791666666666663}\n",
      "[05-19 17:17:17 | models:predict_with_model] ======svc======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "train Counter({'Absent': 97, 'Present': 14}) test Counter({'Absent': 24, 'Present': 3})\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:17:19 | models:grid_cv_model] best parameters: {'predictor__C': 0.01, 'predictor__degree': 1}\n",
      "[05-19 17:17:19 | models:predict_with_model] result for CV:{'split0_test_score': array([0.91891892, 0.91891892, 0.91891892, 0.91891892, 0.91891892,\n",
      "       0.91891892, 0.91891892, 0.91891892, 0.91891892]), 'split1_test_score': array([0.75675676, 0.75675676, 0.75675676, 0.75675676, 0.75675676,\n",
      "       0.75675676, 0.75675676, 0.75675676, 0.75675676]), 'split2_test_score': array([0.94594595, 0.94594595, 0.94594595, 0.94594595, 0.94594595,\n",
      "       0.94594595, 0.94594595, 0.94594595, 0.94594595]), 'mean_test_score': array([0.87387387, 0.87387387, 0.87387387, 0.87387387, 0.87387387,\n",
      "       0.87387387, 0.87387387, 0.87387387, 0.87387387]), 'std_test_score': array([0.08354611, 0.08354611, 0.08354611, 0.08354611, 0.08354611,\n",
      "       0.08354611, 0.08354611, 0.08354611, 0.08354611]), 'rank_test_score': array([1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)}\n",
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:17:19 | models:predict_with_model] result for validation set:{'Accuracy': 0.8888888888888888, 'F1': 0.8366013071895424, 'Precision': 0.7901234567901234, 'Recall': 0.8888888888888888, 'AUROC': 0.3055555555555555}\n",
      "[05-19 17:17:19 | models:predict_with_model] ======svc======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "train Counter({'Absent': 97, 'Present': 14}) test Counter({'Absent': 24, 'Present': 3})\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:17:20 | models:grid_cv_model] best parameters: {'predictor__C': 0.01, 'predictor__degree': 1}\n",
      "[05-19 17:17:20 | models:predict_with_model] result for CV:{'split0_test_score': array([0.89189189, 0.89189189, 0.89189189, 0.89189189, 0.89189189,\n",
      "       0.89189189, 0.89189189, 0.89189189, 0.89189189]), 'split1_test_score': array([0.83783784, 0.83783784, 0.83783784, 0.83783784, 0.83783784,\n",
      "       0.83783784, 0.83783784, 0.83783784, 0.83783784]), 'split2_test_score': array([0.89189189, 0.89189189, 0.89189189, 0.89189189, 0.89189189,\n",
      "       0.89189189, 0.89189189, 0.89189189, 0.89189189]), 'mean_test_score': array([0.87387387, 0.87387387, 0.87387387, 0.87387387, 0.87387387,\n",
      "       0.87387387, 0.87387387, 0.87387387, 0.87387387]), 'std_test_score': array([0.02548133, 0.02548133, 0.02548133, 0.02548133, 0.02548133,\n",
      "       0.02548133, 0.02548133, 0.02548133, 0.02548133]), 'rank_test_score': array([1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:17:20 | models:predict_with_model] result for validation set:{'Accuracy': 0.8888888888888888, 'F1': 0.8366013071895424, 'Precision': 0.7901234567901234, 'Recall': 0.8888888888888888, 'AUROC': 0.45833333333333326}\n",
      "[05-19 17:17:20 | cv_models:cv_predict_eval_with_model] ======random_forest======\n",
      "[05-19 17:17:20 | models:predict_with_model] ======random_forest======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "train Counter({'Absent': 96, 'Present': 14}) test Counter({'Absent': 25, 'Present': 3})\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:17:52 | models:grid_cv_model] best parameters: {'predictor__max_depth': 10, 'predictor__max_features': 'auto', 'predictor__min_samples_leaf': 4, 'predictor__n_estimators': 100}\n",
      "[05-19 17:17:52 | models:predict_with_model] result for CV:{'split0_test_score': array([0.91891892, 0.91891892, 0.91891892, 0.91891892, 0.91891892,\n",
      "       0.91891892, 0.91891892, 0.91891892, 0.91891892, 0.91891892,\n",
      "       0.91891892, 0.91891892, 0.91891892, 0.91891892, 0.91891892,\n",
      "       0.91891892]), 'split1_test_score': array([0.81081081, 0.81081081, 0.81081081, 0.81081081, 0.81081081,\n",
      "       0.81081081, 0.81081081, 0.81081081, 0.81081081, 0.81081081,\n",
      "       0.81081081, 0.81081081, 0.81081081, 0.81081081, 0.81081081,\n",
      "       0.81081081]), 'split2_test_score': array([0.86111111, 0.86111111, 0.86111111, 0.86111111, 0.88888889,\n",
      "       0.88888889, 0.88888889, 0.88888889, 0.86111111, 0.86111111,\n",
      "       0.86111111, 0.86111111, 0.88888889, 0.88888889, 0.88888889,\n",
      "       0.88888889]), 'mean_test_score': array([0.86361361, 0.86361361, 0.86361361, 0.86361361, 0.87287287,\n",
      "       0.87287287, 0.87287287, 0.87287287, 0.86361361, 0.86361361,\n",
      "       0.86361361, 0.86361361, 0.87287287, 0.87287287, 0.87287287,\n",
      "       0.87287287]), 'std_test_score': array([0.04417041, 0.04417041, 0.04417041, 0.04417041, 0.04556479,\n",
      "       0.04556479, 0.04556479, 0.04556479, 0.04417041, 0.04417041,\n",
      "       0.04417041, 0.04417041, 0.04556479, 0.04556479, 0.04556479,\n",
      "       0.04556479]), 'rank_test_score': array([9, 9, 9, 9, 1, 1, 1, 1, 9, 9, 9, 9, 1, 1, 1, 1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:17:52 | models:predict_with_model] result for validation set:{'Accuracy': 0.8928571428571429, 'F1': 0.8423180592991916, 'Precision': 0.7971938775510204, 'Recall': 0.8928571428571429, 'AUROC': 0.48}\n",
      "[05-19 17:17:52 | models:predict_with_model] ======random_forest======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "train Counter({'Absent': 97, 'Present': 13}) test Counter({'Absent': 24, 'Present': 4})\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.1s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:18:24 | models:grid_cv_model] best parameters: {'predictor__max_depth': 10, 'predictor__max_features': 'auto', 'predictor__min_samples_leaf': 4, 'predictor__n_estimators': 100}\n",
      "[05-19 17:18:24 | models:predict_with_model] result for CV:{'split0_test_score': array([0.91891892, 0.91891892, 0.91891892, 0.91891892, 0.91891892,\n",
      "       0.91891892, 0.91891892, 0.91891892, 0.91891892, 0.91891892,\n",
      "       0.91891892, 0.91891892, 0.91891892, 0.91891892, 0.91891892,\n",
      "       0.91891892]), 'split1_test_score': array([0.81081081, 0.81081081, 0.81081081, 0.81081081, 0.81081081,\n",
      "       0.81081081, 0.81081081, 0.81081081, 0.81081081, 0.81081081,\n",
      "       0.81081081, 0.81081081, 0.81081081, 0.81081081, 0.81081081,\n",
      "       0.81081081]), 'split2_test_score': array([0.88888889, 0.88888889, 0.88888889, 0.88888889, 0.91666667,\n",
      "       0.91666667, 0.91666667, 0.91666667, 0.88888889, 0.88888889,\n",
      "       0.88888889, 0.88888889, 0.91666667, 0.91666667, 0.91666667,\n",
      "       0.91666667]), 'mean_test_score': array([0.87287287, 0.87287287, 0.87287287, 0.87287287, 0.88213213,\n",
      "       0.88213213, 0.88213213, 0.88213213, 0.87287287, 0.87287287,\n",
      "       0.87287287, 0.87287287, 0.88213213, 0.88213213, 0.88213213,\n",
      "       0.88213213]), 'std_test_score': array([0.04556479, 0.04556479, 0.04556479, 0.04556479, 0.05044017,\n",
      "       0.05044017, 0.05044017, 0.05044017, 0.04556479, 0.04556479,\n",
      "       0.04556479, 0.04556479, 0.05044017, 0.05044017, 0.05044017,\n",
      "       0.05044017]), 'rank_test_score': array([9, 9, 9, 9, 1, 1, 1, 1, 9, 9, 9, 9, 1, 1, 1, 1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:18:24 | models:predict_with_model] result for validation set:{'Accuracy': 0.8571428571428571, 'F1': 0.7912087912087912, 'Precision': 0.7346938775510203, 'Recall': 0.8571428571428571, 'AUROC': 0.8020833333333334}\n",
      "[05-19 17:18:24 | models:predict_with_model] ======random_forest======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "train Counter({'Absent': 97, 'Present': 13}) test Counter({'Absent': 24, 'Present': 4})\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.2s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:18:56 | models:grid_cv_model] best parameters: {'predictor__max_depth': 10, 'predictor__max_features': 'auto', 'predictor__min_samples_leaf': 1, 'predictor__n_estimators': 100}\n",
      "[05-19 17:18:56 | models:predict_with_model] result for CV:{'split0_test_score': array([0.89189189, 0.89189189, 0.89189189, 0.89189189, 0.89189189,\n",
      "       0.89189189, 0.89189189, 0.89189189, 0.89189189, 0.89189189,\n",
      "       0.89189189, 0.89189189, 0.89189189, 0.89189189, 0.89189189,\n",
      "       0.89189189]), 'split1_test_score': array([0.91891892, 0.91891892, 0.91891892, 0.91891892, 0.89189189,\n",
      "       0.89189189, 0.89189189, 0.89189189, 0.91891892, 0.91891892,\n",
      "       0.91891892, 0.91891892, 0.89189189, 0.89189189, 0.89189189,\n",
      "       0.89189189]), 'split2_test_score': array([0.86111111, 0.86111111, 0.86111111, 0.86111111, 0.86111111,\n",
      "       0.86111111, 0.86111111, 0.86111111, 0.86111111, 0.86111111,\n",
      "       0.86111111, 0.86111111, 0.86111111, 0.86111111, 0.86111111,\n",
      "       0.86111111]), 'mean_test_score': array([0.89064064, 0.89064064, 0.89064064, 0.89064064, 0.88163163,\n",
      "       0.88163163, 0.88163163, 0.88163163, 0.89064064, 0.89064064,\n",
      "       0.89064064, 0.89064064, 0.88163163, 0.88163163, 0.88163163,\n",
      "       0.88163163]), 'std_test_score': array([0.02361652, 0.02361652, 0.02361652, 0.02361652, 0.0145102 ,\n",
      "       0.0145102 , 0.0145102 , 0.0145102 , 0.02361652, 0.02361652,\n",
      "       0.02361652, 0.02361652, 0.0145102 , 0.0145102 , 0.0145102 ,\n",
      "       0.0145102 ]), 'rank_test_score': array([1, 1, 1, 1, 9, 9, 9, 9, 1, 1, 1, 1, 9, 9, 9, 9], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:18:56 | models:predict_with_model] result for validation set:{'Accuracy': 0.8214285714285714, 'F1': 0.773109243697479, 'Precision': 0.7301587301587301, 'Recall': 0.8214285714285714, 'AUROC': 0.625}\n",
      "[05-19 17:18:56 | models:predict_with_model] ======random_forest======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "train Counter({'Absent': 97, 'Present': 14}) test Counter({'Absent': 24, 'Present': 3})\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   1.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   0.9s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:19:28 | models:grid_cv_model] best parameters: {'predictor__max_depth': 10, 'predictor__max_features': 'auto', 'predictor__min_samples_leaf': 1, 'predictor__n_estimators': 100}\n",
      "[05-19 17:19:28 | models:predict_with_model] result for CV:{'split0_test_score': array([0.91891892, 0.91891892, 0.91891892, 0.91891892, 0.91891892,\n",
      "       0.91891892, 0.91891892, 0.91891892, 0.91891892, 0.91891892,\n",
      "       0.91891892, 0.91891892, 0.91891892, 0.91891892, 0.91891892,\n",
      "       0.91891892]), 'split1_test_score': array([0.75675676, 0.75675676, 0.75675676, 0.75675676, 0.75675676,\n",
      "       0.75675676, 0.75675676, 0.75675676, 0.75675676, 0.75675676,\n",
      "       0.75675676, 0.75675676, 0.75675676, 0.75675676, 0.75675676,\n",
      "       0.75675676]), 'split2_test_score': array([0.94594595, 0.94594595, 0.94594595, 0.94594595, 0.94594595,\n",
      "       0.94594595, 0.94594595, 0.94594595, 0.94594595, 0.94594595,\n",
      "       0.94594595, 0.94594595, 0.94594595, 0.94594595, 0.94594595,\n",
      "       0.94594595]), 'mean_test_score': array([0.87387387, 0.87387387, 0.87387387, 0.87387387, 0.87387387,\n",
      "       0.87387387, 0.87387387, 0.87387387, 0.87387387, 0.87387387,\n",
      "       0.87387387, 0.87387387, 0.87387387, 0.87387387, 0.87387387,\n",
      "       0.87387387]), 'std_test_score': array([0.08354611, 0.08354611, 0.08354611, 0.08354611, 0.08354611,\n",
      "       0.08354611, 0.08354611, 0.08354611, 0.08354611, 0.08354611,\n",
      "       0.08354611, 0.08354611, 0.08354611, 0.08354611, 0.08354611,\n",
      "       0.08354611]), 'rank_test_score': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:19:28 | models:predict_with_model] result for validation set:{'Accuracy': 0.8888888888888888, 'F1': 0.8366013071895424, 'Precision': 0.7901234567901234, 'Recall': 0.8888888888888888, 'AUROC': 0.7083333333333334}\n",
      "[05-19 17:19:28 | models:predict_with_model] ======random_forest======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Counter({'Absent': 97, 'Present': 14}) test Counter({'Absent': 24, 'Present': 3})\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:20:00 | models:grid_cv_model] best parameters: {'predictor__max_depth': 10, 'predictor__max_features': 'auto', 'predictor__min_samples_leaf': 1, 'predictor__n_estimators': 100}\n",
      "[05-19 17:20:00 | models:predict_with_model] result for CV:{'split0_test_score': array([0.89189189, 0.89189189, 0.89189189, 0.89189189, 0.89189189,\n",
      "       0.89189189, 0.89189189, 0.89189189, 0.89189189, 0.89189189,\n",
      "       0.89189189, 0.89189189, 0.89189189, 0.89189189, 0.89189189,\n",
      "       0.89189189]), 'split1_test_score': array([0.81081081, 0.81081081, 0.81081081, 0.81081081, 0.81081081,\n",
      "       0.81081081, 0.81081081, 0.81081081, 0.81081081, 0.81081081,\n",
      "       0.81081081, 0.81081081, 0.81081081, 0.81081081, 0.81081081,\n",
      "       0.81081081]), 'split2_test_score': array([0.89189189, 0.89189189, 0.89189189, 0.89189189, 0.89189189,\n",
      "       0.89189189, 0.89189189, 0.89189189, 0.89189189, 0.89189189,\n",
      "       0.89189189, 0.89189189, 0.89189189, 0.89189189, 0.89189189,\n",
      "       0.89189189]), 'mean_test_score': array([0.86486486, 0.86486486, 0.86486486, 0.86486486, 0.86486486,\n",
      "       0.86486486, 0.86486486, 0.86486486, 0.86486486, 0.86486486,\n",
      "       0.86486486, 0.86486486, 0.86486486, 0.86486486, 0.86486486,\n",
      "       0.86486486]), 'std_test_score': array([0.03822199, 0.03822199, 0.03822199, 0.03822199, 0.03822199,\n",
      "       0.03822199, 0.03822199, 0.03822199, 0.03822199, 0.03822199,\n",
      "       0.03822199, 0.03822199, 0.03822199, 0.03822199, 0.03822199,\n",
      "       0.03822199]), 'rank_test_score': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:20:00 | models:predict_with_model] result for validation set:{'Accuracy': 0.8888888888888888, 'F1': 0.8366013071895424, 'Precision': 0.7901234567901234, 'Recall': 0.8888888888888888, 'AUROC': 0.47916666666666663}\n",
      "[05-19 17:20:00 | cv_models:cv_predict_eval_with_model] ======mlp======\n",
      "[05-19 17:20:00 | models:predict_with_model] ======mlp======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "train Counter({'Absent': 96, 'Present': 14}) test Counter({'Absent': 25, 'Present': 3})\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.1s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   2.1s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   2.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.5s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.9s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.9s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:20:12 | models:grid_cv_model] best parameters: {'predictor__hidden_layer_sizes': (100, 10)}\n",
      "[05-19 17:20:12 | models:predict_with_model] result for CV:{'split0_test_score': array([0.78378378, 0.75675676, 0.83783784, 0.86486486]), 'split1_test_score': array([0.75675676, 0.75675676, 0.67567568, 0.75675676]), 'split2_test_score': array([0.86111111, 0.80555556, 0.83333333, 0.72222222]), 'mean_test_score': array([0.80055055, 0.77302302, 0.78228228, 0.78128128]), 'std_test_score': array([0.04422142, 0.02300397, 0.07540468, 0.06076084]), 'rank_test_score': array([1, 4, 2, 3], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:20:13 | models:predict_with_model] result for validation set:{'Accuracy': 0.8571428571428571, 'F1': 0.8241758241758241, 'Precision': 0.7936507936507936, 'Recall': 0.8571428571428571, 'AUROC': 0.6}\n",
      "[05-19 17:20:13 | models:predict_with_model] ======mlp======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "train Counter({'Absent': 97, 'Present': 13}) test Counter({'Absent': 24, 'Present': 4})\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   2.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   2.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.6s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   2.0s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   2.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:20:25 | models:grid_cv_model] best parameters: {'predictor__hidden_layer_sizes': (100, 10)}\n",
      "[05-19 17:20:25 | models:predict_with_model] result for CV:{'split0_test_score': array([0.91891892, 0.81081081, 0.91891892, 0.83783784]), 'split1_test_score': array([0.81081081, 0.75675676, 0.78378378, 0.81081081]), 'split2_test_score': array([0.91666667, 0.86111111, 0.91666667, 0.88888889]), 'mean_test_score': array([0.88213213, 0.80955956, 0.87312312, 0.84584585]), 'std_test_score': array([0.05044017, 0.04261167, 0.06317914, 0.0323743 ]), 'rank_test_score': array([1, 4, 2, 3], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:20:25 | models:predict_with_model] result for validation set:{'Accuracy': 0.75, 'F1': 0.7612293144208039, 'Precision': 0.773913043478261, 'Recall': 0.75, 'AUROC': 0.5520833333333333}\n",
      "[05-19 17:20:25 | models:predict_with_model] ======mlp======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "train Counter({'Absent': 97, 'Present': 13}) test Counter({'Absent': 24, 'Present': 4})\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.9s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.6s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.7s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.8s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.9s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:20:36 | models:grid_cv_model] best parameters: {'predictor__hidden_layer_sizes': (200, 20)}\n",
      "[05-19 17:20:36 | models:predict_with_model] result for CV:{'split0_test_score': array([0.86486486, 0.7027027 , 0.89189189, 0.86486486]), 'split1_test_score': array([0.67567568, 0.78378378, 0.89189189, 0.78378378]), 'split2_test_score': array([0.83333333, 0.75      , 0.86111111, 0.80555556]), 'mean_test_score': array([0.79129129, 0.7454955 , 0.88163163, 0.81806807]), 'std_test_score': array([0.08275984, 0.03325411, 0.0145102 , 0.03426327]), 'rank_test_score': array([3, 4, 1, 2], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:20:37 | models:predict_with_model] result for validation set:{'Accuracy': 0.8214285714285714, 'F1': 0.8104956268221574, 'Precision': 0.8019047619047619, 'Recall': 0.8214285714285714, 'AUROC': 0.5520833333333334}\n",
      "[05-19 17:20:37 | models:predict_with_model] ======mlp======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "train Counter({'Absent': 97, 'Present': 14}) test Counter({'Absent': 24, 'Present': 3})\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.1s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.5s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.7s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.5s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:20:50 | models:grid_cv_model] best parameters: {'predictor__hidden_layer_sizes': (400, 40)}\n",
      "[05-19 17:20:50 | models:predict_with_model] result for CV:{'split0_test_score': array([0.81081081, 0.86486486, 0.67567568, 0.83783784]), 'split1_test_score': array([0.72972973, 0.7027027 , 0.72972973, 0.75675676]), 'split2_test_score': array([0.83783784, 0.59459459, 0.91891892, 0.83783784]), 'mean_test_score': array([0.79279279, 0.72072072, 0.77477477, 0.81081081]), 'std_test_score': array([0.04593711, 0.11107052, 0.10428682, 0.03822199]), 'rank_test_score': array([2, 4, 3, 1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:20:51 | models:predict_with_model] result for validation set:{'Accuracy': 0.8148148148148148, 'F1': 0.7981859410430838, 'Precision': 0.7822222222222223, 'Recall': 0.8148148148148148, 'AUROC': 0.4444444444444444}\n",
      "[05-19 17:20:51 | models:predict_with_model] ======mlp======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.6s\n",
      "train Counter({'Absent': 97, 'Present': 14}) test Counter({'Absent': 24, 'Present': 3})\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.9s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.5s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.5s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.5s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:21:02 | models:grid_cv_model] best parameters: {'predictor__hidden_layer_sizes': (200, 20)}\n",
      "[05-19 17:21:02 | models:predict_with_model] result for CV:{'split0_test_score': array([0.86486486, 0.83783784, 0.86486486, 0.89189189]), 'split1_test_score': array([0.83783784, 0.81081081, 0.72972973, 0.75675676]), 'split2_test_score': array([0.78378378, 0.83783784, 0.89189189, 0.81081081]), 'mean_test_score': array([0.82882883, 0.82882883, 0.82882883, 0.81981982]), 'std_test_score': array([0.03370863, 0.01274066, 0.07093701, 0.05553526]), 'rank_test_score': array([2, 2, 1, 4], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:21:03 | models:predict_with_model] result for validation set:{'Accuracy': 0.8888888888888888, 'F1': 0.8366013071895424, 'Precision': 0.7901234567901234, 'Recall': 0.8888888888888888, 'AUROC': 0.5555555555555556}\n",
      "[05-19 17:21:03 | cv_models:cv_predict_eval_with_model] ======xgboost======\n",
      "[05-19 17:21:03 | models:predict_with_model] ======xgboost======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "train Counter({'Absent': 96, 'Present': 14}) test Counter({'Absent': 25, 'Present': 3})\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:21:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.7s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   1.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:21:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:21:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:21:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   1.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:21:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:21:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:21:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:21:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:21:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:21:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:21:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:21:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.9s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:21:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[05-19 17:21:15 | models:grid_cv_model] best parameters: {'predictor__learning_rate': 0.01, 'predictor__n_estimators': 100, 'predictor__reg_alpha': 10}\n",
      "[05-19 17:21:15 | models:predict_with_model] result for CV:{'split0_test_score': array([0.91891892, 0.91891892, 0.91891892, 0.91891892]), 'split1_test_score': array([0.81081081, 0.81081081, 0.81081081, 0.81081081]), 'split2_test_score': array([0.80555556, 0.88888889, 0.86111111, 0.88888889]), 'mean_test_score': array([0.8450951 , 0.87287287, 0.86361361, 0.87287287]), 'std_test_score': array([0.0522454 , 0.04556479, 0.04417041, 0.04556479]), 'rank_test_score': array([4, 1, 3, 1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:21:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:21:16 | models:predict_with_model] result for validation set:{'Accuracy': 0.8928571428571429, 'F1': 0.8423180592991916, 'Precision': 0.7971938775510204, 'Recall': 0.8928571428571429, 'AUROC': 0.6666666666666666}\n",
      "[05-19 17:21:16 | models:predict_with_model] ======xgboost======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "train Counter({'Absent': 97, 'Present': 13}) test Counter({'Absent': 24, 'Present': 4})\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:21:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:21:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:21:18] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:21:18] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:21:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:21:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:21:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:21:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:21:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:21:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:21:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:21:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:21:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[05-19 17:21:22 | models:grid_cv_model] best parameters: {'predictor__learning_rate': 0.01, 'predictor__n_estimators': 100, 'predictor__reg_alpha': 10}\n",
      "[05-19 17:21:22 | models:predict_with_model] result for CV:{'split0_test_score': array([0.91891892, 0.91891892, 0.91891892, 0.91891892]), 'split1_test_score': array([0.81081081, 0.81081081, 0.81081081, 0.81081081]), 'split2_test_score': array([0.88888889, 0.91666667, 0.88888889, 0.91666667]), 'mean_test_score': array([0.87287287, 0.88213213, 0.87287287, 0.88213213]), 'std_test_score': array([0.04556479, 0.05044017, 0.04556479, 0.05044017]), 'rank_test_score': array([3, 1, 3, 1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:21:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:21:22 | models:predict_with_model] result for validation set:{'Accuracy': 0.8571428571428571, 'F1': 0.7912087912087912, 'Precision': 0.7346938775510203, 'Recall': 0.8571428571428571, 'AUROC': 0.8125}\n",
      "[05-19 17:21:22 | models:predict_with_model] ======xgboost======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "train Counter({'Absent': 97, 'Present': 13}) test Counter({'Absent': 24, 'Present': 4})\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:21:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:21:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:21:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:21:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:21:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:21:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:21:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:21:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:21:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:21:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:21:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:21:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:21:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[05-19 17:21:27 | models:grid_cv_model] best parameters: {'predictor__learning_rate': 0.01, 'predictor__n_estimators': 100, 'predictor__reg_alpha': 10}\n",
      "[05-19 17:21:27 | models:predict_with_model] result for CV:{'split0_test_score': array([0.86486486, 0.89189189, 0.89189189, 0.89189189]), 'split1_test_score': array([0.83783784, 0.89189189, 0.89189189, 0.89189189]), 'split2_test_score': array([0.83333333, 0.86111111, 0.83333333, 0.86111111]), 'mean_test_score': array([0.84534535, 0.88163163, 0.87237237, 0.88163163]), 'std_test_score': array([0.01392435, 0.0145102 , 0.02760477, 0.0145102 ]), 'rank_test_score': array([4, 1, 3, 1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:21:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:21:28 | models:predict_with_model] result for validation set:{'Accuracy': 0.8571428571428571, 'F1': 0.7912087912087912, 'Precision': 0.7346938775510203, 'Recall': 0.8571428571428571, 'AUROC': 0.65625}\n",
      "[05-19 17:21:28 | models:predict_with_model] ======xgboost======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "train Counter({'Absent': 97, 'Present': 14}) test Counter({'Absent': 24, 'Present': 3})\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:21:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:21:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:21:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:21:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:21:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:21:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:21:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:21:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:21:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:21:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:21:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:21:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:21:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[05-19 17:21:33 | models:grid_cv_model] best parameters: {'predictor__learning_rate': 0.01, 'predictor__n_estimators': 100, 'predictor__reg_alpha': 1}\n",
      "[05-19 17:21:33 | models:predict_with_model] result for CV:{'split0_test_score': array([0.89189189, 0.91891892, 0.89189189, 0.91891892]), 'split1_test_score': array([0.75675676, 0.75675676, 0.75675676, 0.75675676]), 'split2_test_score': array([0.97297297, 0.94594595, 0.94594595, 0.94594595]), 'mean_test_score': array([0.87387387, 0.87387387, 0.86486486, 0.87387387]), 'std_test_score': array([0.08918464, 0.08354611, 0.07956541, 0.08354611]), 'rank_test_score': array([1, 1, 4, 1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:21:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:21:34 | models:predict_with_model] result for validation set:{'Accuracy': 0.8888888888888888, 'F1': 0.8366013071895424, 'Precision': 0.7901234567901234, 'Recall': 0.8888888888888888, 'AUROC': 0.6944444444444444}\n",
      "[05-19 17:21:34 | models:predict_with_model] ======xgboost======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "train Counter({'Absent': 97, 'Present': 14}) test Counter({'Absent': 24, 'Present': 3})\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:21:34] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:21:34] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:21:34] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:21:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:21:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:21:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:21:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:21:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:21:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:21:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:21:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:21:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:21:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[05-19 17:21:38 | models:grid_cv_model] best parameters: {'predictor__learning_rate': 0.01, 'predictor__n_estimators': 100, 'predictor__reg_alpha': 10}\n",
      "[05-19 17:21:38 | models:predict_with_model] result for CV:{'split0_test_score': array([0.89189189, 0.89189189, 0.89189189, 0.89189189]), 'split1_test_score': array([0.78378378, 0.83783784, 0.78378378, 0.83783784]), 'split2_test_score': array([0.89189189, 0.89189189, 0.89189189, 0.89189189]), 'mean_test_score': array([0.85585586, 0.87387387, 0.85585586, 0.87387387]), 'std_test_score': array([0.05096265, 0.02548133, 0.05096265, 0.02548133]), 'rank_test_score': array([3, 1, 3, 1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:21:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:21:39 | models:predict_with_model] result for validation set:{'Accuracy': 0.8888888888888888, 'F1': 0.8366013071895424, 'Precision': 0.7901234567901234, 'Recall': 0.8888888888888888, 'AUROC': 0.6527777777777778}\n",
      "[05-19 17:21:39 | application_cross_validation:ApplicationCV] Saved results to /labs/gevaertlab/users/yyhhli/code/vae/applications/results/VAE3D32AUG_70/StfLymphInvasion.cv_result_dict.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "{'__dict': {}, 'logistic_regression': {'Accuracy': [0.8928571428571429, 0.8571428571428571, 0.8571428571428571, 0.8888888888888888, 0.8888888888888888], 'F1': [0.8423180592991916, 0.7912087912087912, 0.7912087912087912, 0.8366013071895424, 0.8366013071895424], 'Precision': [0.7971938775510204, 0.7346938775510203, 0.7346938775510203, 0.7901234567901234, 0.7901234567901234], 'Recall': [0.8928571428571429, 0.8571428571428571, 0.8571428571428571, 0.8888888888888888, 0.8888888888888888], 'AUROC': [0.5, 0.5, 0.5, 0.5, 0.5]}, 'k_nearest_neighbors': {'Accuracy': [0.8928571428571429, 0.8571428571428571, 0.8571428571428571, 0.8888888888888888, 0.8888888888888888], 'F1': [0.8423180592991916, 0.7912087912087912, 0.7912087912087912, 0.8366013071895424, 0.8366013071895424], 'Precision': [0.7971938775510204, 0.7346938775510203, 0.7346938775510203, 0.7901234567901234, 0.7901234567901234], 'Recall': [0.8928571428571429, 0.8571428571428571, 0.8571428571428571, 0.8888888888888888, 0.8888888888888888], 'AUROC': [0.5399999999999999, 0.4791666666666666, 0.38541666666666674, 0.8194444444444444, 0.3333333333333333]}, 'svc': {'Accuracy': [0.8928571428571429, 0.8571428571428571, 0.8571428571428571, 0.8888888888888888, 0.8888888888888888], 'F1': [0.8423180592991916, 0.7912087912087912, 0.7912087912087912, 0.8366013071895424, 0.8366013071895424], 'Precision': [0.7971938775510204, 0.7346938775510203, 0.7346938775510203, 0.7901234567901234, 0.7901234567901234], 'Recall': [0.8928571428571429, 0.8571428571428571, 0.8571428571428571, 0.8888888888888888, 0.8888888888888888], 'AUROC': [0.6000000000000001, 0.5, 0.44791666666666663, 0.3055555555555555, 0.45833333333333326]}, 'random_forest': {'Accuracy': [0.8928571428571429, 0.8571428571428571, 0.8214285714285714, 0.8888888888888888, 0.8888888888888888], 'F1': [0.8423180592991916, 0.7912087912087912, 0.773109243697479, 0.8366013071895424, 0.8366013071895424], 'Precision': [0.7971938775510204, 0.7346938775510203, 0.7301587301587301, 0.7901234567901234, 0.7901234567901234], 'Recall': [0.8928571428571429, 0.8571428571428571, 0.8214285714285714, 0.8888888888888888, 0.8888888888888888], 'AUROC': [0.48, 0.8020833333333334, 0.625, 0.7083333333333334, 0.47916666666666663]}, 'mlp': {'Accuracy': [0.8571428571428571, 0.75, 0.8214285714285714, 0.8148148148148148, 0.8888888888888888], 'F1': [0.8241758241758241, 0.7612293144208039, 0.8104956268221574, 0.7981859410430838, 0.8366013071895424], 'Precision': [0.7936507936507936, 0.773913043478261, 0.8019047619047619, 0.7822222222222223, 0.7901234567901234], 'Recall': [0.8571428571428571, 0.75, 0.8214285714285714, 0.8148148148148148, 0.8888888888888888], 'AUROC': [0.6, 0.5520833333333333, 0.5520833333333334, 0.4444444444444444, 0.5555555555555556]}, 'xgboost': {'Accuracy': [0.8928571428571429, 0.8571428571428571, 0.8571428571428571, 0.8888888888888888, 0.8888888888888888], 'F1': [0.8423180592991916, 0.7912087912087912, 0.7912087912087912, 0.8366013071895424, 0.8366013071895424], 'Precision': [0.7971938775510204, 0.7346938775510203, 0.7346938775510203, 0.7901234567901234, 0.7901234567901234], 'Recall': [0.8928571428571429, 0.8571428571428571, 0.8571428571428571, 0.8888888888888888, 0.8888888888888888], 'AUROC': [0.6666666666666666, 0.8125, 0.65625, 0.6944444444444444, 0.6527777777777778]}}\n",
      "======= Predicting StfEGFRMutation with model version 70 =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:21:42 | patch_ds:LIDCPatchAugDataset] patient split: train:699, val:88, test:88\n",
      "[05-19 17:21:43 | patch_ds:LNDbPatch32AugDataset] patient split: train:168, val:22, test:22\n",
      "[05-19 17:21:43 | patch_stanfordradiogenomics:StanfordRadiogenomicsPatchAugDataset] patient split: train:100, test:43\n",
      "[05-19 17:21:43 | export:  Exporter] initializing embeddings\n",
      "[05-19 17:21:46 | patch_ds:LIDCPatchAugDataset] patient split: train:699, val:88, test:88\n",
      "[05-19 17:21:46 | patch_ds:LNDbPatch32AugDataset] patient split: train:168, val:22, test:22\n",
      "[05-19 17:21:46 | patch_stanfordradiogenomics:StanfordRadiogenomicsPatchAugDataset] patient split: train:100, test:43\n",
      "[05-19 17:21:47 | application_cross_validation:ApplicationCV] -----CV prediction for task StfEGFRMutation-----\n",
      "[05-19 17:21:47 | application:ApplicationCV] Loading best hparams ...\n",
      "[05-19 17:21:47 | cv_models:cv_predict_task] models used ['logistic_regression', 'k_nearest_neighbors', 'svc', 'random_forest', 'mlp', 'xgboost']\n",
      "[05-19 17:21:47 | cv_models:cv_predict_task] Before transform: X shape = train:(100, 4096), val:(43, 4096); Y shape = train:(100,), val:(43,)\n",
      "[05-19 17:21:47 | models:data_summary] X shape = train:(79, 4096), val:(37, 4096); Y shape = train:(79,), val:(37,)\n",
      "Y classes = \n",
      " train: \n",
      "      value count\n",
      "0    Mutant    17\n",
      "1  Wildtype    62; \n",
      " val: \n",
      "      value count\n",
      "0    Mutant     6\n",
      "1  Wildtype    31\n",
      "[05-19 17:21:47 | cv_models:cv_predict_eval_with_model] ======logistic_regression======\n",
      "[05-19 17:21:47 | models:predict_with_model] ======logistic_regression======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | 4.0 secs.\n",
      "initializing | 8.0 secs.\n",
      "train Counter({'Wildtype': 74, 'Mutant': 18}) test Counter({'Wildtype': 19, 'Mutant': 5})\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[05-19 17:21:49 | models:grid_cv_model] best parameters: {'predictor__C': 0.01}\n",
      "[05-19 17:21:49 | models:predict_with_model] result for CV:{'split0_test_score': array([0.74193548, 0.74193548]), 'split1_test_score': array([0.83870968, 0.83870968]), 'split2_test_score': array([0.83333333, 0.83333333]), 'mean_test_score': array([0.8046595, 0.8046595]), 'std_test_score': array([0.04440685, 0.04440685]), 'rank_test_score': array([1, 1], dtype=int32)}\n",
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:21:49 | models:predict_with_model] result for validation set:{'Accuracy': 0.7916666666666666, 'F1': 0.6996124031007752, 'Precision': 0.626736111111111, 'Recall': 0.7916666666666666, 'AUROC': 0.5}\n",
      "[05-19 17:21:49 | models:predict_with_model] ======logistic_regression======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "train Counter({'Wildtype': 75, 'Mutant': 18}) test Counter({'Wildtype': 18, 'Mutant': 5})\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:21:50 | models:grid_cv_model] best parameters: {'predictor__C': 0.01}\n",
      "[05-19 17:21:50 | models:predict_with_model] result for CV:{'split0_test_score': array([0.87096774, 0.87096774]), 'split1_test_score': array([0.80645161, 0.80645161]), 'split2_test_score': array([0.74193548, 0.74193548]), 'mean_test_score': array([0.80645161, 0.80645161]), 'std_test_score': array([0.0526772, 0.0526772]), 'rank_test_score': array([1, 1], dtype=int32)}\n",
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:21:50 | models:predict_with_model] result for validation set:{'Accuracy': 0.782608695652174, 'F1': 0.687168610816543, 'Precision': 0.6124763705103969, 'Recall': 0.782608695652174, 'AUROC': 0.5}\n",
      "[05-19 17:21:50 | models:predict_with_model] ======logistic_regression======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "train Counter({'Wildtype': 75, 'Mutant': 18}) test Counter({'Wildtype': 18, 'Mutant': 5})\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:21:52 | models:grid_cv_model] best parameters: {'predictor__C': 0.01}\n",
      "[05-19 17:21:52 | models:predict_with_model] result for CV:{'split0_test_score': array([0.83870968, 0.83870968]), 'split1_test_score': array([0.87096774, 0.87096774]), 'split2_test_score': array([0.70967742, 0.70967742]), 'mean_test_score': array([0.80645161, 0.80645161]), 'std_test_score': array([0.06968538, 0.06968538]), 'rank_test_score': array([1, 1], dtype=int32)}\n",
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:21:52 | models:predict_with_model] result for validation set:{'Accuracy': 0.782608695652174, 'F1': 0.687168610816543, 'Precision': 0.6124763705103969, 'Recall': 0.782608695652174, 'AUROC': 0.5}\n",
      "[05-19 17:21:52 | models:predict_with_model] ======logistic_regression======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "train Counter({'Wildtype': 74, 'Mutant': 19}) test Counter({'Wildtype': 19, 'Mutant': 4})\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[05-19 17:21:54 | models:grid_cv_model] best parameters: {'predictor__C': 0.01}\n",
      "[05-19 17:21:54 | models:predict_with_model] result for CV:{'split0_test_score': array([0.80645161, 0.80645161]), 'split1_test_score': array([0.83870968, 0.83870968]), 'split2_test_score': array([0.74193548, 0.74193548]), 'mean_test_score': array([0.79569892, 0.79569892]), 'std_test_score': array([0.04023288, 0.04023288]), 'rank_test_score': array([1, 1], dtype=int32)}\n",
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:21:54 | models:predict_with_model] result for validation set:{'Accuracy': 0.8260869565217391, 'F1': 0.7474120082815735, 'Precision': 0.6824196597353497, 'Recall': 0.8260869565217391, 'AUROC': 0.5}\n",
      "[05-19 17:21:54 | models:predict_with_model] ======logistic_regression======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "train Counter({'Wildtype': 74, 'Mutant': 19}) test Counter({'Wildtype': 19, 'Mutant': 4})\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[05-19 17:21:56 | models:grid_cv_model] best parameters: {'predictor__C': 0.01}\n",
      "[05-19 17:21:56 | models:predict_with_model] result for CV:{'split0_test_score': array([0.70967742, 0.70967742]), 'split1_test_score': array([0.83870968, 0.83870968]), 'split2_test_score': array([0.83870968, 0.83870968]), 'mean_test_score': array([0.79569892, 0.79569892]), 'std_test_score': array([0.06082639, 0.06082639]), 'rank_test_score': array([1, 1], dtype=int32)}\n",
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:21:56 | models:predict_with_model] result for validation set:{'Accuracy': 0.8260869565217391, 'F1': 0.7474120082815735, 'Precision': 0.6824196597353497, 'Recall': 0.8260869565217391, 'AUROC': 0.5}\n",
      "[05-19 17:21:56 | cv_models:cv_predict_eval_with_model] ======k_nearest_neighbors======\n",
      "[05-19 17:21:56 | models:predict_with_model] ======k_nearest_neighbors======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "train Counter({'Wildtype': 74, 'Mutant': 18}) test Counter({'Wildtype': 19, 'Mutant': 5})\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:21:58 | models:grid_cv_model] best parameters: {'predictor__n_neighbors': 10, 'predictor__p': 2}\n",
      "[05-19 17:21:58 | models:predict_with_model] result for CV:{'split0_test_score': array([0.74193548, 0.74193548, 0.74193548, 0.74193548, 0.74193548,\n",
      "       0.74193548, 0.74193548, 0.74193548, 0.74193548, 0.74193548,\n",
      "       0.74193548, 0.74193548]), 'split1_test_score': array([0.74193548, 0.70967742, 0.77419355, 0.80645161, 0.80645161,\n",
      "       0.80645161, 0.77419355, 0.77419355, 0.83870968, 0.77419355,\n",
      "       0.80645161, 0.83870968]), 'split2_test_score': array([0.83333333, 0.83333333, 0.76666667, 0.83333333, 0.83333333,\n",
      "       0.8       , 0.83333333, 0.83333333, 0.83333333, 0.83333333,\n",
      "       0.86666667, 0.83333333]), 'mean_test_score': array([0.77240143, 0.76164875, 0.7609319 , 0.79390681, 0.79390681,\n",
      "       0.7827957 , 0.78315412, 0.78315412, 0.8046595 , 0.78315412,\n",
      "       0.80501792, 0.8046595 ]), 'std_test_score': array([0.04308536, 0.05237147, 0.01377949, 0.03835293, 0.03835293,\n",
      "       0.02901234, 0.03784715, 0.03784715, 0.04440685, 0.03784715,\n",
      "       0.05093138, 0.04440685]), 'rank_test_score': array([10, 11, 12,  4,  4,  9,  6,  6,  2,  6,  1,  2], dtype=int32)}\n",
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:21:58 | models:predict_with_model] result for validation set:{'Accuracy': 0.7916666666666666, 'F1': 0.6996124031007752, 'Precision': 0.626736111111111, 'Recall': 0.7916666666666666, 'AUROC': 0.4526315789473684}\n",
      "[05-19 17:21:58 | models:predict_with_model] ======k_nearest_neighbors======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "train Counter({'Wildtype': 75, 'Mutant': 18}) test Counter({'Wildtype': 18, 'Mutant': 5})\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:22:00 | models:grid_cv_model] best parameters: {'predictor__n_neighbors': 10, 'predictor__p': 5}\n",
      "[05-19 17:22:00 | models:predict_with_model] result for CV:{'split0_test_score': array([0.64516129, 0.58064516, 0.61290323, 0.67741935, 0.67741935,\n",
      "       0.67741935, 0.74193548, 0.77419355, 0.80645161, 0.70967742,\n",
      "       0.74193548, 0.83870968]), 'split1_test_score': array([0.67741935, 0.67741935, 0.67741935, 0.74193548, 0.74193548,\n",
      "       0.74193548, 0.74193548, 0.77419355, 0.80645161, 0.80645161,\n",
      "       0.80645161, 0.80645161]), 'split2_test_score': array([0.74193548, 0.74193548, 0.74193548, 0.74193548, 0.74193548,\n",
      "       0.74193548, 0.74193548, 0.74193548, 0.74193548, 0.74193548,\n",
      "       0.74193548, 0.74193548]), 'mean_test_score': array([0.68817204, 0.66666667, 0.67741935, 0.72043011, 0.72043011,\n",
      "       0.72043011, 0.74193548, 0.76344086, 0.78494624, 0.75268817,\n",
      "       0.76344086, 0.79569892]), 'std_test_score': array([4.02328751e-02, 6.62840215e-02, 5.26771988e-02, 3.04131949e-02,\n",
      "       3.04131949e-02, 3.04131949e-02, 1.11022302e-16, 1.52065974e-02,\n",
      "       3.04131949e-02, 4.02328751e-02, 3.04131949e-02, 4.02328751e-02]), 'rank_test_score': array([10, 12, 11,  7,  7,  7,  6,  3,  2,  5,  3,  1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:22:00 | models:predict_with_model] result for validation set:{'Accuracy': 0.7391304347826086, 'F1': 0.6652173913043478, 'Precision': 0.6047430830039525, 'Recall': 0.7391304347826086, 'AUROC': 0.4833333333333334}\n",
      "[05-19 17:22:00 | models:predict_with_model] ======k_nearest_neighbors======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Counter({'Wildtype': 75, 'Mutant': 18}) test Counter({'Wildtype': 18, 'Mutant': 5})\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:22:02 | models:grid_cv_model] best parameters: {'predictor__n_neighbors': 7, 'predictor__p': 1}\n",
      "[05-19 17:22:02 | models:predict_with_model] result for CV:{'split0_test_score': array([0.80645161, 0.74193548, 0.80645161, 0.83870968, 0.80645161,\n",
      "       0.83870968, 0.83870968, 0.83870968, 0.80645161, 0.83870968,\n",
      "       0.80645161, 0.77419355]), 'split1_test_score': array([0.67741935, 0.74193548, 0.67741935, 0.80645161, 0.83870968,\n",
      "       0.83870968, 0.87096774, 0.87096774, 0.80645161, 0.83870968,\n",
      "       0.87096774, 0.80645161]), 'split2_test_score': array([0.70967742, 0.70967742, 0.67741935, 0.67741935, 0.67741935,\n",
      "       0.70967742, 0.70967742, 0.70967742, 0.70967742, 0.70967742,\n",
      "       0.70967742, 0.70967742]), 'mean_test_score': array([0.7311828 , 0.7311828 , 0.72043011, 0.77419355, 0.77419355,\n",
      "       0.79569892, 0.80645161, 0.80645161, 0.77419355, 0.79569892,\n",
      "       0.79569892, 0.76344086]), 'std_test_score': array([0.05482817, 0.0152066 , 0.06082639, 0.06968538, 0.06968538,\n",
      "       0.06082639, 0.06968538, 0.06968538, 0.04561979, 0.06082639,\n",
      "       0.06628402, 0.04023288]), 'rank_test_score': array([10, 10, 12,  6,  6,  3,  1,  1,  6,  3,  5,  9], dtype=int32)}\n",
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:22:02 | models:predict_with_model] result for validation set:{'Accuracy': 0.782608695652174, 'F1': 0.687168610816543, 'Precision': 0.6124763705103969, 'Recall': 0.782608695652174, 'AUROC': 0.36111111111111116}\n",
      "[05-19 17:22:02 | models:predict_with_model] ======k_nearest_neighbors======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "train Counter({'Wildtype': 74, 'Mutant': 19}) test Counter({'Wildtype': 19, 'Mutant': 4})\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:22:03 | models:grid_cv_model] best parameters: {'predictor__n_neighbors': 10, 'predictor__p': 1}\n",
      "[05-19 17:22:03 | models:predict_with_model] result for CV:{'split0_test_score': array([0.74193548, 0.74193548, 0.74193548, 0.74193548, 0.77419355,\n",
      "       0.77419355, 0.80645161, 0.74193548, 0.80645161, 0.80645161,\n",
      "       0.80645161, 0.80645161]), 'split1_test_score': array([0.77419355, 0.77419355, 0.77419355, 0.77419355, 0.77419355,\n",
      "       0.74193548, 0.80645161, 0.83870968, 0.80645161, 0.83870968,\n",
      "       0.83870968, 0.80645161]), 'split2_test_score': array([0.74193548, 0.74193548, 0.64516129, 0.67741935, 0.70967742,\n",
      "       0.64516129, 0.70967742, 0.74193548, 0.74193548, 0.74193548,\n",
      "       0.74193548, 0.74193548]), 'mean_test_score': array([0.75268817, 0.75268817, 0.72043011, 0.7311828 , 0.75268817,\n",
      "       0.72043011, 0.77419355, 0.77419355, 0.78494624, 0.79569892,\n",
      "       0.79569892, 0.78494624]), 'std_test_score': array([0.0152066 , 0.0152066 , 0.05482817, 0.04023288, 0.03041319,\n",
      "       0.05482817, 0.04561979, 0.04561979, 0.03041319, 0.04023288,\n",
      "       0.04023288, 0.03041319]), 'rank_test_score': array([ 7,  7, 11, 10,  7, 11,  5,  5,  3,  1,  1,  3], dtype=int32)}\n",
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:22:03 | models:predict_with_model] result for validation set:{'Accuracy': 0.8260869565217391, 'F1': 0.7474120082815735, 'Precision': 0.6824196597353497, 'Recall': 0.8260869565217391, 'AUROC': 0.3157894736842105}\n",
      "[05-19 17:22:03 | models:predict_with_model] ======k_nearest_neighbors======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "train Counter({'Wildtype': 74, 'Mutant': 19}) test Counter({'Wildtype': 19, 'Mutant': 4})\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:22:05 | models:grid_cv_model] best parameters: {'predictor__n_neighbors': 5, 'predictor__p': 2}\n",
      "[05-19 17:22:05 | models:predict_with_model] result for CV:{'split0_test_score': array([0.67741935, 0.67741935, 0.67741935, 0.70967742, 0.70967742,\n",
      "       0.70967742, 0.70967742, 0.70967742, 0.70967742, 0.70967742,\n",
      "       0.70967742, 0.70967742]), 'split1_test_score': array([0.80645161, 0.70967742, 0.77419355, 0.77419355, 0.83870968,\n",
      "       0.80645161, 0.83870968, 0.83870968, 0.83870968, 0.83870968,\n",
      "       0.83870968, 0.77419355]), 'split2_test_score': array([0.77419355, 0.80645161, 0.70967742, 0.80645161, 0.83870968,\n",
      "       0.77419355, 0.83870968, 0.83870968, 0.77419355, 0.80645161,\n",
      "       0.77419355, 0.83870968]), 'mean_test_score': array([0.75268817, 0.7311828 , 0.72043011, 0.76344086, 0.79569892,\n",
      "       0.76344086, 0.79569892, 0.79569892, 0.77419355, 0.78494624,\n",
      "       0.77419355, 0.77419355]), 'std_test_score': array([0.05482817, 0.05482817, 0.04023288, 0.04023288, 0.06082639,\n",
      "       0.04023288, 0.06082639, 0.06082639, 0.0526772 , 0.05482817,\n",
      "       0.0526772 , 0.0526772 ]), 'rank_test_score': array([10, 11, 12,  8,  1,  8,  1,  1,  6,  4,  6,  5], dtype=int32)}\n",
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:22:05 | models:predict_with_model] result for validation set:{'Accuracy': 0.8260869565217391, 'F1': 0.7474120082815735, 'Precision': 0.6824196597353497, 'Recall': 0.8260869565217391, 'AUROC': 0.4013157894736842}\n",
      "[05-19 17:22:05 | cv_models:cv_predict_eval_with_model] ======svc======\n",
      "[05-19 17:22:05 | models:predict_with_model] ======svc======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "train Counter({'Wildtype': 74, 'Mutant': 18}) test Counter({'Wildtype': 19, 'Mutant': 5})\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:22:06 | models:grid_cv_model] best parameters: {'predictor__C': 0.01, 'predictor__degree': 1}\n",
      "[05-19 17:22:06 | models:predict_with_model] result for CV:{'split0_test_score': array([0.74193548, 0.74193548, 0.74193548, 0.74193548, 0.74193548,\n",
      "       0.74193548, 0.74193548, 0.74193548, 0.74193548]), 'split1_test_score': array([0.83870968, 0.83870968, 0.83870968, 0.83870968, 0.83870968,\n",
      "       0.83870968, 0.83870968, 0.83870968, 0.83870968]), 'split2_test_score': array([0.83333333, 0.83333333, 0.83333333, 0.83333333, 0.83333333,\n",
      "       0.83333333, 0.83333333, 0.83333333, 0.83333333]), 'mean_test_score': array([0.8046595, 0.8046595, 0.8046595, 0.8046595, 0.8046595, 0.8046595,\n",
      "       0.8046595, 0.8046595, 0.8046595]), 'std_test_score': array([0.04440685, 0.04440685, 0.04440685, 0.04440685, 0.04440685,\n",
      "       0.04440685, 0.04440685, 0.04440685, 0.04440685]), 'rank_test_score': array([1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)}\n",
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:22:06 | models:predict_with_model] result for validation set:{'Accuracy': 0.7916666666666666, 'F1': 0.6996124031007752, 'Precision': 0.626736111111111, 'Recall': 0.7916666666666666, 'AUROC': 0.5473684210526315}\n",
      "[05-19 17:22:06 | models:predict_with_model] ======svc======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "train Counter({'Wildtype': 75, 'Mutant': 18}) test Counter({'Wildtype': 18, 'Mutant': 5})\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:22:07 | models:grid_cv_model] best parameters: {'predictor__C': 0.01, 'predictor__degree': 1}\n",
      "[05-19 17:22:07 | models:predict_with_model] result for CV:{'split0_test_score': array([0.87096774, 0.87096774, 0.87096774, 0.87096774, 0.87096774,\n",
      "       0.87096774, 0.87096774, 0.87096774, 0.87096774]), 'split1_test_score': array([0.80645161, 0.80645161, 0.80645161, 0.80645161, 0.80645161,\n",
      "       0.80645161, 0.80645161, 0.80645161, 0.80645161]), 'split2_test_score': array([0.74193548, 0.74193548, 0.74193548, 0.74193548, 0.74193548,\n",
      "       0.74193548, 0.74193548, 0.74193548, 0.74193548]), 'mean_test_score': array([0.80645161, 0.80645161, 0.80645161, 0.80645161, 0.80645161,\n",
      "       0.80645161, 0.80645161, 0.80645161, 0.80645161]), 'std_test_score': array([0.0526772, 0.0526772, 0.0526772, 0.0526772, 0.0526772, 0.0526772,\n",
      "       0.0526772, 0.0526772, 0.0526772]), 'rank_test_score': array([1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)}\n",
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:22:08 | models:predict_with_model] result for validation set:{'Accuracy': 0.782608695652174, 'F1': 0.687168610816543, 'Precision': 0.6124763705103969, 'Recall': 0.782608695652174, 'AUROC': 0.4111111111111111}\n",
      "[05-19 17:22:08 | models:predict_with_model] ======svc======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "train Counter({'Wildtype': 75, 'Mutant': 18}) test Counter({'Wildtype': 18, 'Mutant': 5})\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:22:09 | models:grid_cv_model] best parameters: {'predictor__C': 0.01, 'predictor__degree': 1}\n",
      "[05-19 17:22:09 | models:predict_with_model] result for CV:{'split0_test_score': array([0.83870968, 0.83870968, 0.83870968, 0.83870968, 0.83870968,\n",
      "       0.83870968, 0.83870968, 0.83870968, 0.83870968]), 'split1_test_score': array([0.87096774, 0.87096774, 0.87096774, 0.87096774, 0.87096774,\n",
      "       0.87096774, 0.87096774, 0.87096774, 0.87096774]), 'split2_test_score': array([0.70967742, 0.70967742, 0.70967742, 0.70967742, 0.70967742,\n",
      "       0.70967742, 0.70967742, 0.70967742, 0.70967742]), 'mean_test_score': array([0.80645161, 0.80645161, 0.80645161, 0.80645161, 0.80645161,\n",
      "       0.80645161, 0.80645161, 0.80645161, 0.80645161]), 'std_test_score': array([0.06968538, 0.06968538, 0.06968538, 0.06968538, 0.06968538,\n",
      "       0.06968538, 0.06968538, 0.06968538, 0.06968538]), 'rank_test_score': array([1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:22:09 | models:predict_with_model] result for validation set:{'Accuracy': 0.782608695652174, 'F1': 0.687168610816543, 'Precision': 0.6124763705103969, 'Recall': 0.782608695652174, 'AUROC': 0.6111111111111112}\n",
      "[05-19 17:22:09 | models:predict_with_model] ======svc======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "train Counter({'Wildtype': 74, 'Mutant': 19}) test Counter({'Wildtype': 19, 'Mutant': 4})\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:22:10 | models:grid_cv_model] best parameters: {'predictor__C': 0.01, 'predictor__degree': 1}\n",
      "[05-19 17:22:10 | models:predict_with_model] result for CV:{'split0_test_score': array([0.80645161, 0.80645161, 0.80645161, 0.80645161, 0.80645161,\n",
      "       0.80645161, 0.80645161, 0.80645161, 0.80645161]), 'split1_test_score': array([0.83870968, 0.83870968, 0.83870968, 0.83870968, 0.83870968,\n",
      "       0.83870968, 0.83870968, 0.83870968, 0.83870968]), 'split2_test_score': array([0.74193548, 0.74193548, 0.74193548, 0.74193548, 0.74193548,\n",
      "       0.74193548, 0.74193548, 0.74193548, 0.74193548]), 'mean_test_score': array([0.79569892, 0.79569892, 0.79569892, 0.79569892, 0.79569892,\n",
      "       0.79569892, 0.79569892, 0.79569892, 0.79569892]), 'std_test_score': array([0.04023288, 0.04023288, 0.04023288, 0.04023288, 0.04023288,\n",
      "       0.04023288, 0.04023288, 0.04023288, 0.04023288]), 'rank_test_score': array([1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)}\n",
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:22:10 | models:predict_with_model] result for validation set:{'Accuracy': 0.8260869565217391, 'F1': 0.7474120082815735, 'Precision': 0.6824196597353497, 'Recall': 0.8260869565217391, 'AUROC': 0.7763157894736842}\n",
      "[05-19 17:22:10 | models:predict_with_model] ======svc======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "train Counter({'Wildtype': 74, 'Mutant': 19}) test Counter({'Wildtype': 19, 'Mutant': 4})\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:22:11 | models:grid_cv_model] best parameters: {'predictor__C': 0.01, 'predictor__degree': 1}\n",
      "[05-19 17:22:11 | models:predict_with_model] result for CV:{'split0_test_score': array([0.70967742, 0.70967742, 0.70967742, 0.70967742, 0.70967742,\n",
      "       0.70967742, 0.70967742, 0.70967742, 0.70967742]), 'split1_test_score': array([0.83870968, 0.83870968, 0.83870968, 0.83870968, 0.83870968,\n",
      "       0.83870968, 0.83870968, 0.83870968, 0.83870968]), 'split2_test_score': array([0.83870968, 0.83870968, 0.83870968, 0.83870968, 0.83870968,\n",
      "       0.83870968, 0.83870968, 0.83870968, 0.83870968]), 'mean_test_score': array([0.79569892, 0.79569892, 0.79569892, 0.79569892, 0.79569892,\n",
      "       0.79569892, 0.79569892, 0.79569892, 0.79569892]), 'std_test_score': array([0.06082639, 0.06082639, 0.06082639, 0.06082639, 0.06082639,\n",
      "       0.06082639, 0.06082639, 0.06082639, 0.06082639]), 'rank_test_score': array([1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)}\n",
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:22:11 | models:predict_with_model] result for validation set:{'Accuracy': 0.8260869565217391, 'F1': 0.7474120082815735, 'Precision': 0.6824196597353497, 'Recall': 0.8260869565217391, 'AUROC': 0.6842105263157895}\n",
      "[05-19 17:22:11 | cv_models:cv_predict_eval_with_model] ======random_forest======\n",
      "[05-19 17:22:11 | models:predict_with_model] ======random_forest======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "train Counter({'Wildtype': 74, 'Mutant': 18}) test Counter({'Wildtype': 19, 'Mutant': 5})\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.9s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.1s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:22:44 | models:grid_cv_model] best parameters: {'predictor__max_depth': 10, 'predictor__max_features': 'auto', 'predictor__min_samples_leaf': 1, 'predictor__n_estimators': 100}\n",
      "[05-19 17:22:44 | models:predict_with_model] result for CV:{'split0_test_score': array([0.74193548, 0.74193548, 0.74193548, 0.74193548, 0.74193548,\n",
      "       0.74193548, 0.74193548, 0.74193548, 0.74193548, 0.74193548,\n",
      "       0.74193548, 0.74193548, 0.74193548, 0.74193548, 0.74193548,\n",
      "       0.74193548]), 'split1_test_score': array([0.83870968, 0.83870968, 0.83870968, 0.83870968, 0.83870968,\n",
      "       0.83870968, 0.83870968, 0.83870968, 0.83870968, 0.83870968,\n",
      "       0.83870968, 0.83870968, 0.83870968, 0.83870968, 0.83870968,\n",
      "       0.83870968]), 'split2_test_score': array([0.83333333, 0.83333333, 0.83333333, 0.83333333, 0.83333333,\n",
      "       0.83333333, 0.83333333, 0.83333333, 0.83333333, 0.83333333,\n",
      "       0.83333333, 0.83333333, 0.83333333, 0.83333333, 0.83333333,\n",
      "       0.83333333]), 'mean_test_score': array([0.8046595, 0.8046595, 0.8046595, 0.8046595, 0.8046595, 0.8046595,\n",
      "       0.8046595, 0.8046595, 0.8046595, 0.8046595, 0.8046595, 0.8046595,\n",
      "       0.8046595, 0.8046595, 0.8046595, 0.8046595]), 'std_test_score': array([0.04440685, 0.04440685, 0.04440685, 0.04440685, 0.04440685,\n",
      "       0.04440685, 0.04440685, 0.04440685, 0.04440685, 0.04440685,\n",
      "       0.04440685, 0.04440685, 0.04440685, 0.04440685, 0.04440685,\n",
      "       0.04440685]), 'rank_test_score': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:22:44 | models:predict_with_model] result for validation set:{'Accuracy': 0.7916666666666666, 'F1': 0.6996124031007752, 'Precision': 0.626736111111111, 'Recall': 0.7916666666666666, 'AUROC': 0.6368421052631579}\n",
      "[05-19 17:22:44 | models:predict_with_model] ======random_forest======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Counter({'Wildtype': 75, 'Mutant': 18}) test Counter({'Wildtype': 18, 'Mutant': 5})\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:23:15 | models:grid_cv_model] best parameters: {'predictor__max_depth': 10, 'predictor__max_features': 'auto', 'predictor__min_samples_leaf': 1, 'predictor__n_estimators': 100}\n",
      "[05-19 17:23:15 | models:predict_with_model] result for CV:{'split0_test_score': array([0.87096774, 0.87096774, 0.87096774, 0.87096774, 0.87096774,\n",
      "       0.87096774, 0.87096774, 0.87096774, 0.87096774, 0.87096774,\n",
      "       0.87096774, 0.87096774, 0.87096774, 0.87096774, 0.87096774,\n",
      "       0.87096774]), 'split1_test_score': array([0.80645161, 0.80645161, 0.80645161, 0.80645161, 0.80645161,\n",
      "       0.80645161, 0.80645161, 0.80645161, 0.80645161, 0.80645161,\n",
      "       0.80645161, 0.80645161, 0.80645161, 0.80645161, 0.80645161,\n",
      "       0.80645161]), 'split2_test_score': array([0.74193548, 0.74193548, 0.74193548, 0.74193548, 0.74193548,\n",
      "       0.74193548, 0.74193548, 0.74193548, 0.74193548, 0.74193548,\n",
      "       0.74193548, 0.74193548, 0.74193548, 0.74193548, 0.74193548,\n",
      "       0.74193548]), 'mean_test_score': array([0.80645161, 0.80645161, 0.80645161, 0.80645161, 0.80645161,\n",
      "       0.80645161, 0.80645161, 0.80645161, 0.80645161, 0.80645161,\n",
      "       0.80645161, 0.80645161, 0.80645161, 0.80645161, 0.80645161,\n",
      "       0.80645161]), 'std_test_score': array([0.0526772, 0.0526772, 0.0526772, 0.0526772, 0.0526772, 0.0526772,\n",
      "       0.0526772, 0.0526772, 0.0526772, 0.0526772, 0.0526772, 0.0526772,\n",
      "       0.0526772, 0.0526772, 0.0526772, 0.0526772]), 'rank_test_score': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:23:16 | models:predict_with_model] result for validation set:{'Accuracy': 0.782608695652174, 'F1': 0.687168610816543, 'Precision': 0.6124763705103969, 'Recall': 0.782608695652174, 'AUROC': 0.7777777777777778}\n",
      "[05-19 17:23:16 | models:predict_with_model] ======random_forest======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "train Counter({'Wildtype': 75, 'Mutant': 18}) test Counter({'Wildtype': 18, 'Mutant': 5})\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   1.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:23:48 | models:grid_cv_model] best parameters: {'predictor__max_depth': 10, 'predictor__max_features': 'auto', 'predictor__min_samples_leaf': 1, 'predictor__n_estimators': 100}\n",
      "[05-19 17:23:48 | models:predict_with_model] result for CV:{'split0_test_score': array([0.83870968, 0.83870968, 0.83870968, 0.83870968, 0.83870968,\n",
      "       0.83870968, 0.83870968, 0.83870968, 0.83870968, 0.83870968,\n",
      "       0.83870968, 0.83870968, 0.83870968, 0.83870968, 0.83870968,\n",
      "       0.83870968]), 'split1_test_score': array([0.87096774, 0.87096774, 0.87096774, 0.87096774, 0.87096774,\n",
      "       0.87096774, 0.87096774, 0.87096774, 0.87096774, 0.87096774,\n",
      "       0.87096774, 0.87096774, 0.87096774, 0.87096774, 0.87096774,\n",
      "       0.87096774]), 'split2_test_score': array([0.70967742, 0.70967742, 0.70967742, 0.70967742, 0.70967742,\n",
      "       0.70967742, 0.70967742, 0.70967742, 0.70967742, 0.70967742,\n",
      "       0.70967742, 0.70967742, 0.70967742, 0.70967742, 0.70967742,\n",
      "       0.70967742]), 'mean_test_score': array([0.80645161, 0.80645161, 0.80645161, 0.80645161, 0.80645161,\n",
      "       0.80645161, 0.80645161, 0.80645161, 0.80645161, 0.80645161,\n",
      "       0.80645161, 0.80645161, 0.80645161, 0.80645161, 0.80645161,\n",
      "       0.80645161]), 'std_test_score': array([0.06968538, 0.06968538, 0.06968538, 0.06968538, 0.06968538,\n",
      "       0.06968538, 0.06968538, 0.06968538, 0.06968538, 0.06968538,\n",
      "       0.06968538, 0.06968538, 0.06968538, 0.06968538, 0.06968538,\n",
      "       0.06968538]), 'rank_test_score': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:23:48 | models:predict_with_model] result for validation set:{'Accuracy': 0.782608695652174, 'F1': 0.687168610816543, 'Precision': 0.6124763705103969, 'Recall': 0.782608695652174, 'AUROC': 0.5888888888888889}\n",
      "[05-19 17:23:48 | models:predict_with_model] ======random_forest======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "train Counter({'Wildtype': 74, 'Mutant': 19}) test Counter({'Wildtype': 19, 'Mutant': 4})\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:24:20 | models:grid_cv_model] best parameters: {'predictor__max_depth': 10, 'predictor__max_features': 'auto', 'predictor__min_samples_leaf': 1, 'predictor__n_estimators': 100}\n",
      "[05-19 17:24:20 | models:predict_with_model] result for CV:{'split0_test_score': array([0.80645161, 0.80645161, 0.80645161, 0.80645161, 0.80645161,\n",
      "       0.80645161, 0.80645161, 0.80645161, 0.80645161, 0.80645161,\n",
      "       0.80645161, 0.80645161, 0.80645161, 0.80645161, 0.80645161,\n",
      "       0.80645161]), 'split1_test_score': array([0.83870968, 0.83870968, 0.83870968, 0.83870968, 0.83870968,\n",
      "       0.83870968, 0.83870968, 0.83870968, 0.83870968, 0.83870968,\n",
      "       0.83870968, 0.83870968, 0.83870968, 0.83870968, 0.83870968,\n",
      "       0.83870968]), 'split2_test_score': array([0.74193548, 0.74193548, 0.74193548, 0.74193548, 0.74193548,\n",
      "       0.74193548, 0.74193548, 0.74193548, 0.74193548, 0.74193548,\n",
      "       0.74193548, 0.74193548, 0.74193548, 0.74193548, 0.74193548,\n",
      "       0.74193548]), 'mean_test_score': array([0.79569892, 0.79569892, 0.79569892, 0.79569892, 0.79569892,\n",
      "       0.79569892, 0.79569892, 0.79569892, 0.79569892, 0.79569892,\n",
      "       0.79569892, 0.79569892, 0.79569892, 0.79569892, 0.79569892,\n",
      "       0.79569892]), 'std_test_score': array([0.04023288, 0.04023288, 0.04023288, 0.04023288, 0.04023288,\n",
      "       0.04023288, 0.04023288, 0.04023288, 0.04023288, 0.04023288,\n",
      "       0.04023288, 0.04023288, 0.04023288, 0.04023288, 0.04023288,\n",
      "       0.04023288]), 'rank_test_score': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:24:20 | models:predict_with_model] result for validation set:{'Accuracy': 0.8260869565217391, 'F1': 0.7474120082815735, 'Precision': 0.6824196597353497, 'Recall': 0.8260869565217391, 'AUROC': 0.4671052631578947}\n",
      "[05-19 17:24:20 | models:predict_with_model] ======random_forest======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "train Counter({'Wildtype': 74, 'Mutant': 19}) test Counter({'Wildtype': 19, 'Mutant': 4})\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:24:52 | models:grid_cv_model] best parameters: {'predictor__max_depth': 10, 'predictor__max_features': 'auto', 'predictor__min_samples_leaf': 4, 'predictor__n_estimators': 100}\n",
      "[05-19 17:24:52 | models:predict_with_model] result for CV:{'split0_test_score': array([0.67741935, 0.67741935, 0.67741935, 0.67741935, 0.70967742,\n",
      "       0.70967742, 0.70967742, 0.70967742, 0.67741935, 0.67741935,\n",
      "       0.67741935, 0.67741935, 0.70967742, 0.70967742, 0.70967742,\n",
      "       0.70967742]), 'split1_test_score': array([0.83870968, 0.83870968, 0.83870968, 0.83870968, 0.83870968,\n",
      "       0.83870968, 0.83870968, 0.83870968, 0.83870968, 0.83870968,\n",
      "       0.83870968, 0.83870968, 0.83870968, 0.83870968, 0.83870968,\n",
      "       0.83870968]), 'split2_test_score': array([0.83870968, 0.83870968, 0.83870968, 0.83870968, 0.83870968,\n",
      "       0.83870968, 0.83870968, 0.83870968, 0.83870968, 0.83870968,\n",
      "       0.83870968, 0.83870968, 0.83870968, 0.83870968, 0.83870968,\n",
      "       0.83870968]), 'mean_test_score': array([0.78494624, 0.78494624, 0.78494624, 0.78494624, 0.79569892,\n",
      "       0.79569892, 0.79569892, 0.79569892, 0.78494624, 0.78494624,\n",
      "       0.78494624, 0.78494624, 0.79569892, 0.79569892, 0.79569892,\n",
      "       0.79569892]), 'std_test_score': array([0.07603299, 0.07603299, 0.07603299, 0.07603299, 0.06082639,\n",
      "       0.06082639, 0.06082639, 0.06082639, 0.07603299, 0.07603299,\n",
      "       0.07603299, 0.07603299, 0.06082639, 0.06082639, 0.06082639,\n",
      "       0.06082639]), 'rank_test_score': array([9, 9, 9, 9, 1, 1, 1, 1, 9, 9, 9, 9, 1, 1, 1, 1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:24:52 | models:predict_with_model] result for validation set:{'Accuracy': 0.8260869565217391, 'F1': 0.7474120082815735, 'Precision': 0.6824196597353497, 'Recall': 0.8260869565217391, 'AUROC': 0.3684210526315789}\n",
      "[05-19 17:24:52 | cv_models:cv_predict_eval_with_model] ======mlp======\n",
      "[05-19 17:24:52 | models:predict_with_model] ======mlp======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "train Counter({'Wildtype': 74, 'Mutant': 18}) test Counter({'Wildtype': 19, 'Mutant': 5})\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.9s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.9s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   2.1s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   2.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.6s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:25:04 | models:grid_cv_model] best parameters: {'predictor__hidden_layer_sizes': (400, 40)}\n",
      "[05-19 17:25:04 | models:predict_with_model] result for CV:{'split0_test_score': array([0.77419355, 0.70967742, 0.74193548, 0.74193548]), 'split1_test_score': array([0.64516129, 0.80645161, 0.77419355, 0.80645161]), 'split2_test_score': array([0.6       , 0.83333333, 0.76666667, 0.83333333]), 'mean_test_score': array([0.67311828, 0.78315412, 0.7609319 , 0.79390681]), 'std_test_score': array([0.07381076, 0.05310227, 0.01377949, 0.03835293]), 'rank_test_score': array([4, 2, 3, 1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:25:06 | models:predict_with_model] result for validation set:{'Accuracy': 0.7916666666666666, 'F1': 0.6996124031007752, 'Precision': 0.626736111111111, 'Recall': 0.7916666666666666, 'AUROC': 0.3052631578947368}\n",
      "[05-19 17:25:06 | models:predict_with_model] ======mlp======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.8s\n",
      "train Counter({'Wildtype': 75, 'Mutant': 18}) test Counter({'Wildtype': 18, 'Mutant': 5})\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.3s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   2.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   2.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:25:17 | models:grid_cv_model] best parameters: {'predictor__hidden_layer_sizes': (200, 20)}\n",
      "[05-19 17:25:17 | models:predict_with_model] result for CV:{'split0_test_score': array([0.87096774, 0.64516129, 0.80645161, 0.61290323]), 'split1_test_score': array([0.58064516, 0.74193548, 0.70967742, 0.80645161]), 'split2_test_score': array([0.70967742, 0.70967742, 0.70967742, 0.70967742]), 'mean_test_score': array([0.72043011, 0.69892473, 0.74193548, 0.70967742]), 'std_test_score': array([0.11876732, 0.04023288, 0.04561979, 0.0790158 ]), 'rank_test_score': array([2, 4, 1, 3], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:25:18 | models:predict_with_model] result for validation set:{'Accuracy': 0.6521739130434783, 'F1': 0.6178489702517161, 'Precision': 0.5869565217391305, 'Recall': 0.6521739130434783, 'AUROC': 0.28888888888888886}\n",
      "[05-19 17:25:18 | models:predict_with_model] ======mlp======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.1s\n",
      "train Counter({'Wildtype': 75, 'Mutant': 18}) test Counter({'Wildtype': 18, 'Mutant': 5})\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.9s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.3s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.9s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.9s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:25:29 | models:grid_cv_model] best parameters: {'predictor__hidden_layer_sizes': (100, 20)}\n",
      "[05-19 17:25:29 | models:predict_with_model] result for CV:{'split0_test_score': array([0.77419355, 0.83870968, 0.80645161, 0.48387097]), 'split1_test_score': array([0.67741935, 0.77419355, 0.51612903, 0.83870968]), 'split2_test_score': array([0.5483871 , 0.5483871 , 0.70967742, 0.74193548]), 'mean_test_score': array([0.66666667, 0.72043011, 0.67741935, 0.68817204]), 'std_test_score': array([0.09249812, 0.12447136, 0.12069863, 0.14976762]), 'rank_test_score': array([4, 1, 3, 2], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:25:29 | models:predict_with_model] result for validation set:{'Accuracy': 0.8260869565217391, 'F1': 0.7768115942028986, 'Precision': 0.8577075098814229, 'Recall': 0.8260869565217391, 'AUROC': 0.8555555555555556}\n",
      "[05-19 17:25:29 | models:predict_with_model] ======mlp======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "train Counter({'Wildtype': 74, 'Mutant': 19}) test Counter({'Wildtype': 19, 'Mutant': 4})\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.9s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.3s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   2.0s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   2.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.5s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:25:40 | models:grid_cv_model] best parameters: {'predictor__hidden_layer_sizes': (200, 20)}\n",
      "[05-19 17:25:40 | models:predict_with_model] result for CV:{'split0_test_score': array([0.41935484, 0.61290323, 0.80645161, 0.67741935]), 'split1_test_score': array([0.64516129, 0.77419355, 0.80645161, 0.74193548]), 'split2_test_score': array([0.77419355, 0.51612903, 0.70967742, 0.74193548]), 'mean_test_score': array([0.61290323, 0.6344086 , 0.77419355, 0.72043011]), 'std_test_score': array([0.14664712, 0.10644618, 0.04561979, 0.03041319]), 'rank_test_score': array([4, 3, 1, 2], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:25:41 | models:predict_with_model] result for validation set:{'Accuracy': 0.8260869565217391, 'F1': 0.7474120082815735, 'Precision': 0.6824196597353497, 'Recall': 0.8260869565217391, 'AUROC': 0.4342105263157895}\n",
      "[05-19 17:25:41 | models:predict_with_model] ======mlp======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "train Counter({'Wildtype': 74, 'Mutant': 19}) test Counter({'Wildtype': 19, 'Mutant': 4})\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:25:51 | models:grid_cv_model] best parameters: {'predictor__hidden_layer_sizes': (200, 20)}\n",
      "[05-19 17:25:51 | models:predict_with_model] result for CV:{'split0_test_score': array([0.51612903, 0.5483871 , 0.67741935, 0.70967742]), 'split1_test_score': array([0.4516129 , 0.80645161, 0.74193548, 0.58064516]), 'split2_test_score': array([0.64516129, 0.64516129, 0.77419355, 0.74193548]), 'mean_test_score': array([0.53763441, 0.66666667, 0.7311828 , 0.67741935]), 'std_test_score': array([0.08046575, 0.10644618, 0.04023288, 0.06968538]), 'rank_test_score': array([4, 3, 1, 2], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:25:53 | models:predict_with_model] result for validation set:{'Accuracy': 0.782608695652174, 'F1': 0.7253446447507954, 'Precision': 0.6758893280632412, 'Recall': 0.782608695652174, 'AUROC': 0.4473684210526316}\n",
      "[05-19 17:25:53 | cv_models:cv_predict_eval_with_model] ======xgboost======\n",
      "[05-19 17:25:53 | models:predict_with_model] ======xgboost======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.4s\n",
      "train Counter({'Wildtype': 74, 'Mutant': 18}) test Counter({'Wildtype': 19, 'Mutant': 5})\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:25:53] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   1.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:25:54] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.9s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:25:55] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.9s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:25:55] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.9s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:25:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.9s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:25:57] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.9s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:25:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:25:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.5s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   1.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:26:00] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:26:00] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.9s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:26:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:26:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   1.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:26:02] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[05-19 17:26:03 | models:grid_cv_model] best parameters: {'predictor__learning_rate': 0.1, 'predictor__n_estimators': 100, 'predictor__reg_alpha': 1}\n",
      "[05-19 17:26:03 | models:predict_with_model] result for CV:{'split0_test_score': array([0.77419355, 0.77419355, 0.74193548, 0.77419355]), 'split1_test_score': array([0.67741935, 0.67741935, 0.80645161, 0.67741935]), 'split2_test_score': array([0.83333333, 0.8       , 0.8       , 0.83333333]), 'mean_test_score': array([0.76164875, 0.75053763, 0.7827957 , 0.76164875]), 'std_test_score': array([0.06426674, 0.05276492, 0.02901234, 0.06426674]), 'rank_test_score': array([2, 4, 1, 2], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:26:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[05-19 17:26:04 | models:predict_with_model] result for validation set:{'Accuracy': 0.75, 'F1': 0.6785714285714285, 'Precision': 0.6195652173913043, 'Recall': 0.75, 'AUROC': 0.5578947368421052}\n",
      "[05-19 17:26:04 | models:predict_with_model] ======xgboost======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "train Counter({'Wildtype': 75, 'Mutant': 18}) test Counter({'Wildtype': 18, 'Mutant': 5})\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:26:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.9s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:26:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:26:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.9s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:26:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.9s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:26:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:26:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   1.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:26:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:26:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:26:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:26:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:26:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:26:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:26:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[05-19 17:26:12 | models:grid_cv_model] best parameters: {'predictor__learning_rate': 0.01, 'predictor__n_estimators': 100, 'predictor__reg_alpha': 10}\n",
      "[05-19 17:26:12 | models:predict_with_model] result for CV:{'split0_test_score': array([0.80645161, 0.93548387, 0.87096774, 0.87096774]), 'split1_test_score': array([0.74193548, 0.80645161, 0.80645161, 0.80645161]), 'split2_test_score': array([0.67741935, 0.74193548, 0.74193548, 0.74193548]), 'mean_test_score': array([0.74193548, 0.82795699, 0.80645161, 0.80645161]), 'std_test_score': array([0.0526772 , 0.08046575, 0.0526772 , 0.0526772 ]), 'rank_test_score': array([4, 1, 2, 2], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:26:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:26:13 | models:predict_with_model] result for validation set:{'Accuracy': 0.782608695652174, 'F1': 0.687168610816543, 'Precision': 0.6124763705103969, 'Recall': 0.782608695652174, 'AUROC': 0.8333333333333333}\n",
      "[05-19 17:26:13 | models:predict_with_model] ======xgboost======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "train Counter({'Wildtype': 75, 'Mutant': 18}) test Counter({'Wildtype': 18, 'Mutant': 5})\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:26:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:26:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:26:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:26:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:26:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:26:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:26:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:26:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:26:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:26:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:26:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:26:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:26:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[05-19 17:26:17 | models:grid_cv_model] best parameters: {'predictor__learning_rate': 0.1, 'predictor__n_estimators': 100, 'predictor__reg_alpha': 10}\n",
      "[05-19 17:26:17 | models:predict_with_model] result for CV:{'split0_test_score': array([0.77419355, 0.80645161, 0.83870968, 0.83870968]), 'split1_test_score': array([0.80645161, 0.74193548, 0.83870968, 0.87096774]), 'split2_test_score': array([0.70967742, 0.70967742, 0.70967742, 0.70967742]), 'mean_test_score': array([0.76344086, 0.75268817, 0.79569892, 0.80645161]), 'std_test_score': array([0.04023288, 0.04023288, 0.06082639, 0.06968538]), 'rank_test_score': array([3, 4, 2, 1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:26:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[05-19 17:26:17 | models:predict_with_model] result for validation set:{'Accuracy': 0.7391304347826086, 'F1': 0.6652173913043478, 'Precision': 0.6047430830039525, 'Recall': 0.7391304347826086, 'AUROC': 0.4444444444444444}\n",
      "[05-19 17:26:17 | models:predict_with_model] ======xgboost======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "train Counter({'Wildtype': 74, 'Mutant': 19}) test Counter({'Wildtype': 19, 'Mutant': 4})\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:26:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:26:18] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:26:18] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:26:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:26:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:26:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:26:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:26:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:26:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:26:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:26:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:26:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:26:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[05-19 17:26:22 | models:grid_cv_model] best parameters: {'predictor__learning_rate': 0.01, 'predictor__n_estimators': 100, 'predictor__reg_alpha': 1}\n",
      "[05-19 17:26:22 | models:predict_with_model] result for CV:{'split0_test_score': array([0.74193548, 0.74193548, 0.74193548, 0.77419355]), 'split1_test_score': array([0.83870968, 0.67741935, 0.80645161, 0.74193548]), 'split2_test_score': array([0.74193548, 0.74193548, 0.74193548, 0.74193548]), 'mean_test_score': array([0.77419355, 0.72043011, 0.76344086, 0.75268817]), 'std_test_score': array([0.04561979, 0.03041319, 0.03041319, 0.0152066 ]), 'rank_test_score': array([1, 4, 2, 3], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:26:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:26:23 | models:predict_with_model] result for validation set:{'Accuracy': 0.8260869565217391, 'F1': 0.7474120082815735, 'Precision': 0.6824196597353497, 'Recall': 0.8260869565217391, 'AUROC': 0.5394736842105263}\n",
      "[05-19 17:26:23 | models:predict_with_model] ======xgboost======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "train Counter({'Wildtype': 74, 'Mutant': 19}) test Counter({'Wildtype': 19, 'Mutant': 4})\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:26:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:26:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:26:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:26:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:26:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:26:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:26:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:26:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:26:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:26:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:26:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:26:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:26:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[05-19 17:26:27 | models:grid_cv_model] best parameters: {'predictor__learning_rate': 0.1, 'predictor__n_estimators': 100, 'predictor__reg_alpha': 10}\n",
      "[05-19 17:26:27 | models:predict_with_model] result for CV:{'split0_test_score': array([0.64516129, 0.61290323, 0.64516129, 0.67741935]), 'split1_test_score': array([0.74193548, 0.83870968, 0.74193548, 0.83870968]), 'split2_test_score': array([0.83870968, 0.83870968, 0.80645161, 0.83870968]), 'mean_test_score': array([0.74193548, 0.76344086, 0.7311828 , 0.78494624]), 'std_test_score': array([0.0790158 , 0.10644618, 0.06628402, 0.07603299]), 'rank_test_score': array([3, 2, 4, 1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:26:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:26:27 | models:predict_with_model] result for validation set:{'Accuracy': 0.8260869565217391, 'F1': 0.7474120082815735, 'Precision': 0.6824196597353497, 'Recall': 0.8260869565217391, 'AUROC': 0.7368421052631579}\n",
      "[05-19 17:26:27 | application_cross_validation:ApplicationCV] Saved results to /labs/gevaertlab/users/yyhhli/code/vae/applications/results/VAE3D32AUG_70/StfEGFRMutation.cv_result_dict.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "{'__dict': {}, 'logistic_regression': {'Accuracy': [0.7916666666666666, 0.782608695652174, 0.782608695652174, 0.8260869565217391, 0.8260869565217391], 'F1': [0.6996124031007752, 0.687168610816543, 0.687168610816543, 0.7474120082815735, 0.7474120082815735], 'Precision': [0.626736111111111, 0.6124763705103969, 0.6124763705103969, 0.6824196597353497, 0.6824196597353497], 'Recall': [0.7916666666666666, 0.782608695652174, 0.782608695652174, 0.8260869565217391, 0.8260869565217391], 'AUROC': [0.5, 0.5, 0.5, 0.5, 0.5]}, 'k_nearest_neighbors': {'Accuracy': [0.7916666666666666, 0.7391304347826086, 0.782608695652174, 0.8260869565217391, 0.8260869565217391], 'F1': [0.6996124031007752, 0.6652173913043478, 0.687168610816543, 0.7474120082815735, 0.7474120082815735], 'Precision': [0.626736111111111, 0.6047430830039525, 0.6124763705103969, 0.6824196597353497, 0.6824196597353497], 'Recall': [0.7916666666666666, 0.7391304347826086, 0.782608695652174, 0.8260869565217391, 0.8260869565217391], 'AUROC': [0.4526315789473684, 0.4833333333333334, 0.36111111111111116, 0.3157894736842105, 0.4013157894736842]}, 'svc': {'Accuracy': [0.7916666666666666, 0.782608695652174, 0.782608695652174, 0.8260869565217391, 0.8260869565217391], 'F1': [0.6996124031007752, 0.687168610816543, 0.687168610816543, 0.7474120082815735, 0.7474120082815735], 'Precision': [0.626736111111111, 0.6124763705103969, 0.6124763705103969, 0.6824196597353497, 0.6824196597353497], 'Recall': [0.7916666666666666, 0.782608695652174, 0.782608695652174, 0.8260869565217391, 0.8260869565217391], 'AUROC': [0.5473684210526315, 0.4111111111111111, 0.6111111111111112, 0.7763157894736842, 0.6842105263157895]}, 'random_forest': {'Accuracy': [0.7916666666666666, 0.782608695652174, 0.782608695652174, 0.8260869565217391, 0.8260869565217391], 'F1': [0.6996124031007752, 0.687168610816543, 0.687168610816543, 0.7474120082815735, 0.7474120082815735], 'Precision': [0.626736111111111, 0.6124763705103969, 0.6124763705103969, 0.6824196597353497, 0.6824196597353497], 'Recall': [0.7916666666666666, 0.782608695652174, 0.782608695652174, 0.8260869565217391, 0.8260869565217391], 'AUROC': [0.6368421052631579, 0.7777777777777778, 0.5888888888888889, 0.4671052631578947, 0.3684210526315789]}, 'mlp': {'Accuracy': [0.7916666666666666, 0.6521739130434783, 0.8260869565217391, 0.8260869565217391, 0.782608695652174], 'F1': [0.6996124031007752, 0.6178489702517161, 0.7768115942028986, 0.7474120082815735, 0.7253446447507954], 'Precision': [0.626736111111111, 0.5869565217391305, 0.8577075098814229, 0.6824196597353497, 0.6758893280632412], 'Recall': [0.7916666666666666, 0.6521739130434783, 0.8260869565217391, 0.8260869565217391, 0.782608695652174], 'AUROC': [0.3052631578947368, 0.28888888888888886, 0.8555555555555556, 0.4342105263157895, 0.4473684210526316]}, 'xgboost': {'Accuracy': [0.75, 0.782608695652174, 0.7391304347826086, 0.8260869565217391, 0.8260869565217391], 'F1': [0.6785714285714285, 0.687168610816543, 0.6652173913043478, 0.7474120082815735, 0.7474120082815735], 'Precision': [0.6195652173913043, 0.6124763705103969, 0.6047430830039525, 0.6824196597353497, 0.6824196597353497], 'Recall': [0.75, 0.782608695652174, 0.7391304347826086, 0.8260869565217391, 0.8260869565217391], 'AUROC': [0.5578947368421052, 0.8333333333333333, 0.4444444444444444, 0.5394736842105263, 0.7368421052631579]}}\n",
      "======= Predicting StfKRASMutation with model version 70 =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:26:31 | patch_ds:LIDCPatchAugDataset] patient split: train:699, val:88, test:88\n",
      "[05-19 17:26:31 | patch_ds:LNDbPatch32AugDataset] patient split: train:168, val:22, test:22\n",
      "[05-19 17:26:31 | patch_stanfordradiogenomics:StanfordRadiogenomicsPatchAugDataset] patient split: train:100, test:43\n",
      "[05-19 17:26:31 | export:  Exporter] initializing embeddings\n",
      "[05-19 17:26:34 | patch_ds:LIDCPatchAugDataset] patient split: train:699, val:88, test:88\n",
      "[05-19 17:26:35 | patch_ds:LNDbPatch32AugDataset] patient split: train:168, val:22, test:22\n",
      "[05-19 17:26:35 | patch_stanfordradiogenomics:StanfordRadiogenomicsPatchAugDataset] patient split: train:100, test:43\n",
      "[05-19 17:26:35 | application_cross_validation:ApplicationCV] -----CV prediction for task StfKRASMutation-----\n",
      "[05-19 17:26:35 | application:ApplicationCV] Loading best hparams ...\n",
      "[05-19 17:26:35 | cv_models:cv_predict_task] models used ['logistic_regression', 'k_nearest_neighbors', 'svc', 'random_forest', 'mlp', 'xgboost']\n",
      "[05-19 17:26:35 | cv_models:cv_predict_task] Before transform: X shape = train:(100, 4096), val:(43, 4096); Y shape = train:(100,), val:(43,)\n",
      "[05-19 17:26:35 | models:data_summary] X shape = train:(78, 4096), val:(36, 4096); Y shape = train:(78,), val:(36,)\n",
      "Y classes = \n",
      " train: \n",
      "      value count\n",
      "0    Mutant    19\n",
      "1  Wildtype    59; \n",
      " val: \n",
      "      value count\n",
      "0    Mutant     7\n",
      "1  Wildtype    29\n",
      "[05-19 17:26:35 | cv_models:cv_predict_eval_with_model] ======logistic_regression======\n",
      "[05-19 17:26:35 | models:predict_with_model] ======logistic_regression======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | 4.0 secs.\n",
      "initializing | 8.0 secs.\n",
      "train Counter({'Wildtype': 71, 'Mutant': 20}) test Counter({'Wildtype': 17, 'Mutant': 6})\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[05-19 17:26:37 | models:grid_cv_model] best parameters: {'predictor__C': 0.01}\n",
      "[05-19 17:26:37 | models:predict_with_model] result for CV:{'split0_test_score': array([0.70967742, 0.70967742]), 'split1_test_score': array([0.83333333, 0.83333333]), 'split2_test_score': array([0.8, 0.8]), 'mean_test_score': array([0.78100358, 0.78100358]), 'std_test_score': array([0.05223884, 0.05223884]), 'rank_test_score': array([1, 1], dtype=int32)}\n",
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:26:37 | models:predict_with_model] result for validation set:{'Accuracy': 0.7391304347826086, 'F1': 0.6282608695652173, 'Precision': 0.5463137996219282, 'Recall': 0.7391304347826086, 'AUROC': 0.5}\n",
      "[05-19 17:26:37 | models:predict_with_model] ======logistic_regression======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "train Counter({'Wildtype': 70, 'Mutant': 21}) test Counter({'Wildtype': 18, 'Mutant': 5})\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[05-19 17:26:39 | models:grid_cv_model] best parameters: {'predictor__C': 0.01}\n",
      "[05-19 17:26:39 | models:predict_with_model] result for CV:{'split0_test_score': array([0.83870968, 0.83870968]), 'split1_test_score': array([0.8, 0.8]), 'split2_test_score': array([0.66666667, 0.66666667]), 'mean_test_score': array([0.76845878, 0.76845878]), 'std_test_score': array([0.07369231, 0.07369231]), 'rank_test_score': array([1, 1], dtype=int32)}\n",
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:26:39 | models:predict_with_model] result for validation set:{'Accuracy': 0.782608695652174, 'F1': 0.687168610816543, 'Precision': 0.6124763705103969, 'Recall': 0.782608695652174, 'AUROC': 0.5}\n",
      "[05-19 17:26:39 | models:predict_with_model] ======logistic_regression======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "train Counter({'Wildtype': 70, 'Mutant': 21}) test Counter({'Wildtype': 18, 'Mutant': 5})\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[05-19 17:26:41 | models:grid_cv_model] best parameters: {'predictor__C': 0.01}\n",
      "[05-19 17:26:41 | models:predict_with_model] result for CV:{'split0_test_score': array([0.80645161, 0.80645161]), 'split1_test_score': array([0.66666667, 0.66666667]), 'split2_test_score': array([0.83333333, 0.83333333]), 'mean_test_score': array([0.7688172, 0.7688172]), 'std_test_score': array([0.07306028, 0.07306028]), 'rank_test_score': array([1, 1], dtype=int32)}\n",
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:26:41 | models:predict_with_model] result for validation set:{'Accuracy': 0.782608695652174, 'F1': 0.687168610816543, 'Precision': 0.6124763705103969, 'Recall': 0.782608695652174, 'AUROC': 0.5}\n",
      "[05-19 17:26:41 | models:predict_with_model] ======logistic_regression======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "train Counter({'Wildtype': 70, 'Mutant': 21}) test Counter({'Wildtype': 18, 'Mutant': 5})\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[05-19 17:26:43 | models:grid_cv_model] best parameters: {'predictor__C': 0.01}\n",
      "[05-19 17:26:43 | models:predict_with_model] result for CV:{'split0_test_score': array([0.64516129, 0.64516129]), 'split1_test_score': array([0.86666667, 0.86666667]), 'split2_test_score': array([0.8, 0.8]), 'mean_test_score': array([0.77060932, 0.77060932]), 'std_test_score': array([0.09278655, 0.09278655]), 'rank_test_score': array([1, 1], dtype=int32)}\n",
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:26:43 | models:predict_with_model] result for validation set:{'Accuracy': 0.782608695652174, 'F1': 0.687168610816543, 'Precision': 0.6124763705103969, 'Recall': 0.782608695652174, 'AUROC': 0.5}\n",
      "[05-19 17:26:43 | models:predict_with_model] ======logistic_regression======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "train Counter({'Wildtype': 71, 'Mutant': 21}) test Counter({'Wildtype': 17, 'Mutant': 5})\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[CV] END ..................................predictor__C=0.01; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[05-19 17:26:45 | models:grid_cv_model] best parameters: {'predictor__C': 0.01}\n",
      "[05-19 17:26:45 | models:predict_with_model] result for CV:{'split0_test_score': array([0.80645161, 0.80645161]), 'split1_test_score': array([0.77419355, 0.77419355]), 'split2_test_score': array([0.73333333, 0.73333333]), 'mean_test_score': array([0.77132616, 0.77132616]), 'std_test_score': array([0.02991919, 0.02991919]), 'rank_test_score': array([1, 1], dtype=int32)}\n",
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:26:45 | models:predict_with_model] result for validation set:{'Accuracy': 0.7727272727272727, 'F1': 0.6736596736596737, 'Precision': 0.597107438016529, 'Recall': 0.7727272727272727, 'AUROC': 0.5}\n",
      "[05-19 17:26:45 | cv_models:cv_predict_eval_with_model] ======k_nearest_neighbors======\n",
      "[05-19 17:26:45 | models:predict_with_model] ======k_nearest_neighbors======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ...................................predictor__C=0.1; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "train Counter({'Wildtype': 71, 'Mutant': 20}) test Counter({'Wildtype': 17, 'Mutant': 6})\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:26:47 | models:grid_cv_model] best parameters: {'predictor__n_neighbors': 7, 'predictor__p': 5}\n",
      "[05-19 17:26:47 | models:predict_with_model] result for CV:{'split0_test_score': array([0.70967742, 0.74193548, 0.74193548, 0.67741935, 0.70967742,\n",
      "       0.70967742, 0.70967742, 0.70967742, 0.74193548, 0.70967742,\n",
      "       0.70967742, 0.67741935]), 'split1_test_score': array([0.76666667, 0.8       , 0.83333333, 0.8       , 0.83333333,\n",
      "       0.83333333, 0.83333333, 0.83333333, 0.83333333, 0.83333333,\n",
      "       0.8       , 0.83333333]), 'split2_test_score': array([0.7       , 0.66666667, 0.66666667, 0.76666667, 0.73333333,\n",
      "       0.76666667, 0.8       , 0.8       , 0.8       , 0.8       ,\n",
      "       0.8       , 0.8       ]), 'mean_test_score': array([0.72544803, 0.73620072, 0.74731183, 0.74802867, 0.75878136,\n",
      "       0.76989247, 0.78100358, 0.78100358, 0.79175627, 0.78100358,\n",
      "       0.76989247, 0.7702509 ]), 'std_test_score': array([0.02941253, 0.05458394, 0.0681475 , 0.05174962, 0.05359352,\n",
      "       0.05053382, 0.05223884, 0.05223884, 0.0377656 , 0.05223884,\n",
      "       0.04257847, 0.06703755]), 'rank_test_score': array([12, 11, 10,  9,  8,  6,  2,  2,  1,  2,  6,  5], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:26:47 | models:predict_with_model] result for validation set:{'Accuracy': 0.6956521739130435, 'F1': 0.6064659977703456, 'Precision': 0.5375494071146245, 'Recall': 0.6956521739130435, 'AUROC': 0.3431372549019608}\n",
      "[05-19 17:26:47 | models:predict_with_model] ======k_nearest_neighbors======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Counter({'Wildtype': 70, 'Mutant': 21}) test Counter({'Wildtype': 18, 'Mutant': 5})\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:26:48 | models:grid_cv_model] best parameters: {'predictor__n_neighbors': 10, 'predictor__p': 5}\n",
      "[05-19 17:26:48 | models:predict_with_model] result for CV:{'split0_test_score': array([0.74193548, 0.77419355, 0.61290323, 0.83870968, 0.77419355,\n",
      "       0.67741935, 0.87096774, 0.83870968, 0.77419355, 0.83870968,\n",
      "       0.83870968, 0.77419355]), 'split1_test_score': array([0.66666667, 0.66666667, 0.66666667, 0.66666667, 0.7       ,\n",
      "       0.76666667, 0.66666667, 0.73333333, 0.76666667, 0.66666667,\n",
      "       0.7       , 0.8       ]), 'split2_test_score': array([0.66666667, 0.63333333, 0.56666667, 0.66666667, 0.66666667,\n",
      "       0.7       , 0.66666667, 0.66666667, 0.66666667, 0.66666667,\n",
      "       0.66666667, 0.66666667]), 'mean_test_score': array([0.69175627, 0.69139785, 0.61541219, 0.72401434, 0.71362007,\n",
      "       0.71469534, 0.73476703, 0.74623656, 0.73584229, 0.72401434,\n",
      "       0.73512545, 0.74695341]), 'std_test_score': array([0.03548206, 0.06010615, 0.04086336, 0.08110185, 0.04494172,\n",
      "       0.03788786, 0.09630845, 0.0708264 , 0.04901098, 0.08110185,\n",
      "       0.07449853, 0.05774059]), 'rank_test_score': array([10, 11, 12,  6,  9,  8,  5,  2,  3,  6,  4,  1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:26:49 | models:predict_with_model] result for validation set:{'Accuracy': 0.7391304347826086, 'F1': 0.6652173913043478, 'Precision': 0.6047430830039525, 'Recall': 0.7391304347826086, 'AUROC': 0.5555555555555556}\n",
      "[05-19 17:26:49 | models:predict_with_model] ======k_nearest_neighbors======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Counter({'Wildtype': 70, 'Mutant': 21}) test Counter({'Wildtype': 18, 'Mutant': 5})\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:26:50 | models:grid_cv_model] best parameters: {'predictor__n_neighbors': 7, 'predictor__p': 2}\n",
      "[05-19 17:26:50 | models:predict_with_model] result for CV:{'split0_test_score': array([0.70967742, 0.74193548, 0.80645161, 0.77419355, 0.77419355,\n",
      "       0.83870968, 0.80645161, 0.80645161, 0.77419355, 0.80645161,\n",
      "       0.80645161, 0.80645161]), 'split1_test_score': array([0.63333333, 0.63333333, 0.63333333, 0.63333333, 0.63333333,\n",
      "       0.63333333, 0.63333333, 0.63333333, 0.63333333, 0.66666667,\n",
      "       0.66666667, 0.66666667]), 'split2_test_score': array([0.66666667, 0.6       , 0.6       , 0.83333333, 0.8       ,\n",
      "       0.8       , 0.83333333, 0.86666667, 0.86666667, 0.83333333,\n",
      "       0.8       , 0.8       ]), 'mean_test_score': array([0.66989247, 0.65842294, 0.67992832, 0.74695341, 0.73584229,\n",
      "       0.75734767, 0.75770609, 0.7688172 , 0.75806452, 0.7688172 ,\n",
      "       0.75770609, 0.75770609]), 'std_test_score': array([0.0312507 , 0.06059998, 0.09049452, 0.08389088, 0.07324643,\n",
      "       0.08910397, 0.08862691, 0.09890525, 0.09593825, 0.07306028,\n",
      "       0.06442845, 0.06442845]), 'rank_test_score': array([11, 12, 10,  8,  9,  7,  6,  1,  3,  1,  4,  4], dtype=int32)}\n",
      "[05-19 17:26:50 | models:predict_with_model] result for validation set:{'Accuracy': 0.7391304347826086, 'F1': 0.6652173913043478, 'Precision': 0.6047430830039525, 'Recall': 0.7391304347826086, 'AUROC': 0.7555555555555555}\n",
      "[05-19 17:26:50 | models:predict_with_model] ======k_nearest_neighbors======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "train Counter({'Wildtype': 70, 'Mutant': 21}) test Counter({'Wildtype': 18, 'Mutant': 5})\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:26:52 | models:grid_cv_model] best parameters: {'predictor__n_neighbors': 7, 'predictor__p': 1}\n",
      "[05-19 17:26:52 | models:predict_with_model] result for CV:{'split0_test_score': array([0.67741935, 0.64516129, 0.5483871 , 0.67741935, 0.67741935,\n",
      "       0.61290323, 0.64516129, 0.64516129, 0.64516129, 0.64516129,\n",
      "       0.64516129, 0.64516129]), 'split1_test_score': array([0.73333333, 0.83333333, 0.63333333, 0.7       , 0.66666667,\n",
      "       0.73333333, 0.83333333, 0.76666667, 0.76666667, 0.76666667,\n",
      "       0.76666667, 0.76666667]), 'split2_test_score': array([0.66666667, 0.7       , 0.7       , 0.73333333, 0.73333333,\n",
      "       0.73333333, 0.73333333, 0.76666667, 0.76666667, 0.76666667,\n",
      "       0.8       , 0.76666667]), 'mean_test_score': array([0.69247312, 0.72616487, 0.62724014, 0.70358423, 0.69247312,\n",
      "       0.69318996, 0.73727599, 0.72616487, 0.72616487, 0.72616487,\n",
      "       0.73727599, 0.72616487]), 'std_test_score': array([0.02922411, 0.07901742, 0.06204549, 0.02296705, 0.02922411,\n",
      "       0.0567713 , 0.07687149, 0.05727818, 0.05727818, 0.05727818,\n",
      "       0.06654129, 0.05727818]), 'rank_test_score': array([10,  3, 12,  8, 10,  9,  1,  3,  3,  3,  1,  3], dtype=int32)}\n",
      "[05-19 17:26:52 | models:predict_with_model] result for validation set:{'Accuracy': 0.6086956521739131, 'F1': 0.5922444183313749, 'Precision': 0.5766590389016018, 'Recall': 0.6086956521739131, 'AUROC': 0.3833333333333333}\n",
      "[05-19 17:26:52 | models:predict_with_model] ======k_nearest_neighbors======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "train Counter({'Wildtype': 71, 'Mutant': 21}) test Counter({'Wildtype': 17, 'Mutant': 5})\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=3, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=5, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ...........predictor__n_neighbors=7, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:26:54 | models:grid_cv_model] best parameters: {'predictor__n_neighbors': 7, 'predictor__p': 5}\n",
      "[05-19 17:26:54 | models:predict_with_model] result for CV:{'split0_test_score': array([0.64516129, 0.64516129, 0.70967742, 0.67741935, 0.67741935,\n",
      "       0.77419355, 0.77419355, 0.74193548, 0.83870968, 0.80645161,\n",
      "       0.83870968, 0.80645161]), 'split1_test_score': array([0.74193548, 0.74193548, 0.70967742, 0.70967742, 0.70967742,\n",
      "       0.70967742, 0.77419355, 0.77419355, 0.77419355, 0.77419355,\n",
      "       0.80645161, 0.74193548]), 'split2_test_score': array([0.73333333, 0.73333333, 0.73333333, 0.7       , 0.73333333,\n",
      "       0.7       , 0.7       , 0.76666667, 0.76666667, 0.73333333,\n",
      "       0.73333333, 0.66666667]), 'mean_test_score': array([0.70681004, 0.70681004, 0.71756272, 0.69569892, 0.70681004,\n",
      "       0.72795699, 0.74946237, 0.7609319 , 0.79318996, 0.77132616,\n",
      "       0.79283154, 0.73835125]), 'std_test_score': array([0.04373347, 0.04373347, 0.0111515 , 0.01351592, 0.02291666,\n",
      "       0.03293203, 0.03497517, 0.01377949, 0.03233364, 0.02991919,\n",
      "       0.04408456, 0.05712322]), 'rank_test_score': array([ 9,  9,  8, 12,  9,  7,  5,  4,  1,  3,  2,  6], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..........predictor__n_neighbors=10, predictor__p=5; total time=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:26:54 | models:predict_with_model] result for validation set:{'Accuracy': 0.7727272727272727, 'F1': 0.6736596736596737, 'Precision': 0.597107438016529, 'Recall': 0.7727272727272727, 'AUROC': 0.30000000000000004}\n",
      "[05-19 17:26:54 | cv_models:cv_predict_eval_with_model] ======svc======\n",
      "[05-19 17:26:54 | models:predict_with_model] ======svc======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Counter({'Wildtype': 71, 'Mutant': 20}) test Counter({'Wildtype': 17, 'Mutant': 6})\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:26:55 | models:grid_cv_model] best parameters: {'predictor__C': 0.01, 'predictor__degree': 1}\n",
      "[05-19 17:26:55 | models:predict_with_model] result for CV:{'split0_test_score': array([0.70967742, 0.70967742, 0.70967742, 0.70967742, 0.70967742,\n",
      "       0.70967742, 0.70967742, 0.70967742, 0.70967742]), 'split1_test_score': array([0.83333333, 0.83333333, 0.83333333, 0.83333333, 0.83333333,\n",
      "       0.83333333, 0.83333333, 0.83333333, 0.83333333]), 'split2_test_score': array([0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]), 'mean_test_score': array([0.78100358, 0.78100358, 0.78100358, 0.78100358, 0.78100358,\n",
      "       0.78100358, 0.78100358, 0.78100358, 0.78100358]), 'std_test_score': array([0.05223884, 0.05223884, 0.05223884, 0.05223884, 0.05223884,\n",
      "       0.05223884, 0.05223884, 0.05223884, 0.05223884]), 'rank_test_score': array([1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)}\n",
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:26:55 | models:predict_with_model] result for validation set:{'Accuracy': 0.7391304347826086, 'F1': 0.6282608695652173, 'Precision': 0.5463137996219282, 'Recall': 0.7391304347826086, 'AUROC': 0.5294117647058824}\n",
      "[05-19 17:26:55 | models:predict_with_model] ======svc======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "train Counter({'Wildtype': 70, 'Mutant': 21}) test Counter({'Wildtype': 18, 'Mutant': 5})\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:26:56 | models:grid_cv_model] best parameters: {'predictor__C': 0.01, 'predictor__degree': 1}\n",
      "[05-19 17:26:56 | models:predict_with_model] result for CV:{'split0_test_score': array([0.83870968, 0.83870968, 0.83870968, 0.83870968, 0.83870968,\n",
      "       0.83870968, 0.83870968, 0.83870968, 0.83870968]), 'split1_test_score': array([0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]), 'split2_test_score': array([0.66666667, 0.66666667, 0.66666667, 0.66666667, 0.66666667,\n",
      "       0.66666667, 0.66666667, 0.66666667, 0.66666667]), 'mean_test_score': array([0.76845878, 0.76845878, 0.76845878, 0.76845878, 0.76845878,\n",
      "       0.76845878, 0.76845878, 0.76845878, 0.76845878]), 'std_test_score': array([0.07369231, 0.07369231, 0.07369231, 0.07369231, 0.07369231,\n",
      "       0.07369231, 0.07369231, 0.07369231, 0.07369231]), 'rank_test_score': array([1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)}\n",
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:26:56 | models:predict_with_model] result for validation set:{'Accuracy': 0.782608695652174, 'F1': 0.687168610816543, 'Precision': 0.6124763705103969, 'Recall': 0.782608695652174, 'AUROC': 0.5777777777777777}\n",
      "[05-19 17:26:56 | models:predict_with_model] ======svc======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "train Counter({'Wildtype': 70, 'Mutant': 21}) test Counter({'Wildtype': 18, 'Mutant': 5})\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:26:58 | models:grid_cv_model] best parameters: {'predictor__C': 0.01, 'predictor__degree': 1}\n",
      "[05-19 17:26:58 | models:predict_with_model] result for CV:{'split0_test_score': array([0.80645161, 0.80645161, 0.80645161, 0.80645161, 0.80645161,\n",
      "       0.80645161, 0.80645161, 0.80645161, 0.80645161]), 'split1_test_score': array([0.66666667, 0.66666667, 0.66666667, 0.66666667, 0.66666667,\n",
      "       0.66666667, 0.66666667, 0.66666667, 0.66666667]), 'split2_test_score': array([0.83333333, 0.83333333, 0.83333333, 0.83333333, 0.83333333,\n",
      "       0.83333333, 0.83333333, 0.83333333, 0.83333333]), 'mean_test_score': array([0.7688172, 0.7688172, 0.7688172, 0.7688172, 0.7688172, 0.7688172,\n",
      "       0.7688172, 0.7688172, 0.7688172]), 'std_test_score': array([0.07306028, 0.07306028, 0.07306028, 0.07306028, 0.07306028,\n",
      "       0.07306028, 0.07306028, 0.07306028, 0.07306028]), 'rank_test_score': array([1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:26:58 | models:predict_with_model] result for validation set:{'Accuracy': 0.782608695652174, 'F1': 0.687168610816543, 'Precision': 0.6124763705103969, 'Recall': 0.782608695652174, 'AUROC': 0.31111111111111106}\n",
      "[05-19 17:26:58 | models:predict_with_model] ======svc======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "train Counter({'Wildtype': 70, 'Mutant': 21}) test Counter({'Wildtype': 18, 'Mutant': 5})\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:26:59 | models:grid_cv_model] best parameters: {'predictor__C': 0.01, 'predictor__degree': 1}\n",
      "[05-19 17:26:59 | models:predict_with_model] result for CV:{'split0_test_score': array([0.64516129, 0.64516129, 0.64516129, 0.64516129, 0.64516129,\n",
      "       0.64516129, 0.64516129, 0.64516129, 0.64516129]), 'split1_test_score': array([0.86666667, 0.86666667, 0.86666667, 0.86666667, 0.86666667,\n",
      "       0.86666667, 0.86666667, 0.86666667, 0.86666667]), 'split2_test_score': array([0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]), 'mean_test_score': array([0.77060932, 0.77060932, 0.77060932, 0.77060932, 0.77060932,\n",
      "       0.77060932, 0.77060932, 0.77060932, 0.77060932]), 'std_test_score': array([0.09278655, 0.09278655, 0.09278655, 0.09278655, 0.09278655,\n",
      "       0.09278655, 0.09278655, 0.09278655, 0.09278655]), 'rank_test_score': array([1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)}\n",
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:26:59 | models:predict_with_model] result for validation set:{'Accuracy': 0.782608695652174, 'F1': 0.687168610816543, 'Precision': 0.6124763705103969, 'Recall': 0.782608695652174, 'AUROC': 0.4666666666666667}\n",
      "[05-19 17:26:59 | models:predict_with_model] ======svc======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "train Counter({'Wildtype': 71, 'Mutant': 21}) test Counter({'Wildtype': 17, 'Mutant': 5})\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END .............predictor__C=0.01, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ..............predictor__C=0.1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=1; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=2; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:27:00 | models:grid_cv_model] best parameters: {'predictor__C': 0.01, 'predictor__degree': 1}\n",
      "[05-19 17:27:00 | models:predict_with_model] result for CV:{'split0_test_score': array([0.80645161, 0.80645161, 0.80645161, 0.80645161, 0.80645161,\n",
      "       0.80645161, 0.80645161, 0.80645161, 0.80645161]), 'split1_test_score': array([0.77419355, 0.77419355, 0.77419355, 0.77419355, 0.77419355,\n",
      "       0.77419355, 0.77419355, 0.77419355, 0.77419355]), 'split2_test_score': array([0.73333333, 0.73333333, 0.73333333, 0.73333333, 0.73333333,\n",
      "       0.73333333, 0.73333333, 0.73333333, 0.73333333]), 'mean_test_score': array([0.77132616, 0.77132616, 0.77132616, 0.77132616, 0.77132616,\n",
      "       0.77132616, 0.77132616, 0.77132616, 0.77132616]), 'std_test_score': array([0.02991919, 0.02991919, 0.02991919, 0.02991919, 0.02991919,\n",
      "       0.02991919, 0.02991919, 0.02991919, 0.02991919]), 'rank_test_score': array([1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)}\n",
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:27:00 | models:predict_with_model] result for validation set:{'Accuracy': 0.7727272727272727, 'F1': 0.6736596736596737, 'Precision': 0.597107438016529, 'Recall': 0.7727272727272727, 'AUROC': 0.23529411764705885}\n",
      "[05-19 17:27:00 | cv_models:cv_predict_eval_with_model] ======random_forest======\n",
      "[05-19 17:27:00 | models:predict_with_model] ======random_forest======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.0s\n",
      "[CV] END ................predictor__C=1, predictor__degree=3; total time=   0.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.1s\n",
      "train Counter({'Wildtype': 71, 'Mutant': 20}) test Counter({'Wildtype': 17, 'Mutant': 6})\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:27:32 | models:grid_cv_model] best parameters: {'predictor__max_depth': 10, 'predictor__max_features': 'auto', 'predictor__min_samples_leaf': 4, 'predictor__n_estimators': 100}\n",
      "[05-19 17:27:32 | models:predict_with_model] result for CV:{'split0_test_score': array([0.67741935, 0.67741935, 0.67741935, 0.67741935, 0.70967742,\n",
      "       0.70967742, 0.70967742, 0.70967742, 0.67741935, 0.67741935,\n",
      "       0.67741935, 0.67741935, 0.70967742, 0.70967742, 0.70967742,\n",
      "       0.70967742]), 'split1_test_score': array([0.83333333, 0.83333333, 0.83333333, 0.83333333, 0.83333333,\n",
      "       0.83333333, 0.83333333, 0.83333333, 0.83333333, 0.83333333,\n",
      "       0.83333333, 0.83333333, 0.83333333, 0.83333333, 0.83333333,\n",
      "       0.83333333]), 'split2_test_score': array([0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8,\n",
      "       0.8, 0.8, 0.8]), 'mean_test_score': array([0.7702509 , 0.7702509 , 0.7702509 , 0.7702509 , 0.78100358,\n",
      "       0.78100358, 0.78100358, 0.78100358, 0.7702509 , 0.7702509 ,\n",
      "       0.7702509 , 0.7702509 , 0.78100358, 0.78100358, 0.78100358,\n",
      "       0.78100358]), 'std_test_score': array([0.06703755, 0.06703755, 0.06703755, 0.06703755, 0.05223884,\n",
      "       0.05223884, 0.05223884, 0.05223884, 0.06703755, 0.06703755,\n",
      "       0.06703755, 0.06703755, 0.05223884, 0.05223884, 0.05223884,\n",
      "       0.05223884]), 'rank_test_score': array([9, 9, 9, 9, 1, 1, 1, 1, 9, 9, 9, 9, 1, 1, 1, 1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:27:32 | models:predict_with_model] result for validation set:{'Accuracy': 0.7391304347826086, 'F1': 0.6282608695652173, 'Precision': 0.5463137996219282, 'Recall': 0.7391304347826086, 'AUROC': 0.7450980392156863}\n",
      "[05-19 17:27:32 | models:predict_with_model] ======random_forest======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "train Counter({'Wildtype': 70, 'Mutant': 21}) test Counter({'Wildtype': 18, 'Mutant': 5})\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:28:04 | models:grid_cv_model] best parameters: {'predictor__max_depth': 10, 'predictor__max_features': 'auto', 'predictor__min_samples_leaf': 1, 'predictor__n_estimators': 200}\n",
      "[05-19 17:28:04 | models:predict_with_model] result for CV:{'split0_test_score': array([0.83870968, 0.83870968, 0.83870968, 0.83870968, 0.83870968,\n",
      "       0.83870968, 0.83870968, 0.83870968, 0.83870968, 0.83870968,\n",
      "       0.83870968, 0.83870968, 0.83870968, 0.83870968, 0.83870968,\n",
      "       0.83870968]), 'split1_test_score': array([0.66666667, 0.7       , 0.7       , 0.66666667, 0.7       ,\n",
      "       0.7       , 0.7       , 0.66666667, 0.66666667, 0.7       ,\n",
      "       0.7       , 0.66666667, 0.7       , 0.7       , 0.7       ,\n",
      "       0.66666667]), 'split2_test_score': array([0.66666667, 0.66666667, 0.66666667, 0.66666667, 0.66666667,\n",
      "       0.66666667, 0.66666667, 0.66666667, 0.66666667, 0.66666667,\n",
      "       0.66666667, 0.66666667, 0.66666667, 0.66666667, 0.66666667,\n",
      "       0.66666667]), 'mean_test_score': array([0.72401434, 0.73512545, 0.73512545, 0.72401434, 0.73512545,\n",
      "       0.73512545, 0.73512545, 0.72401434, 0.72401434, 0.73512545,\n",
      "       0.73512545, 0.72401434, 0.73512545, 0.73512545, 0.73512545,\n",
      "       0.72401434]), 'std_test_score': array([0.08110185, 0.07449853, 0.07449853, 0.08110185, 0.07449853,\n",
      "       0.07449853, 0.07449853, 0.08110185, 0.08110185, 0.07449853,\n",
      "       0.07449853, 0.08110185, 0.07449853, 0.07449853, 0.07449853,\n",
      "       0.08110185]), 'rank_test_score': array([11,  1,  1, 11,  1,  1,  1, 11, 11,  1,  1, 11,  1,  1,  1, 11],\n",
      "      dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:28:05 | models:predict_with_model] result for validation set:{'Accuracy': 0.782608695652174, 'F1': 0.687168610816543, 'Precision': 0.6124763705103969, 'Recall': 0.782608695652174, 'AUROC': 0.6333333333333333}\n",
      "[05-19 17:28:05 | models:predict_with_model] ======random_forest======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "train Counter({'Wildtype': 70, 'Mutant': 21}) test Counter({'Wildtype': 18, 'Mutant': 5})\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.1s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:28:37 | models:grid_cv_model] best parameters: {'predictor__max_depth': 10, 'predictor__max_features': 'auto', 'predictor__min_samples_leaf': 4, 'predictor__n_estimators': 500}\n",
      "[05-19 17:28:37 | models:predict_with_model] result for CV:{'split0_test_score': array([0.74193548, 0.74193548, 0.74193548, 0.74193548, 0.77419355,\n",
      "       0.80645161, 0.80645161, 0.77419355, 0.74193548, 0.74193548,\n",
      "       0.74193548, 0.74193548, 0.77419355, 0.80645161, 0.80645161,\n",
      "       0.77419355]), 'split1_test_score': array([0.66666667, 0.66666667, 0.66666667, 0.66666667, 0.66666667,\n",
      "       0.63333333, 0.66666667, 0.66666667, 0.66666667, 0.66666667,\n",
      "       0.66666667, 0.66666667, 0.66666667, 0.63333333, 0.66666667,\n",
      "       0.66666667]), 'split2_test_score': array([0.86666667, 0.86666667, 0.83333333, 0.83333333, 0.83333333,\n",
      "       0.83333333, 0.83333333, 0.83333333, 0.86666667, 0.86666667,\n",
      "       0.83333333, 0.83333333, 0.83333333, 0.83333333, 0.83333333,\n",
      "       0.83333333]), 'mean_test_score': array([0.75842294, 0.75842294, 0.74731183, 0.74731183, 0.75806452,\n",
      "       0.75770609, 0.7688172 , 0.75806452, 0.75842294, 0.75842294,\n",
      "       0.74731183, 0.74731183, 0.75806452, 0.75770609, 0.7688172 ,\n",
      "       0.75806452]), 'std_test_score': array([0.08247778, 0.08247778, 0.0681475 , 0.0681475 , 0.0689906 ,\n",
      "       0.08862691, 0.07306028, 0.0689906 , 0.08247778, 0.08247778,\n",
      "       0.0681475 , 0.0681475 , 0.0689906 , 0.08862691, 0.07306028,\n",
      "       0.0689906 ]), 'rank_test_score': array([ 3,  3, 13, 13,  7, 11,  1,  7,  3,  3, 13, 13,  7, 11,  1,  7],\n",
      "      dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:28:38 | models:predict_with_model] result for validation set:{'Accuracy': 0.782608695652174, 'F1': 0.687168610816543, 'Precision': 0.6124763705103969, 'Recall': 0.782608695652174, 'AUROC': 0.6888888888888889}\n",
      "[05-19 17:28:38 | models:predict_with_model] ======random_forest======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "train Counter({'Wildtype': 70, 'Mutant': 21}) test Counter({'Wildtype': 18, 'Mutant': 5})\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   1.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:29:10 | models:grid_cv_model] best parameters: {'predictor__max_depth': 10, 'predictor__max_features': 'auto', 'predictor__min_samples_leaf': 1, 'predictor__n_estimators': 100}\n",
      "[05-19 17:29:10 | models:predict_with_model] result for CV:{'split0_test_score': array([0.64516129, 0.64516129, 0.64516129, 0.64516129, 0.64516129,\n",
      "       0.64516129, 0.64516129, 0.64516129, 0.64516129, 0.64516129,\n",
      "       0.64516129, 0.64516129, 0.64516129, 0.64516129, 0.64516129,\n",
      "       0.64516129]), 'split1_test_score': array([0.86666667, 0.86666667, 0.86666667, 0.86666667, 0.86666667,\n",
      "       0.86666667, 0.86666667, 0.86666667, 0.86666667, 0.86666667,\n",
      "       0.86666667, 0.86666667, 0.86666667, 0.86666667, 0.86666667,\n",
      "       0.86666667]), 'split2_test_score': array([0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8,\n",
      "       0.8, 0.8, 0.8]), 'mean_test_score': array([0.77060932, 0.77060932, 0.77060932, 0.77060932, 0.77060932,\n",
      "       0.77060932, 0.77060932, 0.77060932, 0.77060932, 0.77060932,\n",
      "       0.77060932, 0.77060932, 0.77060932, 0.77060932, 0.77060932,\n",
      "       0.77060932]), 'std_test_score': array([0.09278655, 0.09278655, 0.09278655, 0.09278655, 0.09278655,\n",
      "       0.09278655, 0.09278655, 0.09278655, 0.09278655, 0.09278655,\n",
      "       0.09278655, 0.09278655, 0.09278655, 0.09278655, 0.09278655,\n",
      "       0.09278655]), 'rank_test_score': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:29:10 | models:predict_with_model] result for validation set:{'Accuracy': 0.782608695652174, 'F1': 0.687168610816543, 'Precision': 0.6124763705103969, 'Recall': 0.782608695652174, 'AUROC': 0.5777777777777777}\n",
      "[05-19 17:29:10 | models:predict_with_model] ======random_forest======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Counter({'Wildtype': 71, 'Mutant': 21}) test Counter({'Wildtype': 17, 'Mutant': 5})\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=10, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=1, predictor__n_estimators=1000; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=100; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=200; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=500; total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__max_depth=100, predictor__max_features=auto, predictor__min_samples_leaf=4, predictor__n_estimators=1000; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:29:43 | models:grid_cv_model] best parameters: {'predictor__max_depth': 10, 'predictor__max_features': 'auto', 'predictor__min_samples_leaf': 4, 'predictor__n_estimators': 500}\n",
      "[05-19 17:29:43 | models:predict_with_model] result for CV:{'split0_test_score': array([0.80645161, 0.77419355, 0.80645161, 0.80645161, 0.77419355,\n",
      "       0.77419355, 0.80645161, 0.80645161, 0.80645161, 0.77419355,\n",
      "       0.80645161, 0.80645161, 0.77419355, 0.77419355, 0.80645161,\n",
      "       0.80645161]), 'split1_test_score': array([0.77419355, 0.80645161, 0.77419355, 0.77419355, 0.77419355,\n",
      "       0.80645161, 0.80645161, 0.80645161, 0.77419355, 0.80645161,\n",
      "       0.77419355, 0.77419355, 0.77419355, 0.80645161, 0.80645161,\n",
      "       0.80645161]), 'split2_test_score': array([0.73333333, 0.76666667, 0.73333333, 0.73333333, 0.8       ,\n",
      "       0.76666667, 0.76666667, 0.73333333, 0.73333333, 0.76666667,\n",
      "       0.73333333, 0.73333333, 0.8       , 0.76666667, 0.76666667,\n",
      "       0.73333333]), 'mean_test_score': array([0.77132616, 0.78243728, 0.77132616, 0.77132616, 0.7827957 ,\n",
      "       0.78243728, 0.79318996, 0.78207885, 0.77132616, 0.78243728,\n",
      "       0.77132616, 0.77132616, 0.7827957 , 0.78243728, 0.79318996,\n",
      "       0.78207885]), 'std_test_score': array([0.02991919, 0.01725649, 0.02991919, 0.02991919, 0.01216528,\n",
      "       0.01725649, 0.0187548 , 0.03446829, 0.02991919, 0.01725649,\n",
      "       0.02991919, 0.02991919, 0.01216528, 0.01725649, 0.0187548 ,\n",
      "       0.03446829]), 'rank_test_score': array([11,  5, 11, 11,  3,  5,  1,  9, 11,  5, 11, 11,  3,  5,  1,  9],\n",
      "      dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:29:44 | models:predict_with_model] result for validation set:{'Accuracy': 0.7272727272727273, 'F1': 0.6507177033492823, 'Precision': 0.5887445887445888, 'Recall': 0.7272727272727273, 'AUROC': 0.2588235294117647}\n",
      "[05-19 17:29:44 | cv_models:cv_predict_eval_with_model] ======mlp======\n",
      "[05-19 17:29:44 | models:predict_with_model] ======mlp======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "train Counter({'Wildtype': 71, 'Mutant': 20}) test Counter({'Wildtype': 17, 'Mutant': 6})\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.2s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   1.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   1.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   2.0s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   2.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   2.0s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   2.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.6s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:29:58 | models:grid_cv_model] best parameters: {'predictor__hidden_layer_sizes': (400, 40)}\n",
      "[05-19 17:29:58 | models:predict_with_model] result for CV:{'split0_test_score': array([0.64516129, 0.61290323, 0.70967742, 0.64516129]), 'split1_test_score': array([0.46666667, 0.76666667, 0.66666667, 0.73333333]), 'split2_test_score': array([0.6       , 0.66666667, 0.7       , 0.7       ]), 'mean_test_score': array([0.57060932, 0.68207885, 0.6921147 , 0.69283154]), 'std_test_score': array([0.07577573, 0.06371264, 0.01842308, 0.03635123]), 'rank_test_score': array([4, 3, 2, 1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:30:00 | models:predict_with_model] result for validation set:{'Accuracy': 0.6956521739130435, 'F1': 0.6064659977703456, 'Precision': 0.5375494071146245, 'Recall': 0.6956521739130435, 'AUROC': 0.3823529411764706}\n",
      "[05-19 17:30:00 | models:predict_with_model] ======mlp======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.9s\n",
      "train Counter({'Wildtype': 70, 'Mutant': 21}) test Counter({'Wildtype': 18, 'Mutant': 5})\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.6s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:30:11 | models:grid_cv_model] best parameters: {'predictor__hidden_layer_sizes': (400, 40)}\n",
      "[05-19 17:30:11 | models:predict_with_model] result for CV:{'split0_test_score': array([0.5483871 , 0.61290323, 0.64516129, 0.80645161]), 'split1_test_score': array([0.46666667, 0.56666667, 0.63333333, 0.73333333]), 'split2_test_score': array([0.56666667, 0.6       , 0.53333333, 0.66666667]), 'mean_test_score': array([0.52724014, 0.59318996, 0.60394265, 0.73548387]), 'std_test_score': array([0.04347716, 0.01948054, 0.05016129, 0.05708722]), 'rank_test_score': array([4, 3, 2, 1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:30:13 | models:predict_with_model] result for validation set:{'Accuracy': 0.7391304347826086, 'F1': 0.6652173913043478, 'Precision': 0.6047430830039525, 'Recall': 0.7391304347826086, 'AUROC': 0.3888888888888889}\n",
      "[05-19 17:30:13 | models:predict_with_model] ======mlp======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.4s\n",
      "train Counter({'Wildtype': 70, 'Mutant': 21}) test Counter({'Wildtype': 18, 'Mutant': 5})\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.7s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.5s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:30:25 | models:grid_cv_model] best parameters: {'predictor__hidden_layer_sizes': (400, 40)}\n",
      "[05-19 17:30:25 | models:predict_with_model] result for CV:{'split0_test_score': array([0.41935484, 0.74193548, 0.74193548, 0.83870968]), 'split1_test_score': array([0.6       , 0.66666667, 0.63333333, 0.66666667]), 'split2_test_score': array([0.7       , 0.63333333, 0.83333333, 0.8       ]), 'mean_test_score': array([0.57311828, 0.68064516, 0.73620072, 0.76845878]), 'std_test_score': array([0.11613899, 0.04542507, 0.08175029, 0.07369231]), 'rank_test_score': array([4, 3, 2, 1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   2.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:30:28 | models:predict_with_model] result for validation set:{'Accuracy': 0.782608695652174, 'F1': 0.687168610816543, 'Precision': 0.6124763705103969, 'Recall': 0.782608695652174, 'AUROC': 0.6}\n",
      "[05-19 17:30:28 | models:predict_with_model] ======mlp======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   2.9s\n",
      "train Counter({'Wildtype': 70, 'Mutant': 21}) test Counter({'Wildtype': 18, 'Mutant': 5})\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.7s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.7s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.3s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:30:36 | models:grid_cv_model] best parameters: {'predictor__hidden_layer_sizes': (100, 20)}\n",
      "[05-19 17:30:36 | models:predict_with_model] result for CV:{'split0_test_score': array([0.67741935, 0.61290323, 0.61290323, 0.64516129]), 'split1_test_score': array([0.6       , 0.76666667, 0.66666667, 0.7       ]), 'split2_test_score': array([0.73333333, 0.8       , 0.8       , 0.7       ]), 'mean_test_score': array([0.6702509 , 0.7265233 , 0.69318996, 0.68172043]), 'std_test_score': array([0.0546686 , 0.08148586, 0.07865077, 0.02585122]), 'rank_test_score': array([4, 1, 2, 3], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:30:37 | models:predict_with_model] result for validation set:{'Accuracy': 0.782608695652174, 'F1': 0.687168610816543, 'Precision': 0.6124763705103969, 'Recall': 0.782608695652174, 'AUROC': 0.14444444444444446}\n",
      "[05-19 17:30:37 | models:predict_with_model] ======mlp======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "train Counter({'Wildtype': 71, 'Mutant': 21}) test Counter({'Wildtype': 17, 'Mutant': 5})\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.8s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 10); total time=   0.8s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.5s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(100, 20); total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.1s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.9s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(200, 20); total time=   0.9s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.9s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   2.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.6s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.5s\n",
      "[CV] END ............predictor__hidden_layer_sizes=(400, 40); total time=   1.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:30:51 | models:grid_cv_model] best parameters: {'predictor__hidden_layer_sizes': (400, 40)}\n",
      "[05-19 17:30:51 | models:predict_with_model] result for CV:{'split0_test_score': array([0.74193548, 0.61290323, 0.74193548, 0.58064516]), 'split1_test_score': array([0.5483871 , 0.58064516, 0.61290323, 0.74193548]), 'split2_test_score': array([0.46666667, 0.56666667, 0.63333333, 0.73333333]), 'mean_test_score': array([0.58566308, 0.58673835, 0.66272401, 0.68530466]), 'std_test_score': array([0.11542777, 0.01936148, 0.05662856, 0.07408872]), 'rank_test_score': array([4, 3, 2, 1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   2.5s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05-19 17:30:54 | models:predict_with_model] result for validation set:{'Accuracy': 0.6363636363636364, 'F1': 0.6010101010101011, 'Precision': 0.569377990430622, 'Recall': 0.6363636363636364, 'AUROC': 0.611764705882353}\n",
      "[05-19 17:30:54 | cv_models:cv_predict_eval_with_model] ======xgboost======\n",
      "[05-19 17:30:54 | models:predict_with_model] ======xgboost======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   2.6s\n",
      "train Counter({'Wildtype': 71, 'Mutant': 20}) test Counter({'Wildtype': 17, 'Mutant': 6})\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:30:54] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   2.2s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   2.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:30:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.9s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.9s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:30:57] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   1.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:30:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   1.1s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:30:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   1.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:31:00] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.0s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   1.0s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:31:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:31:02] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   1.2s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   1.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:31:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:31:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:31:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:31:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:31:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[05-19 17:31:04 | models:grid_cv_model] best parameters: {'predictor__learning_rate': 0.1, 'predictor__n_estimators': 100, 'predictor__reg_alpha': 10}\n",
      "[05-19 17:31:04 | models:predict_with_model] result for CV:{'split0_test_score': array([0.70967742, 0.70967742, 0.70967742, 0.70967742]), 'split1_test_score': array([0.8, 0.8, 0.8, 0.8]), 'split2_test_score': array([0.76666667, 0.8       , 0.76666667, 0.83333333]), 'mean_test_score': array([0.75878136, 0.76989247, 0.75878136, 0.78100358]), 'std_test_score': array([0.03729321, 0.04257847, 0.03729321, 0.05223884]), 'rank_test_score': array([3, 2, 3, 1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:31:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:31:04 | models:predict_with_model] result for validation set:{'Accuracy': 0.7391304347826086, 'F1': 0.6282608695652173, 'Precision': 0.5463137996219282, 'Recall': 0.7391304347826086, 'AUROC': 0.75}\n",
      "[05-19 17:31:04 | models:predict_with_model] ======xgboost======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "train Counter({'Wildtype': 70, 'Mutant': 21}) test Counter({'Wildtype': 18, 'Mutant': 5})\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:31:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:31:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:31:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:31:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:31:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:31:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:31:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:31:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:31:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:31:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:31:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:31:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:31:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[05-19 17:31:09 | models:grid_cv_model] best parameters: {'predictor__learning_rate': 0.1, 'predictor__n_estimators': 100, 'predictor__reg_alpha': 1}\n",
      "[05-19 17:31:09 | models:predict_with_model] result for CV:{'split0_test_score': array([0.77419355, 0.83870968, 0.87096774, 0.83870968]), 'split1_test_score': array([0.7       , 0.46666667, 0.73333333, 0.46666667]), 'split2_test_score': array([0.7       , 0.63333333, 0.66666667, 0.66666667]), 'mean_test_score': array([0.72473118, 0.64623656, 0.75698925, 0.65734767]), 'std_test_score': array([0.03497517, 0.15215972, 0.08506638, 0.1520288 ]), 'rank_test_score': array([2, 4, 1, 3], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:31:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[05-19 17:31:09 | models:predict_with_model] result for validation set:{'Accuracy': 0.8260869565217391, 'F1': 0.7768115942028986, 'Precision': 0.8577075098814229, 'Recall': 0.8260869565217391, 'AUROC': 0.6555555555555556}\n",
      "[05-19 17:31:09 | models:predict_with_model] ======xgboost======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "train Counter({'Wildtype': 70, 'Mutant': 21}) test Counter({'Wildtype': 18, 'Mutant': 5})\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:31:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:31:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:31:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:31:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:31:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:31:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:31:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:31:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:31:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:31:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:31:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:31:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:31:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[05-19 17:31:13 | models:grid_cv_model] best parameters: {'predictor__learning_rate': 0.1, 'predictor__n_estimators': 100, 'predictor__reg_alpha': 1}\n",
      "[05-19 17:31:13 | models:predict_with_model] result for CV:{'split0_test_score': array([0.67741935, 0.77419355, 0.70967742, 0.80645161]), 'split1_test_score': array([0.66666667, 0.66666667, 0.63333333, 0.66666667]), 'split2_test_score': array([0.73333333, 0.66666667, 0.8       , 0.66666667]), 'mean_test_score': array([0.69247312, 0.70250896, 0.71433692, 0.71326165]), 'std_test_score': array([0.02922411, 0.05068866, 0.06812111, 0.06589526]), 'rank_test_score': array([4, 3, 1, 2], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:31:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:31:14 | models:predict_with_model] result for validation set:{'Accuracy': 0.782608695652174, 'F1': 0.687168610816543, 'Precision': 0.6124763705103969, 'Recall': 0.782608695652174, 'AUROC': 0.7333333333333334}\n",
      "[05-19 17:31:14 | models:predict_with_model] ======xgboost======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "train Counter({'Wildtype': 70, 'Mutant': 21}) test Counter({'Wildtype': 18, 'Mutant': 5})\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:31:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:31:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:31:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:31:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:31:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:31:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:31:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:31:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:31:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:31:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:31:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:31:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:31:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[05-19 17:31:18 | models:grid_cv_model] best parameters: {'predictor__learning_rate': 0.1, 'predictor__n_estimators': 100, 'predictor__reg_alpha': 1}\n",
      "[05-19 17:31:18 | models:predict_with_model] result for CV:{'split0_test_score': array([0.64516129, 0.64516129, 0.64516129, 0.64516129]), 'split1_test_score': array([0.63333333, 0.76666667, 0.8       , 0.76666667]), 'split2_test_score': array([0.8       , 0.8       , 0.8       , 0.83333333]), 'mean_test_score': array([0.69283154, 0.73727599, 0.7483871 , 0.7483871 ]), 'std_test_score': array([0.07593323, 0.06654129, 0.07299167, 0.07790073]), 'rank_test_score': array([4, 3, 1, 1], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:31:18] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[05-19 17:31:18 | models:predict_with_model] result for validation set:{'Accuracy': 0.782608695652174, 'F1': 0.687168610816543, 'Precision': 0.6124763705103969, 'Recall': 0.782608695652174, 'AUROC': 0.8111111111111111}\n",
      "[05-19 17:31:18 | models:predict_with_model] ======xgboost======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "train Counter({'Wildtype': 71, 'Mutant': 21}) test Counter({'Wildtype': 17, 'Mutant': 5})\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:31:18] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:31:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:31:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:31:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:31:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.4s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:31:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.01, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.4s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:31:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:31:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:31:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.3s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=1; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:31:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:31:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.2s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:31:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.2s\n",
      "[CV] END predictor__learning_rate=0.1, predictor__n_estimators=100, predictor__reg_alpha=10; total time=   0.3s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:31:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[05-19 17:31:23 | models:grid_cv_model] best parameters: {'predictor__learning_rate': 0.01, 'predictor__n_estimators': 100, 'predictor__reg_alpha': 10}\n",
      "[05-19 17:31:23 | models:predict_with_model] result for CV:{'split0_test_score': array([0.70967742, 0.77419355, 0.74193548, 0.77419355]), 'split1_test_score': array([0.77419355, 0.77419355, 0.74193548, 0.77419355]), 'split2_test_score': array([0.73333333, 0.8       , 0.8       , 0.76666667]), 'mean_test_score': array([0.7390681 , 0.7827957 , 0.76129032, 0.77168459]), 'std_test_score': array([0.02664893, 0.01216528, 0.02737188, 0.00354821]), 'rank_test_score': array([4, 1, 3, 2], dtype=int32)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[17:31:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[05-19 17:31:23 | models:predict_with_model] result for validation set:{'Accuracy': 0.7272727272727273, 'F1': 0.6507177033492823, 'Precision': 0.5887445887445888, 'Recall': 0.7272727272727273, 'AUROC': 0.6411764705882352}\n",
      "[05-19 17:31:23 | application_cross_validation:ApplicationCV] Saved results to /labs/gevaertlab/users/yyhhli/code/vae/applications/results/VAE3D32AUG_70/StfKRASMutation.cv_result_dict.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ......... (step 2 of 2) Processing predictor, total=   0.6s\n",
      "{'__dict': {}, 'logistic_regression': {'Accuracy': [0.7391304347826086, 0.782608695652174, 0.782608695652174, 0.782608695652174, 0.7727272727272727], 'F1': [0.6282608695652173, 0.687168610816543, 0.687168610816543, 0.687168610816543, 0.6736596736596737], 'Precision': [0.5463137996219282, 0.6124763705103969, 0.6124763705103969, 0.6124763705103969, 0.597107438016529], 'Recall': [0.7391304347826086, 0.782608695652174, 0.782608695652174, 0.782608695652174, 0.7727272727272727], 'AUROC': [0.5, 0.5, 0.5, 0.5, 0.5]}, 'k_nearest_neighbors': {'Accuracy': [0.6956521739130435, 0.7391304347826086, 0.7391304347826086, 0.6086956521739131, 0.7727272727272727], 'F1': [0.6064659977703456, 0.6652173913043478, 0.6652173913043478, 0.5922444183313749, 0.6736596736596737], 'Precision': [0.5375494071146245, 0.6047430830039525, 0.6047430830039525, 0.5766590389016018, 0.597107438016529], 'Recall': [0.6956521739130435, 0.7391304347826086, 0.7391304347826086, 0.6086956521739131, 0.7727272727272727], 'AUROC': [0.3431372549019608, 0.5555555555555556, 0.7555555555555555, 0.3833333333333333, 0.30000000000000004]}, 'svc': {'Accuracy': [0.7391304347826086, 0.782608695652174, 0.782608695652174, 0.782608695652174, 0.7727272727272727], 'F1': [0.6282608695652173, 0.687168610816543, 0.687168610816543, 0.687168610816543, 0.6736596736596737], 'Precision': [0.5463137996219282, 0.6124763705103969, 0.6124763705103969, 0.6124763705103969, 0.597107438016529], 'Recall': [0.7391304347826086, 0.782608695652174, 0.782608695652174, 0.782608695652174, 0.7727272727272727], 'AUROC': [0.5294117647058824, 0.5777777777777777, 0.31111111111111106, 0.4666666666666667, 0.23529411764705885]}, 'random_forest': {'Accuracy': [0.7391304347826086, 0.782608695652174, 0.782608695652174, 0.782608695652174, 0.7272727272727273], 'F1': [0.6282608695652173, 0.687168610816543, 0.687168610816543, 0.687168610816543, 0.6507177033492823], 'Precision': [0.5463137996219282, 0.6124763705103969, 0.6124763705103969, 0.6124763705103969, 0.5887445887445888], 'Recall': [0.7391304347826086, 0.782608695652174, 0.782608695652174, 0.782608695652174, 0.7272727272727273], 'AUROC': [0.7450980392156863, 0.6333333333333333, 0.6888888888888889, 0.5777777777777777, 0.2588235294117647]}, 'mlp': {'Accuracy': [0.6956521739130435, 0.7391304347826086, 0.782608695652174, 0.782608695652174, 0.6363636363636364], 'F1': [0.6064659977703456, 0.6652173913043478, 0.687168610816543, 0.687168610816543, 0.6010101010101011], 'Precision': [0.5375494071146245, 0.6047430830039525, 0.6124763705103969, 0.6124763705103969, 0.569377990430622], 'Recall': [0.6956521739130435, 0.7391304347826086, 0.782608695652174, 0.782608695652174, 0.6363636363636364], 'AUROC': [0.3823529411764706, 0.3888888888888889, 0.6, 0.14444444444444446, 0.611764705882353]}, 'xgboost': {'Accuracy': [0.7391304347826086, 0.8260869565217391, 0.782608695652174, 0.782608695652174, 0.7272727272727273], 'F1': [0.6282608695652173, 0.7768115942028986, 0.687168610816543, 0.687168610816543, 0.6507177033492823], 'Precision': [0.5463137996219282, 0.8577075098814229, 0.6124763705103969, 0.6124763705103969, 0.5887445887445888], 'Recall': [0.7391304347826086, 0.8260869565217391, 0.782608695652174, 0.782608695652174, 0.7272727272727273], 'AUROC': [0.75, 0.6555555555555556, 0.7333333333333334, 0.8111111111111111, 0.6411764705882352]}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for task in [\"StfAJCC\", \"StfHisGrade\", \"StfNStage\", \"StfTStage\", \"StfLymphInvasion\", \"StfEGFRMutation\", \"StfKRASMutation\"]:  # \"StfVolume\", \"StfLymphInvasion\"\n",
    "    for version in [70]:\n",
    "        print(\n",
    "            f\"======= Predicting {task} with model version {version} =======\")\n",
    "        app = ApplicationCV(log_name='VAE3D32AUG',\n",
    "                            version=version,\n",
    "                            task_name=task,\n",
    "                            task_kwds={\"task_type\": \"classification\"},\n",
    "                            base_model_name='VAE3D',\n",
    "                            dataloaders={'train': stfrg_train_patch_dataloader,\n",
    "                                        'val': stfrg_test_patch_dataloader})\n",
    "\n",
    "        result_dict = app.task_prediction(tune_hparams=True, models='all')\n",
    "        print(result_dict)\n",
    "        app.save_results(verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for task in [\"StfLymphInvasion\"]:\n",
    "    for version in [49, 51, 53, 60]:\n",
    "        print(\n",
    "            f\"======= Predicting {task} with model version {version} =======\")\n",
    "        app = ApplicationCV(log_name='VAE3D32AUG',\n",
    "                            version=version,\n",
    "                            task_name=task,\n",
    "                            task_kwds={\"task_type\": \"classification\"},\n",
    "                            base_model_name='VAE3D',\n",
    "                            dataloaders={'train': stfrg_train_patch_dataloader,\n",
    "                                        'val': stfrg_test_patch_dataloader})\n",
    "\n",
    "        result_dict = app.task_prediction(tune_hparams=True, models='xgboost')\n",
    "        print(result_dict)\n",
    "        app.save_results(verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for task in [\"StfLymphInvasion\"]:\n",
    "    for version in [1, 2, 3]:\n",
    "        print(\n",
    "            f\"======= Predicting {task} with model version {version} =======\")\n",
    "        app = ApplicationCV(log_name='PRETRAINED_VAE',\n",
    "                            version=version,\n",
    "                            task_name=task,\n",
    "                            task_kwds={\"task_type\": \"classification\"},\n",
    "                            base_model_name='VAE3D',\n",
    "                            dataloaders={'train': stfrg_train_patch_dataloader,\n",
    "                                        'val': stfrg_test_patch_dataloader})\n",
    "\n",
    "        result_dict = app.task_prediction(tune_hparams=True, models='xgboost')\n",
    "        print(result_dict)\n",
    "        app.save_results(verbose=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "69a9686b88574cea3f3be86d1b85294c5e5eb295dbbf26619c72ae656e929b42"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('lungvae38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
