{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do experiment on size of nodules using LIDC dataset\n",
    "# select two batches of images, one is smallest 5%, the other is largest 5%\n",
    "# get their embeddings and calculate the difference\n",
    "# select another batch of nodules, could be any\n",
    "# modify with the direction of the vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import sys\n",
    "sys.path.insert(1, '/labs/gevaertlab/users/yyhhli/code/vae/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[04-12 17:38:45 | patch_ds:LIDCPatchAugDataset] patient split: train:699, val:88, test:88\n",
      "[04-12 17:38:45 | patch_ds:LIDCPatchAugDataset] patient split: train:699, val:88, test:88\n"
     ]
    }
   ],
   "source": [
    "# import lidc dataset\n",
    "from datasets import PATCH_DATASETS\n",
    "from datasets.utils import sitk2tensor\n",
    "lidc_train = PATCH_DATASETS['LIDCPatchAugDataset'](root_dir=None, transform=sitk2tensor, split='train')\n",
    "lidc_val = PATCH_DATASETS['LIDCPatchAugDataset'](root_dir=None, transform=sitk2tensor, split='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataloaders\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "lidc_train_dataloader = DataLoader(dataset=lidc_train, batch_size=36, shuffle=False, drop_last=False, num_workers=4, pin_memory=False)\n",
    "lidc_val_dataloader = DataLoader(dataset=lidc_val, batch_size=36, shuffle=False, drop_last=False, num_workers=4, pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[04-12 17:39:02 | instantiator:  <module>] Created a temporary directory at /tmp/tmpoqcxin4t\n",
      "[04-12 17:39:02 | instantiator:    _write] Writing /tmp/tmpoqcxin4t/_remote_module_non_sriptable.py\n",
      "[04-12 17:39:06 | patch_ds:LIDCPatchAugDataset] patient split: train:699, val:88, test:88\n",
      "[04-12 17:39:06 | patch_ds:LNDbPatch32AugDataset] patient split: train:168, val:22, test:22\n",
      "[04-12 17:39:06 | patch_stanfordradiogenomics:StanfordRadiogenomicsPatchAugDataset] patient split: train:100, test:43\n"
     ]
    }
   ],
   "source": [
    "# import exporter\n",
    "from evaluations.export import Exporter\n",
    "\n",
    "exporter = Exporter(log_name=\"VAE3D32AUG\", version=60, \n",
    "    dataloaders={\"train\": lidc_train_dataloader, \"val\": lidc_val_dataloader}, \n",
    "    task_names=[\"volume\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[04-12 17:39:06 | export:  Exporter] initializing embeddings\n",
      "[04-12 17:39:10 | patch_ds:LIDCPatchAugDataset] patient split: train:699, val:88, test:88\n",
      "[04-12 17:39:10 | patch_ds:LNDbPatch32AugDataset] patient split: train:168, val:22, test:22\n",
      "[04-12 17:39:10 | patch_stanfordradiogenomics:StanfordRadiogenomicsPatchAugDataset] patient split: train:100, test:43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | 75.0 secs.\n"
     ]
    }
   ],
   "source": [
    "embeddings, data_names, label_dict = exporter.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select smallest and largest 5% nodules\n",
    "import numpy as np\n",
    "volume = np.array(label_dict[\"volume\"]['train']) # numpy array\n",
    "smallest_5_idx = volume.argsort()[:int(len(volume)*0.05)]\n",
    "largest_5_idx = volume.argsort()[-int(len(volume)*0.05):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7444.667388783828"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(volume[largest_5_idx] - volume[smallest_5_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_train = embeddings[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_train = np.array(embeddings_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5304, 4096)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get their embeddings\n",
    "smallest_5_embeddings = embeddings_train[smallest_5_idx]\n",
    "largest_5_embeddings = embeddings_train[largest_5_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LIDC-IDRI-0001.84.Aug00',\n",
       " 'LIDC-IDRI-0001.85.Aug00',\n",
       " 'LIDC-IDRI-0001.86.Aug00',\n",
       " 'LIDC-IDRI-0001.87.Aug00',\n",
       " 'LIDC-IDRI-0002.88.Aug00']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_names[\"train\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the difference\n",
    "smallest_5_embeddings_mean = smallest_5_embeddings.mean(axis=0)\n",
    "largest_5_embeddings_mean = largest_5_embeddings.mean(axis=0)\n",
    "diff_vector = largest_5_embeddings_mean - smallest_5_embeddings_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select another batch of nodules from val dataset\n",
    "test_nodules = next(iter(lidc_val_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_nodules[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 32, 32])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_nodules[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the nodules\n",
    "from utils.visualization import vis3d_tensor\n",
    "vis_dir=\"/labs/gevaertlab/users/yyhhli/code/vae/EDA/image_synthesize_experiment/results/\"\n",
    "vis3d_tensor(test_nodules[0], save_path=osp.join(vis_dir, \"test_nodules_orig.jpeg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[04-12 18:37:25 | patch_ds:LIDCPatchAugDataset] patient split: train:699, val:88, test:88\n",
      "[04-12 18:37:25 | patch_ds:LNDbPatch32AugDataset] patient split: train:168, val:22, test:22\n",
      "[04-12 18:37:25 | patch_stanfordradiogenomics:StanfordRadiogenomicsPatchAugDataset] patient split: train:100, test:43\n"
     ]
    }
   ],
   "source": [
    "# generate images\n",
    "from evaluations.evaluator import ReconEvaluator\n",
    "evaluator = ReconEvaluator(vis_dir=vis_dir, log_name='VAE3D32AUG', version=60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get embeddings\n",
    "embeds = evaluator.module.model.encode(test_nodules[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([36, 2048]) torch.Size([36, 2048])\n"
     ]
    }
   ],
   "source": [
    "print(embeds[0].shape, embeds[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corrupt the nodules embeddings\n",
    "corrupted_embeddings = embeds[0] + torch.from_numpy(diff_vector[:2048]).type(torch.FloatTensor).to(evaluator.module.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([36, 2048])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrupted_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "synth_img = evaluator.generate(corrupted_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([36, 1, 32, 32, 32])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synth_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis3d_tensor(synth_img, save_path=osp.join(vis_dir, \"test_nodules_corrupted.jpeg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corrupt the nodules embeddings to the other direction\n",
    "corrupted_embeddings_smaller = embeds[0] - torch.from_numpy(diff_vector[:2048]).type(torch.FloatTensor).to(evaluator.module.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_img_smaller = evaluator.generate(corrupted_embeddings_smaller)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize\n",
    "vis3d_tensor(synth_img_smaller, save_path=osp.join(vis_dir, \"test_nodules_corrupted_smaller.jpeg\"))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "69a9686b88574cea3f3be86d1b85294c5e5eb295dbbf26619c72ae656e929b42"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('lungvae38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
