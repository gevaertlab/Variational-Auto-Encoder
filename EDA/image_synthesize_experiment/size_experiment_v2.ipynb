{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import sys\n",
    "sys.path.insert(1, '/labs/gevaertlab/users/yyhhli/code/vae/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/gevaertlab/users/yyhhli/miniconda3/envs/lungvae38/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[04-15 14:52:17 | patch_ds:LIDCPatchAugDataset] patient split: train:699, val:88, test:88\n",
      "[04-15 14:52:17 | patch_ds:LIDCPatchAugDataset] patient split: train:699, val:88, test:88\n"
     ]
    }
   ],
   "source": [
    "# import lidc dataset\n",
    "from datasets import PATCH_DATASETS\n",
    "from datasets.utils import sitk2tensor\n",
    "lidc_train = PATCH_DATASETS['LIDCPatchAugDataset'](root_dir=None, transform=sitk2tensor, split='train')\n",
    "lidc_val = PATCH_DATASETS['LIDCPatchAugDataset'](root_dir=None, transform=sitk2tensor, split='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataloaders\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "lidc_train_dataloader = DataLoader(dataset=lidc_train, batch_size=36, shuffle=False, drop_last=False, num_workers=4, pin_memory=False)\n",
    "lidc_val_dataloader = DataLoader(dataset=lidc_val, batch_size=36, shuffle=False, drop_last=False, num_workers=4, pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[04-15 14:53:23 | instantiator:  <module>] Created a temporary directory at /tmp/tmpofjgu33f\n",
      "[04-15 14:53:23 | instantiator:    _write] Writing /tmp/tmpofjgu33f/_remote_module_non_sriptable.py\n",
      "[04-15 14:53:27 | patch_ds:LIDCPatchAugDataset] patient split: train:699, val:88, test:88\n",
      "[04-15 14:53:27 | patch_ds:LNDbPatch32AugDataset] patient split: train:168, val:22, test:22\n",
      "[04-15 14:53:28 | patch_stanfordradiogenomics:StanfordRadiogenomicsPatchAugDataset] patient split: train:100, test:43\n"
     ]
    }
   ],
   "source": [
    "# import exporter\n",
    "from evaluations.export import Exporter\n",
    "\n",
    "exporter = Exporter(log_name=\"VAE3D32AUG\", version=60, \n",
    "    dataloaders={\"train\": lidc_train_dataloader, \"val\": lidc_val_dataloader}, \n",
    "    task_names=[\"volume\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[04-15 14:53:28 | export:  Exporter] initializing embeddings\n",
      "[04-15 14:53:32 | patch_ds:LIDCPatchAugDataset] patient split: train:699, val:88, test:88\n",
      "[04-15 14:53:32 | patch_ds:LNDbPatch32AugDataset] patient split: train:168, val:22, test:22\n",
      "[04-15 14:53:32 | patch_stanfordradiogenomics:StanfordRadiogenomicsPatchAugDataset] patient split: train:100, test:43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | 54.0 secs.\n"
     ]
    }
   ],
   "source": [
    "embeddings, data_names, label_dict = exporter.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select smallest and largest 5% nodules\n",
    "import numpy as np\n",
    "volume = np.array(label_dict[\"volume\"]['train']) # numpy array\n",
    "smallest_5_idx = volume.argsort()[:int(len(volume)*0.05)]\n",
    "largest_5_idx = volume.argsort()[-int(len(volume)*0.05):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7444.667388783828"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(volume[largest_5_idx] - volume[smallest_5_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5304, 4096)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_train = embeddings[\"train\"]\n",
    "embeddings_train = np.array(embeddings_train)\n",
    "embeddings_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get their embeddings\n",
    "smallest_5_embeddings = embeddings_train[smallest_5_idx]\n",
    "largest_5_embeddings = embeddings_train[largest_5_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LIDC-IDRI-0001.84.Aug00',\n",
       " 'LIDC-IDRI-0001.85.Aug00',\n",
       " 'LIDC-IDRI-0001.86.Aug00',\n",
       " 'LIDC-IDRI-0001.87.Aug00',\n",
       " 'LIDC-IDRI-0002.88.Aug00']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_names[\"train\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the difference\n",
    "smallest_5_embeddings_mean = smallest_5_embeddings.mean(axis=0)\n",
    "largest_5_embeddings_mean = largest_5_embeddings.mean(axis=0)\n",
    "diff_vector = largest_5_embeddings_mean - smallest_5_embeddings_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select another batch of nodules (36 nodules) from train dataset\n",
    "median_idx = volume.argsort()[int(len(volume)*0.5)-18: int(len(volume)*0.5)+18]\n",
    "median_embeddings = embeddings_train[median_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[04-15 15:15:53 | patch_ds:LIDCPatchAugDataset] patient split: train:699, val:88, test:88\n",
      "[04-15 15:15:54 | patch_ds:LNDbPatch32AugDataset] patient split: train:168, val:22, test:22\n",
      "[04-15 15:15:54 | patch_stanfordradiogenomics:StanfordRadiogenomicsPatchAugDataset] patient split: train:100, test:43\n"
     ]
    }
   ],
   "source": [
    "# generate images\n",
    "from evaluations.evaluator import ReconEvaluator\n",
    "vis_dir=\"/labs/gevaertlab/users/yyhhli/code/vae/EDA/image_synthesize_experiment/results/\"\n",
    "evaluator = ReconEvaluator(vis_dir=vis_dir, log_name='VAE3D32AUG', version=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment 1: enlarge and shrink the nodules\n",
    "import torch\n",
    "half_vector = torch.from_numpy(diff_vector[:2048]).type(torch.FloatTensor).to(evaluator.module.device) / 1.732\n",
    "# enlarge\n",
    "enlarged_embeddings = torch.from_numpy(median_embeddings[:, :2048]) + half_vector\n",
    "# shrink\n",
    "shrinked_embeddings = torch.from_numpy(median_embeddings[:, :2048]) - half_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_images = evaluator.generate(torch.from_numpy(median_embeddings[:, :2048]).type(torch.float))\n",
    "enlarged_images = evaluator.generate(enlarged_embeddings.type(torch.float))\n",
    "shrinked_images = evaluator.generate(shrinked_embeddings.type(torch.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize all the images\n",
    "from utils.visualization import vis3d_tensor\n",
    "vis3d_tensor(median_images, save_path=osp.join(vis_dir, \"test_nodules_median.jpeg\"))\n",
    "vis3d_tensor(enlarged_images, save_path=osp.join(vis_dir, \"test_nodules_enlarged.jpeg\"))\n",
    "vis3d_tensor(shrinked_images, save_path=osp.join(vis_dir, \"test_nodules_shrinked.jpeg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment 2: small to large nodules and large to small nodules\n",
    "small_embeddings = smallest_5_embeddings[:36,:2048]\n",
    "large_embeddings = largest_5_embeddings[:36,:2048]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert large to small and small to large using vector\n",
    "s2l_embeddings = torch.from_numpy(small_embeddings) + half_vector * 1.732\n",
    "l2s_embeddings = torch.from_numpy(large_embeddings) - half_vector * 1.732"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate images\n",
    "small_images = evaluator.generate(torch.from_numpy(small_embeddings).type(torch.float))\n",
    "large_images = evaluator.generate(torch.from_numpy(large_embeddings).type(torch.float))\n",
    "s2l_images = evaluator.generate(s2l_embeddings.type(torch.float))\n",
    "l2s_images = evaluator.generate(l2s_embeddings.type(torch.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all images\n",
    "vis3d_tensor(small_images, save_path=osp.join(vis_dir, \"test_nodules_small.jpeg\"))\n",
    "vis3d_tensor(large_images, save_path=osp.join(vis_dir, \"test_nodules_large.jpeg\"))\n",
    "vis3d_tensor(s2l_images, save_path=osp.join(vis_dir, \"test_nodules_s2l.jpeg\"))\n",
    "vis3d_tensor(l2s_images, save_path=osp.join(vis_dir, \"test_nodules_l2s.jpeg\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "69a9686b88574cea3f3be86d1b85294c5e5eb295dbbf26619c72ae656e929b42"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('lungvae38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
